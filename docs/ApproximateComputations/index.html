<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme Â· ApproximateComputations.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>ApproximateComputations.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li class="toplevel"><a class="toctext" href="#Tutorial-1">Tutorial</a></li><li><a class="toctext" href="#AST-Tutorial-1">AST Tutorial</a></li><li><a class="toctext" href="#Handling-Variables-with-our-AST-1">Handling Variables with our AST</a></li><li><a class="toctext" href="#Loop-Perforation-1">Loop Perforation</a></li><li><a class="toctext" href="#Approximate-Memoisation-1">Approximate Memoisation</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="ApproximateComputations.jl-1" href="#ApproximateComputations.jl-1">ApproximateComputations.jl</a></h1><p><a href="https://travis-ci.org/NTimmons/ApproximateComputations.jl"><img src="https://travis-ci.org/NTimmons/ApproximateComputations.jl.svg?branch=master" alt="Build Status"/></a><a href="https://codecov.io/gh/NTimmons/ApproximateComputations.jl"><img src="https://codecov.io/gh/NTimmons/ApproximateComputations.jl/branch/master/graph/badge.svg" alt="codecov"/></a></p><p>ApproximateComputations.jl is a library for the automatic applicaiton approximate computation software techniques to existing code. In this context, software approximation is where we perform some transformation to existing code to reduce the accuracy for gain in performance.</p><p>This is usually applied through function replacement. The standard workflow is to determine the maximum or average acceptable error for a given code block and then reducing the accuracy of the function so that as little work as possible is spent on gaining a more acurate result that the acceptable level.</p><h1><a class="nav-anchor" id="Tutorial-1" href="#Tutorial-1">Tutorial</a></h1><p>An example of the usage of the small set of functions currently in this library is avialable below. In this small example we show how to generate a replacement for the function &#39;sin&#39; that has an average error when compared to the high-precision implementation of no more than 1x10^-8.</p><ol><li>Generate new functions which approximate &#39;sin&#39; in the range 0.001 to pi/2 </li></ol><pre><code class="language-none">using ApproximateComputations
newFunctionsAndInformation = GenerateAllApproximationFunctions(sin, 0.001, 1.57)</code></pre><ol><li>Filter the generated functions to select the fastest executing function within our error constraint:</li></ol><pre><code class="language-none">a = GetFastestAcceptable(newFunctionsAndInformation, meanErrorLimit=0.00000001)
println(GetFunctionName(a))  # -&gt; returns sin_PolyLet9_Float64bit</code></pre><ol><li>Store the function for use:</li></ol><pre><code class="language-none">approxsin = a.generatedFunction</code></pre><ol><li>Compare to accurate function:</li></ol><pre><code class="language-none">approxResult = approxsin(1.0) # -&gt; Approximation{Float64}(0.8414709848311571)
realResult = sin(1.0)   # -&gt; {Float64} (0.8414709848078965)</code></pre><h4><a class="nav-anchor" id="Using-the-Approximation-type:-1" href="#Using-the-Approximation-type:-1">Using the Approximation type:</a></h4><p>Approximated functions return a type wrapped in Approximation. This is to prevent unintentional mixing of approximate space data with high precision data.</p><ol><li>To convert from an approximation to the original type we use Get(x)</li></ol><pre><code class="language-none">x = Get(approxResult) # -&gt; {Float64} (0.8414709848311571)</code></pre><h4><a class="nav-anchor" id="Extra-function-information:-1" href="#Extra-function-information:-1">Extra function information:</a></h4><p>To be able to produce and select an appropriate approximation the package also contains graphing functions to show the behaviours of the different functions generated by &#39;GenerateAllApproximationFunctions&#39; as well as filtering functions select only the functions which match constraints on error, runtime or internal type precision.</p><h2><a class="nav-anchor" id="AST-Tutorial-1" href="#AST-Tutorial-1">AST Tutorial</a></h2><p>We have implemented a simple AST for altering functions and breaking them into chunks for analysis. The use is relatively simple</p><pre><code class="language-none">using ApproximateComputations
using ImportAll
@importall Base</code></pre><p>First we need to include this package and importall of Base. We need to import all the functions to allow us to override them. We need to override them so we can make them work with our wrapper types and in some cases, inject diagnostics.</p><p>We can define a normal function, in this case &quot;little&quot;, and then submit the function to <code>UpdateEnvironmentForFunction</code>. This will identify all the functions that are called from this function and override them for our wrapper types.</p><pre><code class="language-none">little(x)  = (x * 2) + 5
UpdateEnvironmentForFunction(little)</code></pre><p>We can then produce our AST from this object by passing in our inputs to the functions in the <code>Variable</code> type like this:</p><pre><code class="language-none">littletree = little(Variable(123))
printtree(littletree)

==&gt; |+(id:3)
    |  |*(id:2)
    |  |  |123(id:1)
    |  |  |2
    |  |5</code></pre><p>This shows our valid AST, and the ID for each operation.</p><p>This AST can be executed as a tree using the <code>EmulateTree</code> function</p><pre><code class="language-none">EmulateTree(littletree)
==&gt; 251</code></pre><p>or you can call the function directly:</p><pre><code class="language-none">little(123)
==&gt; 251</code></pre><p>If we want to modify the tree we can do so by supplying a replacement sub-tree and the id of the part of the tree that is to be replaced.</p><p>In this case we are changing the function from  <code>(123 * 2) + 5</code> to <code>(0 * 2) + 5</code></p><pre><code class="language-none">ReplaceSubTree(littletree, Variable(0), 1)
printtree(littletree)
==&gt; |+(id:3)
    |  |*(id:2)
    |  |  |0(id:4)
    |  |  |2
    |  |5</code></pre><p>This changes the input tree and can then be ran to show that the result is now what we expect:</p><pre><code class="language-none">EmulateTree(littletree)
==&gt; 5</code></pre><p>Nice and simple, but allows for powerful automated transformations!</p><h2><a class="nav-anchor" id="Handling-Variables-with-our-AST-1" href="#Handling-Variables-with-our-AST-1">Handling Variables with our AST</a></h2><p>In the above example we instantiated an instance of the function AST with a constant variable. If we wanted to represent the general case of the function we need to instantiate it with a generic &#39;Symbol&#39;</p><pre><code class="language-none">standardfunc(x)  = (x * 2) + 5
UpdateEnvironmentForFunction(standardfunc)

standardfunctree = standardfunc(Variable(:x))</code></pre><p>This is now a AST which can be evaluated with any value or type for the symbol <code>x</code>.</p><p>To be able to do that we have provided two interfaces     - <code>local scope variables</code> - These are passed in the evaluation call and set a value for different symbols for only that call.     - <code>global scope variables</code> - These are set outside of the call to evaulate the tree and are available to any evaluation calls made afterwards.</p><p>There are some rules to using variables. If the variable symbol cannot be resolved an error will be returned and the symbol will be replaced with the value <code>0</code> for that call. If there are conflicting symbols in the global and local scope, the local scope will be used, this allows for convenient replacement.</p><p>Example of evaluating the above tree with a local scope instantiation of <code>:x</code> :</p><pre><code class="language-none">EmulateTree(standardfunctree, Dict(:x=&gt;0) )</code></pre><p>This is the equivilent of calling <code>standardfunc(0)</code></p><p>Example of evaluating the above tree with a global scope instantiation of <code>:x</code> :</p><pre><code class="language-none">SetSymbolValue(:x, 0)
println( EmulateTree(standardfunctree ) )</code></pre><p>This is also the equivilent of calling <code>standardfunc(0)</code></p><h2><a class="nav-anchor" id="Loop-Perforation-1" href="#Loop-Perforation-1">Loop Perforation</a></h2><p>Loop perforation is an approximation approach where loops are manipulated to reduce the iteration count in some way to improve the performance of an application without impacting the final result beyond a fixed constraint.</p><p>This part of our library allows for the targeted replacement of loops parameters to achieve this in a generic way to arbitrary code.</p><p>We perform this optimisation on Julia AST representations. As these cannot in the current release of Julia be directly extracted from a compiled function we require that the source is directly provided, like so:</p><pre><code class="language-none">expr =	quote
				function newfunc()
					aa = 0
					for i in 1:10
						aa = aa + 1
					end
					aa
				end
			end</code></pre><p>This example is of a simple loop which will increment a variable based on a ranged loop. This example is being used as it is trivial to test if the loop replacement has been a success.</p><p>With our function defined we pass it into the loop perforatation function:</p><pre><code class="language-none">LoopPerforation(expr, UnitRange, ClipFrontAndBack)</code></pre><p>The function takes three inputs. The source code that is to be manipulated, the type of loop to target (in this case a loop which uses a UnitRange, others are supported and can be trivially extended to match any pattern), and a function which will output the replacement parameters. The result of calling this function is that the input source code is changed in place.</p><p>For our demo here we are passing in the source code, <code>UnitRange</code> as we are looking to replace the <code>1:10</code> loop parameter which is a <code>UnitRange</code> and the included function <code>ClipFrontAndBack</code> which takes the UnitRange and increments the minimum value and decrements the maximum value, resulting in the range <code>2:8</code>.</p><p>Once this has been called and has succeeded we can extract the function for use by evaluating the Julia Expressions:</p><pre><code class="language-none">eval(expr)</code></pre><p>and then we can test to see if the output is what we expect</p><pre><code class="language-none">@test newfunc() == 8</code></pre><h2><a class="nav-anchor" id="Approximate-Memoisation-1" href="#Approximate-Memoisation-1">Approximate Memoisation</a></h2><p>Memoisation is a common technique to store the return the values of an expensive function so that multiple calls do not result in multiple expensive runs of the function.</p><p>Memoisation can be ineffecient for numerical applications with slight variations of input where each input will result a different value being saved even when they are nearly identical. In an application which is error resilient this is wasted memory as a single value could be stored for all inputs which are close or result in a similar answer.</p><p>As most memoisation is based on a hashtable we are able to construct an approximate memoisation by allowing for the custom of custom hash functions which result in clashes when any two inputs are similar enough to be within our error threshold.</p><p>With this setup, a hash function which causes a clash for any input values in 0.05 unit steps can be used to quantise the memoisation and therefore allow for arbitrary precision. A more complex hash function that allows for mapping based on the first differential of the function being memoised can give scaled memoisation boundaries based on the maximum value change across an input range - allowing for optimal storage within your acceptable error range.</p><p>To do the simple form of this with our tools we define our hash function and storage object:</p><pre><code class="language-none">	sinhash(fn, val) = hash(val)
	memoDict = Dict()</code></pre><p>Then we call the custom hash memoisation function with our targetfunction, storage object and hash function followed by our inputs to the function.</p><pre><code class="language-none">	ApproximateHashingMemoise(sin, memoDict, sinhash, 0.4)
	ApproximateHashingMemoise(sin, memoDict, sinhash, 0.1)</code></pre><p>The returned value of the function will either be the actual value of calling that function with the inputs, or if a value is found in the storage object for the hash of the function and input then the stored value will be returned. Nice and simple!</p><p>The weakness of this type of quantised memoisation is that the first value passed to it for any given quantisation range will represent the whole range. In some cases where there is a non-uniform access pattern for each quantisation range a value that is outside the commonly accessed part might be less representative than others.</p><p>To combat this problem we can also use a trending memoisation approach. In this approach every time a quantised range is accessed the result is added to a record and once the requisite number of samples has been taken the returned value when a hit is found is the average of all the results for that quantisation range.</p><p>The call to do this is very similiar with the addition of a <code>samplecount</code> input variable and we use a more complex storage object to enable the counting of samples for each element. In the demo below we use a sample count of <code>3</code>:</p><pre><code class="language-none">	trendingArray = []
	for i in 1:5000
	   push!(trendingArray,[0,0.0,0.0]) 
	end

	trendingsinhash(fn, val) = 1+Int64.(round(val*10.0))

	@test TrendingMemoisation(sin, trendingsinhash, trendingArray, 3, 0.5)  == 0.479425538604203
	@test TrendingMemoisation(sin, trendingsinhash, trendingArray, 3, 0.55) == 0.5226872289306592
	@test TrendingMemoisation(sin, trendingsinhash, trendingArray, 3, 0.51) == 0.48817724688290753
	@test TrendingMemoisation(sin, trendingsinhash, trendingArray, 3, 0.59) == 0.5563610229127838
	@test TrendingMemoisation(sin, trendingsinhash, trendingArray, 3, 0.59) == 0.5563610229127838
    </code></pre><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>

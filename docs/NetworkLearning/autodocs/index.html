<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings · NetworkLearning.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>NetworkLearning.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Readme</a></li><li class="current"><a class="toctext" href>Docstrings</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Docstrings</a></li></ul></nav><hr/><div id="topbar"><span>Docstrings</span><a class="fa fa-bars" href="#"></a></div></header><p>Package doesn&#39;t contain Documenter docs.</p><p>Docs automatically generated by juliadocs.org</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.BayesRN" href="#NetworkLearning.BayesRN"><code>NetworkLearning.BayesRN</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Naive-Bayes relational neighbour learner (trainable).  Calculates neighbourhood likelihoods (i.e. given a vertex&#39;s class,  the class distribution in its neighbourhood) and uses the resulting information to compute class estimates for each vertex using a Bayesian approach.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.ClassDistributionRN" href="#NetworkLearning.ClassDistributionRN"><code>NetworkLearning.ClassDistributionRN</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Class-distribution relational neighbour (trainable). Claculates a reference vector (RV) for each class (using the vertex neighbourhood information) and compares vertices to the reference vectors corresponding to each class using a similarity measure.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.ComputableAdjacency" href="#NetworkLearning.ComputableAdjacency"><code>NetworkLearning.ComputableAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type where the adjacency information is represented by a . function <code>f</code> and <code>data</code> on which the function can be applied. The result of <code>f(data)</code> has to be either a matrix or a graph.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.EmptyAdjacency" href="#NetworkLearning.EmptyAdjacency"><code>NetworkLearning.EmptyAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type indicating the lack of any adjacency information.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.GibbsSamplingInferer" href="#NetworkLearning.GibbsSamplingInferer"><code>NetworkLearning.GibbsSamplingInferer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Gibbs sapmpling object. Stores the parameters necessary for the algorithm.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.GraphAdjacency" href="#NetworkLearning.GraphAdjacency"><code>NetworkLearning.GraphAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type where the adjacency information is represented by an <code>AbstractGraph</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.IterativeClassificationInferer" href="#NetworkLearning.IterativeClassificationInferer"><code>NetworkLearning.IterativeClassificationInferer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Iterative classification object. Stores the parameters necessary for the algorithm.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.MatrixAdjacency" href="#NetworkLearning.MatrixAdjacency"><code>NetworkLearning.MatrixAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type where the adjacency information is represented by an <code>AbstractMatrix</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.NetworkLearnerEnt" href="#NetworkLearning.NetworkLearnerEnt"><code>NetworkLearning.NetworkLearnerEnt</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Entity-based network learning model type.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.NetworkLearnerObs" href="#NetworkLearning.NetworkLearnerObs"><code>NetworkLearning.NetworkLearnerObs</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Observation-based network learning model type.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.PartialAdjacency" href="#NetworkLearning.PartialAdjacency"><code>NetworkLearning.PartialAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type where the adjacency information is represented by a function <code>f</code> which can be used to calculate an adjacency matrix or graph,  given proper data.&quot;</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.RelaxationLabelingInferer" href="#NetworkLearning.RelaxationLabelingInferer"><code>NetworkLearning.RelaxationLabelingInferer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Relaxation labeling object. Stores the parameters necessary for the algorithm.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.SimpleRN" href="#NetworkLearning.SimpleRN"><code>NetworkLearning.SimpleRN</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Simple relational neighbour learner. Counts for  each vertex how many neighbours from each class are in its neighbourhood.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.WeightedRN" href="#NetworkLearning.WeightedRN"><code>NetworkLearning.WeightedRN</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Weighted relational neighbour learner. For each vertex, it sums up the estimates from neighboring vertices. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.add_adjacency!-Union{Tuple{T}, Tuple{M}, Tuple{M,Array{T,1}}} where T&lt;:AbstractAdjacency where M&lt;:NetworkLearnerObs" href="#NetworkLearning.add_adjacency!-Union{Tuple{T}, Tuple{M}, Tuple{M,Array{T,1}}} where T&lt;:AbstractAdjacency where M&lt;:NetworkLearnerObs"><code>NetworkLearning.add_adjacency!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">add_adjacency!(model, Av)</code></pre><p>Function that adds or, creates and then adds, adjacency objects contained in a vector <code>Av</code> to a network  learning <code>model</code>. The method is used in &#39;ouf-of-graph&#39; learning i.e. the training data is not used in  the predictions for new samples. In such circumstances, the adjacency structures - graphs, matrices etc.  pertinent to the new observations have to be created either using the same functions used in training or,  separately supplied, so that relational variables can be created.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.adjacency-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractAdjacency" href="#NetworkLearning.adjacency-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractAdjacency"><code>NetworkLearning.adjacency</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">adjacency([a,data])</code></pre><p>Constructs an adjacency object. If <code>a</code> is a <code>AbstractMatrix</code>, <code>AbstractGraph</code> or  <code>Tuple</code>, it will return usable adjacencies. If <code>a</code> is a <code>Function</code> or <code>PartialAdjacency</code>, <code>data</code> has to be present. If both arguments are missing,  the function returns an <code>EmptyAdjacency</code>.</p><p><strong>Examples</strong></p><pre><code class="language-none">julia&gt; using NetworkLearning, LightGraphs

julia&gt; A = [0 1 0; 1 0 0; 0 0 0];

julia&gt; Am = adjacency(A)
Matrix adjacency, 3 obs

julia&gt; Ag = adjacency(Graph(A))
Graph adjacency, 3 obs

julia&gt; Ac = adjacency(x-&gt;x,A)
Computable adjacency</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.adjacency_graph-Union{Tuple{MatrixAdjacency{T}}, Tuple{T}} where T&lt;:(AbstractArray{T,2} where T)" href="#NetworkLearning.adjacency_graph-Union{Tuple{MatrixAdjacency{T}}, Tuple{T}} where T&lt;:(AbstractArray{T,2} where T)"><code>NetworkLearning.adjacency_graph</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">adjacency_graph(a)</code></pre><p>Returns an adjacency graph computed from the adjacency information of <code>a</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.adjacency_matrix-Union{Tuple{MatrixAdjacency{T}}, Tuple{T}} where T&lt;:(AbstractArray{T,2} where T)" href="#NetworkLearning.adjacency_matrix-Union{Tuple{MatrixAdjacency{T}}, Tuple{T}} where T&lt;:(AbstractArray{T,2} where T)"><code>NetworkLearning.adjacency_matrix</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">adjacency_matrix(a)</code></pre><p>Returns an adjacency matrix computed from the adjacency information of <code>a</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.adjacency_obs-Tuple{AbstractArray{T,2} where T,UnitRange,LearnBase.ObsDim.Constant{2}}" href="#NetworkLearning.adjacency_obs-Tuple{AbstractArray{T,2} where T,UnitRange,LearnBase.ObsDim.Constant{2}}"><code>NetworkLearning.adjacency_obs</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">adjacency_obs(A, r, obsdim)</code></pre><p>Selects a range <code>r::UnitRange</code> of observations from the matrix <code>A</code>, along the dimension <code>obsdim::LearnBase.ObsDimension</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.fit-Tuple{Type{NetworkLearnerEnt},AbstractArray{T,2} where T,BitArray{1},Array{#s1596,1} where #s1596&lt;:AbstractAdjacency,Any,Any}" href="#NetworkLearning.fit-Tuple{Type{NetworkLearnerEnt},AbstractArray{T,2} where T,BitArray{1},Array{#s1596,1} where #s1596&lt;:AbstractAdjacency,Any,Any}"><code>NetworkLearning.fit</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">fit(::Type{NetworkLearnerEnt}, X, update, Adj, fl_train, fl_exec, fr_train, fr_exec [;kwargs])</code></pre><p>Training method for the entity-based network learning framework.</p><p><strong>Arguments</strong></p><ul><li><code>Xo::AbstractMatrix</code> initial estimates for the entities</li><li><code>update::BitVector</code> mask that indicates wether estimates can be updated (<code>true</code> value) or not (<code>false</code> value); false values </li></ul><p>generally can be associated with estimates of training samples</p><ul><li><code>Adj::Vector{AbstractAdjacency}</code> a vector containing the entity relational structures (adjacency objects)</li><li><code>fr_train</code> relational model training <code>function</code>; can be anything that suports the call <code>fr_train((Xr,y))</code> where <code>y = f_targets(Xo)</code> </li><li><code>fr_exec</code> relational model prediction <code>function</code>; can be anything that suports the call <code>fr_exec(Mr,Xr)</code> where <code>Mr = fr_train((Xr,y))</code></li></ul><p>and <code>Xr</code> is a dataset of relational variables generated by the relational learner using the estimates <code>Xo</code> and the  adjacency structures.</p><p><strong>Keyword arguments</strong></p><ul><li><code>priors::Vector{Float64}</code> class priors (if applicable)</li><li><code>learner::Symbol</code> relational learner (i.e. variable generator); available options <code>:rn</code>, <code>:wrn</code>, <code>:bayesrn</code> and <code>:cdrn</code> (default <code>:wrn</code>)</li><li><code>inference::Symbol</code> collective inference method; available options <code>:rl</code>, <code>:ic</code> and <code>:gs</code> (default <code>:rl</code>)</li><li><code>normalize::Bool</code> whether to normalize the relational variables per-entity to the L1 norm (default <code>true</code>)</li><li><code>f_targets::Function</code> function that extracts targets from estimates generated by the local/relational models </li></ul><p>(default <code>f_targets = x-&gt;MLDataPattern.targets(indmax,x)</code>)</p><ul><li><code>obsdim::Int</code> observation dimension (default <code>2</code>)</li><li><code>tol::Float64</code> maximum admissible mean estimate error for collective inference convergence (default <code>1e-6</code>)</li><li><code>κ::Float64</code> relaxation labeling starting constant, used if <code>learner == :rl</code> (default <code>1.0</code>)</li><li><code>α::Float64</code> relaxation labeling decay constant, used if <code>learner == :rl</code> (default <code>0.99</code>)</li><li><code>maxiter::Int</code> maximum number of iterations for collective inference (default <code>100</code>)</li><li><code>bratio::Float64</code> percentage of iterations i.e. <code>maxiter</code> used for Gibbs sampling burn-in (default <code>0.1</code>)</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.fit-Tuple{Type{NetworkLearnerObs},AbstractArray{T,2} where T,AbstractArray,Array{#s1596,1} where #s1596&lt;:AbstractAdjacency,Any,Any,Any,Any}" href="#NetworkLearning.fit-Tuple{Type{NetworkLearnerObs},AbstractArray{T,2} where T,AbstractArray,Array{#s1596,1} where #s1596&lt;:AbstractAdjacency,Any,Any,Any,Any}"><code>NetworkLearning.fit</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">fit(::Type{NetworkLearnerObs}, X, y, Adj, fl_train, fl_exec, fr_train, fr_exec [;kwargs])</code></pre><p>Training method for the observation-based network learning framework.</p><p><strong>Arguments</strong></p><ul><li><code>X::AbstractMatrix</code> training data (used by <code>fl_train</code>, <code>fl_exec</code>; if <code>use_local_data==true</code>, it is also used by <code>fr_train</code>)</li><li><code>Y::AbstractAray</code> data targets (used by <code>fl_train</code>, <code>fr_train</code>)</li><li><code>Adj::Vector{AbstractAdjacency}</code> a vector containing the observation relational structures (adjacency objects)</li><li><code>fl_train</code> local model training &#39;function&#39;; can be anything that supports the call <code>fl_train((X,y))</code></li><li><code>fl_exec</code> local model prediction &#39;function&#39;; can be anything that supports the call <code>fl_exec(Ml,X)</code> where <code>Ml = fl_train((X,y))</code></li><li><code>fr_train</code> relational model training <code>function</code>; can be anything that suports the call <code>fr_train((Xr,y))</code> </li><li><code>fr_exec</code> relational model prediction <code>function</code>; can be anything that suports the call <code>fr_exec(Mr,Xr)</code> where <code>Mr = fr_train((Xr,y))</code></li></ul><p>and <code>Xr</code> is a dataset of relational variables generated by the relational learner using the results of the local model prediction   function and adjacency structures.</p><p><strong>Keyword arguments</strong></p><ul><li><code>priors::Vector{Float64}</code> class priors (if applicable)</li><li><code>learner::Symbol</code> relational learner (i.e. variable generator); available options <code>:rn</code>, <code>:wrn</code>, <code>:bayesrn</code> and <code>:cdrn</code> (default <code>:wrn</code>)</li><li><code>inference::Symbol</code> collective inference method; available options <code>:rl</code>, <code>:ic</code> and <code>:gs</code> (default <code>:rl</code>)</li><li><code>normalize::Bool</code> whether to normalize the relational variables per-observation to the L1 norm (default <code>true</code>)</li><li><code>use_local_data::Bool</code> whether the relational model should use the local data provided (i.e. in <code>X</code>) (default <code>true</code>)</li><li><code>f_targets::Function</code> function that extracts targets from estimates generated by the local/relational models </li></ul><p>(default <code>f_targets = x-&gt;MLDataPattern.targets(indmax,x)</code>)</p><ul><li><code>obsdim::Int</code> observation dimension (default <code>2</code>)</li><li><code>tol::Float64</code> maximum admissible mean estimate error for collective inference convergence (default <code>1e-6</code>)</li><li><code>κ::Float64</code> relaxation labeling starting constant, used if <code>learner == :rl</code> (default <code>1.0</code>)</li><li><code>α::Float64</code> relaxation labeling decay constant, used if <code>learner == :rl</code> (default <code>0.99</code>)</li><li><code>maxiter::Int</code> maximum number of iterations for collective inference (default <code>100</code>)</li><li><code>bratio::Float64</code> percentage of iterations i.e. <code>maxiter</code> used for Gibbs sampling burn-in (default <code>0.1</code>)</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.fit-Union{Tuple{U2}, Tuple{U}, Tuple{C}, Tuple{R}, Tuple{A}, Tuple{T}, Tuple{Type{NetworkLearnerEnt},T,BitArray{1},A,R,C,U,U2}} where U2 where U where C&lt;:AbstractCollectiveInferer where R&lt;:(Type{#s1589} where #s1589&lt;:AbstractRelationalLearner) where A&lt;:(Array{#s1590,1} where #s1590&lt;:AbstractAdjacency) where T&lt;:(AbstractArray{T,2} where T)" href="#NetworkLearning.fit-Union{Tuple{U2}, Tuple{U}, Tuple{C}, Tuple{R}, Tuple{A}, Tuple{T}, Tuple{Type{NetworkLearnerEnt},T,BitArray{1},A,R,C,U,U2}} where U2 where U where C&lt;:AbstractCollectiveInferer where R&lt;:(Type{#s1589} where #s1589&lt;:AbstractRelationalLearner) where A&lt;:(Array{#s1590,1} where #s1590&lt;:AbstractAdjacency) where T&lt;:(AbstractArray{T,2} where T)"><code>NetworkLearning.fit</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Training method for the network learning framework. This method should not be called directly.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.fit-Union{Tuple{U4}, Tuple{U3}, Tuple{U2}, Tuple{U}, Tuple{C}, Tuple{R}, Tuple{A}, Tuple{S}, Tuple{T}, Tuple{Type{NetworkLearnerObs},T,S,A,R,C,U,U2,U3,U4}} where U4 where U3 where U2 where U where C&lt;:AbstractCollectiveInferer where R&lt;:(Type{#s1586} where #s1586&lt;:AbstractRelationalLearner) where A&lt;:(Array{#s1587,1} where #s1587&lt;:AbstractAdjacency) where S&lt;:AbstractArray where T&lt;:(AbstractArray{T,2} where T)" href="#NetworkLearning.fit-Union{Tuple{U4}, Tuple{U3}, Tuple{U2}, Tuple{U}, Tuple{C}, Tuple{R}, Tuple{A}, Tuple{S}, Tuple{T}, Tuple{Type{NetworkLearnerObs},T,S,A,R,C,U,U2,U3,U4}} where U4 where U3 where U2 where U where C&lt;:AbstractCollectiveInferer where R&lt;:(Type{#s1586} where #s1586&lt;:AbstractRelationalLearner) where A&lt;:(Array{#s1587,1} where #s1587&lt;:AbstractAdjacency) where S&lt;:AbstractArray where T&lt;:(AbstractArray{T,2} where T)"><code>NetworkLearning.fit</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Training method for the network learning framework. This method should not be called directly.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.infer!-Union{Tuple{T}, Tuple{T}} where T&lt;:NetworkLearnerEnt" href="#NetworkLearning.infer!-Union{Tuple{T}, Tuple{T}} where T&lt;:NetworkLearnerEnt"><code>NetworkLearning.infer!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Function that calls collective inference using the information in contained in the entity-based network learner</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.intdim-Tuple{LearnBase.ObsDim.Constant{1}}" href="#NetworkLearning.intdim-Tuple{LearnBase.ObsDim.Constant{1}}"><code>NetworkLearning.intdim</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">intdim(::LearnBase.ObsDimension)</code></pre><p>Returns the integer associated to a dimension object  i.e. <code>intdim(ObsDim.Constant{3})</code>  returns <code>3</code>.  The function is designed to work on matices so  <code>intdim(::ObsDim.Last)</code> will return <code>2</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.matrix_prealloc-Union{Tuple{O}, Tuple{T}, Tuple{Int64,Int64,O}, Tuple{Int64,Int64,O,T}} where O&lt;:LearnBase.ObsDimension where T" href="#NetworkLearning.matrix_prealloc-Union{Tuple{O}, Tuple{T}, Tuple{Int64,Int64,O}, Tuple{Int64,Int64,O,T}} where O&lt;:LearnBase.ObsDimension where T"><code>NetworkLearning.matrix_prealloc</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">matrix_prealloc(no, nv, obsdim, val)</code></pre><p>Returns a <code>Matrix{T}</code> filled with values equal to <code>val::T</code>, having the size <code>no</code> (number of observations) on dimension <code>obsdim</code> and  <code>nv</code> (number of variables) in the other dimension.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.oppdim-Tuple{LearnBase.ObsDim.Constant{1}}" href="#NetworkLearning.oppdim-Tuple{LearnBase.ObsDim.Constant{1}}"><code>NetworkLearning.oppdim</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">oppdim(::LearnBase.ObsDimension)</code></pre><p>Returns the other dimension for a matrix i.e. if provided <code>ObsDim.Constant{1}</code>  returns <code>ObsDim.Constant{2}</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.predict!-Union{Tuple{S}, Tuple{T}, Tuple{M}, Tuple{S,M,T}, Tuple{S,M,T,BitArray{1}}} where S&lt;:(AbstractArray{T,2} where T) where T&lt;:(AbstractArray{T,2} where T) where M&lt;:NetworkLearnerObs" href="#NetworkLearning.predict!-Union{Tuple{S}, Tuple{T}, Tuple{M}, Tuple{S,M,T}, Tuple{S,M,T,BitArray{1}}} where S&lt;:(AbstractArray{T,2} where T) where T&lt;:(AbstractArray{T,2} where T) where M&lt;:NetworkLearnerObs"><code>NetworkLearning.predict!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>In-place prediction method for the network learning framework.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.predict-Union{Tuple{T}, Tuple{M}, Tuple{M,T}, Tuple{M,T,BitArray{1}}} where T&lt;:(AbstractArray{T,2} where T) where M&lt;:NetworkLearnerObs" href="#NetworkLearning.predict-Union{Tuple{T}, Tuple{M}, Tuple{M,T}, Tuple{M,T,BitArray{1}}} where T&lt;:(AbstractArray{T,2} where T) where M&lt;:NetworkLearnerObs"><code>NetworkLearning.predict</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Prediction method for the network learning framework.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.strip_adjacency-Union{Tuple{MatrixAdjacency{T}}, Tuple{T}} where T&lt;:(AbstractArray{T,2} where T)" href="#NetworkLearning.strip_adjacency-Union{Tuple{MatrixAdjacency{T}}, Tuple{T}} where T&lt;:(AbstractArray{T,2} where T)"><code>NetworkLearning.strip_adjacency</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">strip_adjacency(a)</code></pre><p>Function that removes adjancency information (i.e. matrix, graph or other data) from adjacency objects and returns a <code>PartialAdjacency</code> that can be used in conjunction with the <code>adjacency</code> function to build a new adjacency object.</p><p><strong>Examples</strong></p><pre><code class="language-none">julia&gt; using NetworkLearning, LightGraphs

julia&gt; A = [0 1 0; 1 0 0; 0 0 0];

julia&gt; Am = adjacency(A)
Matrix adjacency, 3 obs

julia&gt; Ac = adjacency(x-&gt;x,A)
Computable adjacency

julia&gt; Sm = strip_adjacency(Am)
Partial adjacency, not computable

julia&gt; adjacency(Sm, A) # Sm has to be used with a matrix
Matrix adjacency, 3 obs

julia&gt; Sc = strip_adjacency(Ac)
Partial adjacency, not computable

julia&gt; adjacency(Sc, A) # Sc can be use with any data; calls f(A) where f = x-&gt;x
Matrix adjacency, 3 obs</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.update_adjacency!-Union{Tuple{T}, Tuple{MatrixAdjacency{T},Any}} where T&lt;:(AbstractArray{T,2} where T)" href="#NetworkLearning.update_adjacency!-Union{Tuple{T}, Tuple{MatrixAdjacency{T},Any}} where T&lt;:(AbstractArray{T,2} where T)"><code>NetworkLearning.update_adjacency!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">update_adjacency!(a,f_update)</code></pre><p>Function that updates the data of an adjacency object. <code>a</code> has to be a <code>MatrixAdjacency</code> or  <code>GraphAdjacency</code> while <code>f_update</code> has to of the form <code>f_update = x-&gt;update_function!(x)</code>.</p><p><strong>Examples</strong></p><p>julia&gt; using NetworkLearning, LightGraphs</p><p>julia&gt; A = [0 1 0; 1 0 0; 0 0 0];</p><p>julia&gt; Am = adjacency(A) Matrix adjacency, 3 obs</p><p>julia&gt; update<em>function!(X,x,y) = begin          X[x,y] += 1          X[y,x] += 1          return X        end update</em>function! (generic function with 2 methods)</p><p>julia&gt; f<em>update(x,y) = X-&gt;update</em>function!(X,x,y) f_update (generic function with 1 method)</p><p>julia&gt; for i in 1:3          update<em>adjacency!(Am, f</em>update(1,3)) # call function three times        end</p><p>julia&gt; adjacency_matrix(Am) 3×3 Array{Int64,2}:  0  1  3  1  0  0  3  0  0</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.NetworkLearnerState" href="#NetworkLearning.NetworkLearnerState"><code>NetworkLearning.NetworkLearnerState</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Entity-based network learning model state. It consists of an <code>Array</code> with estimates and a an update mask in the form of a <code>BitVector</code> indicating which observation estimates are to be updated (the ones that are not updated are considered training/stable observations).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.nvars-Tuple{Any,Any}" href="#NetworkLearning.nvars-Tuple{Any,Any}"><code>NetworkLearning.nvars</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns the number of variables given a data object which  supports the <code>nobs</code> function. The data object must ideally  present two dimensions i.e. matrix.</p></div></div></section><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Readme</span></a></footer></article></body></html>

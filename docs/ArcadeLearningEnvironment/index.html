<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme Â· ArcadeLearningEnvironment.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>ArcadeLearningEnvironment.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Citation-1">Citation</a></li><li><a class="toctext" href="#Installation-1">Installation</a></li><li><a class="toctext" href="#Example-1">Example</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><p><a href="https://travis-ci.com/JuliaReinforcementLearning/ArcadeLearningEnvironment.jl"><img src="https://travis-ci.com/JuliaReinforcementLearning/ReinforcementLearning.jl.svg?branch=master" alt="Build Status"/></a> <a href="https://codecov.io/gh/JuliaReinforcementLearning/ArcadeLearningEnvironment.jl"><img src="https://codecov.io/gh/JuliaReinforcementLearning/ReinforcementLearning.jl/branch/master/graph/badge.svg" alt="codecov"/></a></p><h1><a class="nav-anchor" id="ArcadeLearningEnvironment.jl-1" href="#ArcadeLearningEnvironment.jl-1">ArcadeLearningEnvironment.jl</a></h1><p>This package is a <a href="http://julialang.org/">Julia</a> wrapper for the <a href="https://github.com/mgbellemare/Arcade-Learning-Environment">ArcadeLearningEnvironment</a> (ALE).</p><p>ALE is a modified emulator for the Atari 2600 that can emulate around 50 games with additional access to game state information and in-game rewards. This is useful for learning and benchmarking artificial intelligence agents playing computer games.</p><h2><a class="nav-anchor" id="Citation-1" href="#Citation-1">Citation</a></h2><p>If you use this package for research publications, please cite the following paper to acknowledge the work that went into ALE.</p><pre><code class="language-none">@ARTICLE{bellemare13arcade,
	author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
	title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
	journal = {Journal of Artificial Intelligence Research},
	year = 2013,
	month = 06,
	volume = 47,
	pages = {253--279}
}</code></pre><h2><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h2><p>On Mac OS and Linux the package automatically downloads and builds version 0.6.0 of the ArcadeLearningEnvironment by adding it in julia 0.6 with</p><pre><code class="language-julia">Pkg.add(&quot;ArcadeLearningEnvironment&quot;)</code></pre><p>or in the package REPL of julia 0.7.0 with</p><pre><code class="language-julia">add ArcadeLearningEnvironment</code></pre><p>On Windows (which I have not tried yet) you can build the <code>libale_c.dll</code> file manually and set the <code>LIBALE_HOME</code> environment variable to the directory containing this file.  Then, the above two commands should work as well.  Note that this is untested and any correction or feedback is welcome.</p><h2><a class="nav-anchor" id="Example-1" href="#Example-1">Example</a></h2><pre><code class="language-julia">using ArcadeLearningEnvironment


episodes = 50

ale = ALE_new()
loadROM(ale, &quot;seaquest&quot;)

S = zeros(Int64, episodes)
TR = zeros(episodes)
for ei = 1:episodes
    ctr = 0.0

    fc = 0
    while game_over(ale) == false
        actions = getLegalActionSet(ale)
        ctr += act(ale, actions[rand(1:length(actions))])
        fc += 1
    end
    reset_game(ale)
    println(&quot;Game $ei ended after $fc frames with total reward $(ctr).&quot;)

    S[ei] = fc
    TR[ei] = ctr
end
ALE_del(ale)</code></pre><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>

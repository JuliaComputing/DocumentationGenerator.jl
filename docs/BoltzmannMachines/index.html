<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · BoltzmannMachines.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>BoltzmannMachines.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Home</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Home</a></li></ul></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><p>Package doesn&#39;t contain Documenter docs.</p><p>Docs automatically generated by juliadocs.org</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.AbstractOptimizer" href="#BoltzmannMachines.AbstractOptimizer"><code>BoltzmannMachines.AbstractOptimizer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>The <code>AbstractOptimizer</code> interface allows to specify optimization procedures. It consists of three methods:</p><ul><li><code>initialized(optimizer, bm)</code>: May be used for creating an optimizer that is  specifically initialized for the Boltzmann machine <code>bm</code>.  In particular it may be used to allocate reusable space for the gradient.  The default implementation simply returns the unmodified <code>optimizer</code>.</li><li><code>computegradient!(optimizer, v, vmodel, h, hmodel, rbm)</code> or <code>computegradient!(optimizer, meanfieldparticles, gibbsparticles, dbm)</code>  needs to be implemented for computing the gradient given the samples  from the positive and negative phase.</li><li><code>updateparameters!(bm, optimizer)</code> needs to be specified for taking the  gradient step. The default implementation for RBMs expects the fields  <code>learningrate</code> and <code>gradient</code> and adds <code>learningrate * gradient</code> to the  given RBM.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.AbstractRBM" href="#BoltzmannMachines.AbstractRBM"><code>BoltzmannMachines.AbstractRBM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Abstract supertype for all RBMs </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.AbstractTrainLayer" href="#BoltzmannMachines.AbstractTrainLayer"><code>BoltzmannMachines.AbstractTrainLayer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Abstract supertype for layerwise training specification. May be specifications for a normal RBM layer (see <code>TrainLayer</code>) or multiple combined specifications for a partitioned layer (see <code>TrainPartitionedLayer</code>).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.BernoulliGaussianRBM" href="#BoltzmannMachines.BernoulliGaussianRBM"><code>BoltzmannMachines.BernoulliGaussianRBM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">BernoulliGaussianRBM(weights, visbias, hidbias)</code></pre><p>Encapsulates the parameters of an RBM with Bernoulli distributed visible nodes and Gaussian distributed hidden nodes. The standard deviation of the Gaussian distribution is 1.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.BernoulliRBM" href="#BoltzmannMachines.BernoulliRBM"><code>BoltzmannMachines.BernoulliRBM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">BernoulliRBM(weights, visbias, hidbias)</code></pre><p>Encapsulates the parameters of an RBM with Bernoulli distributed nodes.</p><ul><li><code>weights</code>: matrix of weights with size (number of visible nodes, number of hidden nodes)</li><li><code>visbias</code>: bias vector for visible nodes</li><li><code>hidbias</code>: bias vector for hidden nodes</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.Binomial2BernoulliRBM" href="#BoltzmannMachines.Binomial2BernoulliRBM"><code>BoltzmannMachines.Binomial2BernoulliRBM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Binomial2BernoulliRBM(weights, visbias, hidbias)</code></pre><p>Encapsulates the parameters of an RBM with 0/1/2-valued, Binomial (n=2) distributed visible nodes, and Bernoulli distributed hidden nodes. This model is equivalent to a BernoulliRBM in which every two visible nodes are connected with the same weights to each hidden node. The states (0,0) / (1,0) / (0,1) / (1,1) of the visible nodes connected with with the same weights translate as states 0 / 1 / 1 / 2 in the Binomial2BernoulliRBM.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.DataDict" href="#BoltzmannMachines.DataDict"><code>BoltzmannMachines.DataDict</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A dictionary containing names of data sets as keys and the data sets (matrices with samples in rows) as values.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.GaussianBernoulliRBM" href="#BoltzmannMachines.GaussianBernoulliRBM"><code>BoltzmannMachines.GaussianBernoulliRBM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">GaussianBernoulliRBM(weights, visbias, hidbias, sd)</code></pre><p>Encapsulates the parameters of an RBM with Gaussian distributed visible nodes and Bernoulli distributed hidden nodes.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.GaussianBernoulliRBM2" href="#BoltzmannMachines.GaussianBernoulliRBM2"><code>BoltzmannMachines.GaussianBernoulliRBM2</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">GaussianBernoulliRBM2(weights, visbias, hidbias, sd)</code></pre><p>Encapsulates the parameters of an RBM with Gaussian distributed visible nodes and Bernoulli distributed hidden nodes with the alternative energy formula proposed by KyungHyun Cho.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.LoglikelihoodOptimizer" href="#BoltzmannMachines.LoglikelihoodOptimizer"><code>BoltzmannMachines.LoglikelihoodOptimizer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Implements the <code>AbstractOptimizer</code> interface for optimizing the loglikelihood with stochastic gradient descent.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.Monitor" href="#BoltzmannMachines.Monitor"><code>BoltzmannMachines.Monitor</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A vector for collecting <code>MonitoringItem</code>s during training.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.MonitoringItem" href="#BoltzmannMachines.MonitoringItem"><code>BoltzmannMachines.MonitoringItem</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Encapsulates the value of an evaluation calculated in one training epoch. If the evaluation depends on a dataset, the dataset&#39;s name can be specified also.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.Particles" href="#BoltzmannMachines.Particles"><code>BoltzmannMachines.Particles</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p><code>Particles</code> are an array of matrices. The i&#39;th matrix contains in each row the vector of states of the nodes of the i&#39;th layer of an RBM or a DBM. The set of rows with the same index define an activation state in a Boltzmann Machine. Therefore, the size of the i&#39;th matrix is (number of samples/particles, number of nodes in layer i).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.PartitionedRBM" href="#BoltzmannMachines.PartitionedRBM"><code>BoltzmannMachines.PartitionedRBM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">PartitionedRBM(rbms)</code></pre><p>Encapsulates several (parallel) AbstractRBMs that form one partitioned RBM. The nodes of the parallel RBMs are not connected between the RBMs.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.TrainLayer-Tuple{}" href="#BoltzmannMachines.TrainLayer-Tuple{}"><code>BoltzmannMachines.TrainLayer</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Specify parameters for training one RBM-layer in a DBM.</p><p><strong>Optional keyword arguments:</strong></p><ul><li>The optional keyword arguments <code>rbmtype</code>, <code>nhidden</code>, <code>epochs</code>, <code>learningrate</code>/<code>learningrates</code>, <code>sdlearningrate</code>/<code>sdlearningrates</code>, <code>batchsize</code>, <code>pcd</code>, <code>cdsteps</code>, <code>startrbm</code> and <code>optimizer</code>/<code>optimizers</code> are passed to <code>fitrbm</code>. For a detailed description, see there. If a negative value is specified for <code>learningrate</code> or <code>epochs</code>, this indicates that a corresponding default value should be used (parameter defined by call to <code>stackrbms</code>).</li><li><code>monitoring</code>: also like in <code>fitrbm</code>, but may take a <code>DataDict</code> as third argument  (see function <code>stackrbms</code> and its argument <code>monitoringdata</code>).</li><li><code>nvisible</code>: Number of visible units in the RBM. Only relevant for partitioning.  This parameter is derived as much as possible by <code>stackrbms</code>.  For <code>MultimodalDBM</code>s with a partitioned first layer, it is necessary to specify  the number of visible nodes for all but at most one partition in the input layer.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.TrainPartitionedLayer" href="#BoltzmannMachines.TrainPartitionedLayer"><code>BoltzmannMachines.TrainPartitionedLayer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Encapsulates a vector of <code>TrainLayer</code> objects for training a partitioned layer.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.addlayer!-Tuple{Array{BernoulliRBM,1},Array{Float64,2}}" href="#BoltzmannMachines.addlayer!-Tuple{Array{BernoulliRBM,1},Array{Float64,2}}"><code>BoltzmannMachines.addlayer!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">addlayer!(dbm, x)</code></pre><p>Adds a pretrained layer to the BasicDBM <code>dbm</code>, given the dataset <code>x</code> as input for the visible layer of the <code>dbm</code>.</p><p><strong>Optional keyword arguments:</strong></p><ul><li><code>isfirst</code>, <code>islast</code>: indicating that the new RBM should be trained as  first (assumed if <code>dbm</code> is empty) or last layer of the DBM, respectively.  If those flags are not set, the added layer is trained as intermediate layer.  This information is needed to determine the factor for the weights during  pretraining.</li><li><code>epochs</code>, <code>nhidden</code>, <code>learningrate</code>/<code>learningrates</code>, <code>pcd</code>, <code>cdsteps</code>, <code>monitoring</code>: used for fitting the weights of the last layer, see <code>fitrbm(x)</code></li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.aislogimpweights-Tuple{Array{#s1708,1} where #s1708&lt;:Union{BernoulliRBM, PartitionedRBM{BernoulliRBM}}}" href="#BoltzmannMachines.aislogimpweights-Tuple{Array{#s1708,1} where #s1708&lt;:Union{BernoulliRBM, PartitionedRBM{BernoulliRBM}}}"><code>BoltzmannMachines.aislogimpweights</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">aislogimpweights(dbm; ...)</code></pre><p>Computes the logarithmised importance weights in the Annealed Importance Sampling algorithm (AIS) for estimating the ratio of the partition functions of the given DBM <code>dbm</code> to the base-rate DBM with all weights being zero and all biases equal to the biases of the <code>dbm</code>.</p><p>Implements algorithm 4 in [Salakhutdinov+Hinton, 2012]. For DBMs with Bernoulli-distributed nodes only (i. e. here DBMs of type <code>PartitionedBernoulliDBM</code>), it is possible to calculate the importance weights by summing out either the even layers (h1, h3, ...) or the odd layers (v, h2, h4, ...). In the first case, the nodes&#39; activations in the odd layers are used to calculate the probability ratios, in the second case the even layer are used. If <code>dbm</code> is of type <code>PartitionedBernoulliDBM</code>, the optional keyword argument <code>sumout</code> can be used to choose by specifying the values <code>:odd</code> (default) or <code>:even</code>. In the case of <code>MultimodalDBM</code>s, it is not possible to choose and the second case applies there.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.aislogimpweights-Tuple{BoltzmannMachines.AbstractXBernoulliRBM}" href="#BoltzmannMachines.aislogimpweights-Tuple{BoltzmannMachines.AbstractXBernoulliRBM}"><code>BoltzmannMachines.aislogimpweights</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">aislogimpweights(rbm; ...)</code></pre><p>Computes the logarithmised importance weights for estimating the ratio of the partition functions of the given <code>rbm</code> to the RBM with zero weights, but same visible and hidden bias as the <code>rbm</code>. This function implements the Annealed Importance Sampling algorithm (AIS) like described in section 4.1.3 of [Salakhutdinov, 2008].</p><p><strong>Optional keyword arguments (for all types of Boltzmann Machines):</strong></p><ul><li><code>ntemperatures</code>: Number of temperatures for annealing from the starting model to the target model, defaults to 100</li><li><code>temperatures</code>: Vector of temperatures. By default <code>ntemperatures</code> ascending numbers, equally spaced from 0.0 to 1.0</li><li><code>nparticles</code>: Number of parallel chains and calculated weights, defaults to  100</li><li><code>burnin</code>: Number of steps to sample for the Gibbs transition between models</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.aislogimpweights-Union{Tuple{R}, Tuple{R,R}} where R&lt;:AbstractRBM" href="#BoltzmannMachines.aislogimpweights-Union{Tuple{R}, Tuple{R,R}} where R&lt;:AbstractRBM"><code>BoltzmannMachines.aislogimpweights</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">aislogimpweights(rbm1, rbm2; ...)</code></pre><p>Computes the logarithmised importance weights for estimating the log-ratio log(Z2/Z1) for the partition functions Z1 and Z2 of <code>rbm1</code> and <code>rbm2</code>, respectively. Implements the procedure described in section 4.1.2 of [Salakhutdinov, 2008]. This requires that <code>rbm1</code> and <code>rbm2</code> are of the same type and have the same number of visible units.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.aisprecision" href="#BoltzmannMachines.aisprecision"><code>BoltzmannMachines.aisprecision</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">aisprecision(logr, aissd, sdrange)</code></pre><p>Returns the differences of the estimated logratio <code>r</code> to the lower and upper bound of the range defined by the multiple <code>sdrange</code> of the standard deviation of the ratio&#39;s estimator <code>aissd</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.aisprecision" href="#BoltzmannMachines.aisprecision"><code>BoltzmannMachines.aisprecision</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">aisprecision(logimpweights, sdrange)</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.aisstandarddeviation-Tuple{Array{Float64,1}}" href="#BoltzmannMachines.aisstandarddeviation-Tuple{Array{Float64,1}}"><code>BoltzmannMachines.aisstandarddeviation</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Computes the standard deviation of the AIS estimator (not logarithmised) (eq 4.10 in [Salakhutdinov+Hinton, 2012]) given the logarithmised importance weights.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.barsandstripes-Tuple{Int64,Int64}" href="#BoltzmannMachines.barsandstripes-Tuple{Int64,Int64}"><code>BoltzmannMachines.barsandstripes</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">barsandstripes(nsamples, nvariables)</code></pre><p>Generates a test data set. To see the structure in the data set, run e. g. <code>reshape(barsandstripes(1, 16), 4, 4)</code> a few times.</p><p>Example from: MacKay, D. (2003). Information Theory, Inference, and Learning Algorithms</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.computegradient!-Union{Tuple{R}, Tuple{M2}, Tuple{M1}, Tuple{AbstractLoglikelihoodOptimizer{R},M1,M1,M2,M2,R}} where R&lt;:AbstractRBM where M2&lt;:AbstractArray{Float64,2} where M1&lt;:AbstractArray{Float64,2}" href="#BoltzmannMachines.computegradient!-Union{Tuple{R}, Tuple{M2}, Tuple{M1}, Tuple{AbstractLoglikelihoodOptimizer{R},M1,M1,M2,M2,R}} where R&lt;:AbstractRBM where M2&lt;:AbstractArray{Float64,2} where M1&lt;:AbstractArray{Float64,2}"><code>BoltzmannMachines.computegradient!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">computegradient!(optimizer, v, vmodel, h, hmodel, rbm)</code></pre><p>Computes the gradient of the RBM <code>rbm</code> given the the hidden activation <code>h</code> induced by the sample <code>v</code> and the vectors <code>vmodel</code> and <code>hmodel</code> generated by sampling from the model. The result is stored in the <code>optimizer</code> in such a way that it can be applied by a call to <code>updateparameters!</code>. There is no return value.</p><p>For RBMs (excluding PartitionedRBMs), this means saving the gradient in a RBM of the same type in the field <code>optimizer.gradient</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.crossvalidation-Tuple{Array{Float64,2},Function,Vararg{Any,N} where N}" href="#BoltzmannMachines.crossvalidation-Tuple{Array{Float64,2},Function,Vararg{Any,N} where N}"><code>BoltzmannMachines.crossvalidation</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">crossvalidation(x, monitoredfit; ...)</code></pre><p>Performs k-fold cross-validation, given</p><ul><li>the data set <code>x</code> and</li><li><code>monitoredfit</code>: a function that fits and evaluates a model. As arguments it must accept:<ul><li>a training data data set</li><li>a <code>DataDict</code> containing the evaluation data.</li></ul></li></ul><p>The return values of the calls to the <code>monitoredfit</code> function are concatenated with <code>vcat</code>. If the monitoredfit function returns <code>Monitor</code> objects, <code>crossvalidation</code> returns a combined <code>Monitor</code> object that can be displayed by creating a cross-validation plot via <code>BoltzmannMachinesPlots.crossvalidationplot</code>.</p><p><strong>Optional named argument:</strong></p><ul><li><p><code>kfold</code>: specifies the <code>k</code> in &quot;<code>k</code>-fold&quot; (defaults to 10).</p><p>crossvalidation(x, monitoredfit, pars; ...)</p></li></ul><p>If additionaly a vector of parameters <code>pars</code> is given, <code>monitoredfit</code> also expects an additional parameter from the parameter set.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.empiricalloglikelihood" href="#BoltzmannMachines.empiricalloglikelihood"><code>BoltzmannMachines.empiricalloglikelihood</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">empiricalloglikelihood(x, xgen)
empiricalloglikelihood(bm, x, nparticles)
empiricalloglikelihood(bm, x, nparticles, burnin)</code></pre><p>Computes the mean empirical loglikelihood for the data set <code>x</code>. The probability of a sample is estimated to be the empirical probability of the sample in a dataset generated by the model. This data set can be given as <code>xgen</code> or it is generated by running a Gibbs sampler with <code>nparticles</code> for <code>burnin</code> steps (default 5) in the Boltzmann Machine <code>bm</code>. Throws an error if a sample in <code>x</code> is not contained in the generated data set.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.energy-Tuple{BernoulliRBM,Array{Float64,1},Array{Float64,1}}" href="#BoltzmannMachines.energy-Tuple{BernoulliRBM,Array{Float64,1},Array{Float64,1}}"><code>BoltzmannMachines.energy</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">energy(rbm, v, h)</code></pre><p>Computes the energy of the configuration of the visible nodes <code>v</code> and the hidden nodes <code>h</code>, specified as vectors, in the <code>rbm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.exactloglikelihood" href="#BoltzmannMachines.exactloglikelihood"><code>BoltzmannMachines.exactloglikelihood</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">exactloglikelihood(dbm, x)
exactloglikelihood(dbm, x, logz)</code></pre><p>Computes the mean log-likelihood for the given dataset <code>x</code> and the DBM <code>dbm</code> exactly. If the value of the log of the partition function of the <code>dbm</code> is not supplied as argument <code>logz</code>, it will be computed by <code>exactlogpartitionfunction(dbm)</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.exactloglikelihood" href="#BoltzmannMachines.exactloglikelihood"><code>BoltzmannMachines.exactloglikelihood</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">exactloglikelihood(rbm, x)</code></pre><p>Computes the mean log-likelihood for the given dataset <code>x</code> and the RBM <code>rbm</code> exactly. The log of the partition function is computed exactly by <code>exactlogpartitionfunction(rbm)</code>. Besides that, the function simply calls <code>loglikelihood(rbm, x)</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.exactlogpartitionfunction-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM}" href="#BoltzmannMachines.exactlogpartitionfunction-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM}"><code>BoltzmannMachines.exactlogpartitionfunction</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">exactlogpartitionfunction(mdbm)</code></pre><p>Calculates the log of the partition function of the MultimodalDBM <code>mdbm</code> exactly. The execution time grows exponentially with the total number of nodes in hidden layers with odd indexes (i. e. h1, h3, ...).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.exactlogpartitionfunction-Tuple{Array{#s1708,1} where #s1708&lt;:Union{BernoulliRBM, PartitionedRBM{BernoulliRBM}}}" href="#BoltzmannMachines.exactlogpartitionfunction-Tuple{Array{#s1708,1} where #s1708&lt;:Union{BernoulliRBM, PartitionedRBM{BernoulliRBM}}}"><code>BoltzmannMachines.exactlogpartitionfunction</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">exactlogpartitionfunction(dbm)</code></pre><p>Calculates the log of the partition function of the DBM <code>dbm</code> exactly. If the number of hidden layers is even, the execution time grows exponentially with the total number of nodes in hidden layers with odd indexes (i. e. h1, h3, ...). If the number of hidden layers is odd, the execution time grows exponentially with the minimum of (number of nodes in layers with even index, number of nodes in layers with odd index).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.exactlogpartitionfunction-Tuple{BernoulliGaussianRBM}" href="#BoltzmannMachines.exactlogpartitionfunction-Tuple{BernoulliGaussianRBM}"><code>BoltzmannMachines.exactlogpartitionfunction</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">exactlogpartitionfunction(bgrbm)</code></pre><p>Calculates the log of the partition function of the BernoulliGaussianRBM <code>bgrbm</code> exactly. The execution time grows exponentially with the number of visible nodes.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.exactlogpartitionfunction-Tuple{BernoulliRBM}" href="#BoltzmannMachines.exactlogpartitionfunction-Tuple{BernoulliRBM}"><code>BoltzmannMachines.exactlogpartitionfunction</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">exactlogpartitionfunction(rbm)</code></pre><p>Calculates the log of the partition function of the BernoulliRBM <code>rbm</code> exactly. The execution time grows exponentially with the minimum of (number of visible nodes, number of hidden nodes).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.exactlogpartitionfunction-Tuple{GaussianBernoulliRBM}" href="#BoltzmannMachines.exactlogpartitionfunction-Tuple{GaussianBernoulliRBM}"><code>BoltzmannMachines.exactlogpartitionfunction</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">exactlogpartitionfunction(gbrbm)</code></pre><p>Calculates the log of the partition function of the GaussianBernoulliRBM <code>gbrbm</code> exactly. The execution time grows exponentially with the number of hidden nodes.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.fitdbm-Tuple{Array{Float64,2}}" href="#BoltzmannMachines.fitdbm-Tuple{Array{Float64,2}}"><code>BoltzmannMachines.fitdbm</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">fitdbm(x; ...)</code></pre><p>Fits a (multimodal) DBM to the data set <code>x</code>. The procedure consists of two parts: First a stack of RBMs is pretrained in a greedy layerwise manner (see <code>stackrbms(x)</code>). Then the weights of all layers are jointly trained using the general Boltzmann Machine learning procedure (see <code>traindbm!(dbm,x)</code>).</p><p><strong>Optional keyword arguments (ordered by importance):</strong></p><ul><li><code>nhiddens</code>: vector that defines the number of nodes in the hidden layers of  the DBM. The default value specifies two hidden layers with the same size  as the visible layer.</li><li><code>epochs</code>: number of training epochs for joint training</li><li><code>epochspretraining</code>: number of training epochs for pretraining,  defaults to <code>epochs</code></li><li><code>learningrate</code>/<code>learningrates</code>:  learning rate(s) for joint training of layers (= fine tuning)  using the learning algorithm for a general Boltzmann Machine.  The learning rate for fine tuning is by default decaying with the number of epochs,  starting with the given value for the <code>learningrate</code>.  (For more details see <code>traindbm!</code>).</li><li><code>learningratepretraining</code>: learning rate for pretraining,  defaults to <code>learningrate</code></li><li><code>batchsizepretraining</code>: batchsize for pretraining, defaults to 1</li><li><code>nparticles</code>: number of particles used for sampling during joint training of  DBM, default 100</li><li><code>pretraining</code>: The arguments for layerwise pretraining  can be specified for each layer individually.  This is done via a vector of <code>TrainLayer</code> objects.  (For a detailed description of the possible parameters,  see help for <code>TrainLayer</code>).  If the number of training epochs and the learning rate are not specified  explicitly for a layer, the values of <code>epochspretraining</code>,  <code>learningratepretraining</code> and <code>batchsizepretraining</code> are used.</li><li><code>monitoring</code>: Monitoring function accepting a <code>dbm</code> and the number of epochs  retuning nothing. Used for the monitoring of fine-tuning.</li><li><code>monitoringdatapretraining</code>: a <code>DataDict</code> that contains data used for  monitoring the pretraining (see argument <code>monitoringdata</code> of <code>stackrbms</code>.)</li><li><code>optimizer</code>/<code>optimizers</code>: an optimizer or a vector of optimizers for each epoch  (see <code>AbstractOptimizer</code>) used for fine-tuning.</li><li><code>optimizerpretraining</code>: an optimizer used for pre-training.  Defaults to the <code>optimizer</code>.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.fitrbm-Tuple{Array{Float64,2}}" href="#BoltzmannMachines.fitrbm-Tuple{Array{Float64,2}}"><code>BoltzmannMachines.fitrbm</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">fitrbm(x; ...)</code></pre><p>Fits an RBM model to the data set <code>x</code>, using Stochastic Gradient Descent (SGD) with Contrastive Divergence (CD), and returns it.</p><p><strong>Optional keyword arguments (ordered by importance):</strong></p><ul><li><code>rbmtype</code>: the type of the RBM that is to be trained  This must be a subtype of <code>AbstractRBM</code> and defaults to <code>BernoulliRBM</code>.</li><li><code>nhidden</code>: number of hidden units for the returned RBM</li><li><code>epochs</code>: number of training epochs</li><li><code>learningrate</code>/<code>learningrates</code>: The learning rate for the weights and biases  can be specified as single value, used throughout all epochs, or as a vector  of <code>learningrates</code> that contains a value for each epoch. Defaults to 0.005.</li><li><code>batchsize</code>: number of samples that are used for making one step in the  stochastic gradient descent optimizer algorithm. Default is 1.</li><li><code>pcd</code>: indicating whether Persistent Contrastive Divergence (PCD) is to  be used (true, default) or simple CD that initializes the Gibbs Chain with  the training sample (false)</li><li><code>cdsteps</code>: number of Gibbs sampling steps for (persistent)  contrastive divergence, defaults to 1</li><li><code>monitoring</code>: a function that is executed after each training epoch.  It takes an RBM and the epoch as arguments.</li><li><code>upfactor</code>, <code>downfactor</code>: If this function is used for pretraining a part of  a DBM, it is necessary to multiply the weights of the RBM with factors.</li><li><code>sdlearningrate</code>/<code>sdlearningrates</code>: learning rate(s) for the  standard deviation if training a <code>GaussianBernoulliRBM</code> or  <code>GaussianBernoulliRBM2</code>. Ignored for other types of RBMs.  It usually must be much smaller than the learning rates for  the weights. By default it is 0.0, which means that the standard deviation  is not learned.</li><li><code>startrbm</code>: start training with the parameters of the given RBM.  If this argument is specified, <code>nhidden</code> and <code>rbmtype</code> are ignored.</li><li><code>optimizer</code>/<code>optimizers</code>: an object of type <code>AbstractOptimizer</code> or a vector of  them for each epoch. If specified, the optimization is performed as implemented  by the given optimizer type. By default, the <code>LoglikelihoodOptimizer</code>  with the <code>learningrate</code>/<code>learningrates</code> and <code>sdlearningrate</code>/<code>sdlearningrates</code>  is used. For other types of optimizers, the learning rates must be specified  in the <code>optimizer</code>. For more information on how to write your own optimizer,  see <code>AbstractOptimizer</code>.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.freeenergy-Tuple{AbstractRBM,Array{Float64,2}}" href="#BoltzmannMachines.freeenergy-Tuple{AbstractRBM,Array{Float64,2}}"><code>BoltzmannMachines.freeenergy</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">freeenergy(rbm, x)</code></pre><p>Computes the average free energy of the samples in the dataset <code>x</code> for the AbstractRBM <code>rbm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.freeenergy-Tuple{BernoulliRBM,Array{Float64,1}}" href="#BoltzmannMachines.freeenergy-Tuple{BernoulliRBM,Array{Float64,1}}"><code>BoltzmannMachines.freeenergy</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">freeenergy(rbm, v)</code></pre><p>Computes the free energy of the sample <code>v</code> (a vector) for the <code>rbm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.gibbssample!" href="#BoltzmannMachines.gibbssample!"><code>BoltzmannMachines.gibbssample!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">gibbssample!(particles, bm, nsteps)</code></pre><p>Performs Gibbs sampling on the <code>particles</code> in the Boltzmann machine model <code>bm</code> for <code>nsteps</code> steps. (See also: <code>Particles</code>.) When sampling in multimodal deep Boltzmann machines, in-between layers are assumed to contain only Bernoulli-distributed nodes.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.hiddeninput!-Union{Tuple{M}, Tuple{M,BernoulliRBM,M}} where M&lt;:AbstractArray{Float64,1}" href="#BoltzmannMachines.hiddeninput!-Union{Tuple{M}, Tuple{M,BernoulliRBM,M}} where M&lt;:AbstractArray{Float64,1}"><code>BoltzmannMachines.hiddeninput!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">hiddeninput!(h, rbm, v)</code></pre><p>Like <code>hiddeninput</code>, but stores the returned result in <code>h</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.hiddeninput-Union{Tuple{M}, Tuple{AbstractRBM,M}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.hiddeninput-Union{Tuple{M}, Tuple{AbstractRBM,M}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.hiddeninput</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">hiddeninput(rbm, v)</code></pre><p>Computes the total input of the hidden units in the AbstractRBM <code>rbm</code>, given the activations of the visible units <code>v</code>. <code>v</code> may be a vector or a matrix that contains the samples in its rows.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.hiddenpotential!-Union{Tuple{M}, Tuple{M,AbstractXBernoulliRBM,M}, Tuple{M,AbstractXBernoulliRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.hiddenpotential!-Union{Tuple{M}, Tuple{M,AbstractXBernoulliRBM,M}, Tuple{M,AbstractXBernoulliRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.hiddenpotential!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">hiddenpotential!(hh, rbm, vv)
hiddenpotential!(hh, rbm, vv, factor)</code></pre><p>Like <code>hiddenpotential</code>, but stores the returned result in <code>hh</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.hiddenpotential-Union{Tuple{M}, Tuple{AbstractRBM,M}, Tuple{AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.hiddenpotential-Union{Tuple{M}, Tuple{AbstractRBM,M}, Tuple{AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.hiddenpotential</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">hiddenpotential(rbm, v)
hiddenpotential(rbm, v, factor)</code></pre><p>Returns the potential for activations of the hidden nodes in the AbstractRBM <code>rbm</code>, given the activations <code>v</code> of the visible nodes. <code>v</code> may be a vector or a matrix that contains the samples in its rows. The potential is a deterministic value to which sampling can be applied to get the activations. In RBMs with Bernoulli distributed hidden units, the potential of the hidden nodes is the vector of probabilities for them to be turned on.</p><p>The total input can be scaled with the <code>factor</code>. This is needed when pretraining the <code>rbm</code> as part of a DBM.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.initialized-Tuple{AbstractOptimizer,AbstractRBM}" href="#BoltzmannMachines.initialized-Tuple{AbstractOptimizer,AbstractRBM}"><code>BoltzmannMachines.initialized</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">initialized(optimizer, rbm)</code></pre><p>Returns an <code>AbstractOptimizer</code> similar to the given <code>optimizer</code> that can be used to optimize the <code>AbstractRBM</code> <code>rbm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.initparticles-Tuple{AbstractRBM,Int64}" href="#BoltzmannMachines.initparticles-Tuple{AbstractRBM,Int64}"><code>BoltzmannMachines.initparticles</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">initparticles(bm, nparticles; biased = false)</code></pre><p>Creates particles for Gibbs sampling in an Boltzmann machine <code>bm</code>. (See also: <code>Particles</code>)</p><p>For Bernoulli distributed nodes, the particles are initialized with Bernoulli(p) distributed values. If <code>biased == false</code>, p is 0.5, otherwise the results of applying the sigmoid function to the bias values are used as values for the nodes&#39; individual p&#39;s.</p><p>Gaussian nodes are sampled from a normal distribution if <code>biased == false</code>. If <code>biased == true</code> the mean of the Gaussian distribution is shifted by the bias vector and the standard deviation of the nodes is used for sampling.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.initrbm" href="#BoltzmannMachines.initrbm"><code>BoltzmannMachines.initrbm</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">initrbm(x, nhidden)
initrbm(x, nhidden, rbmtype)</code></pre><p>Creates a RBM with <code>nhidden</code> hidden units and initalizes its weights for training on dataset <code>x</code>. <code>rbmtype</code> can be a subtype of <code>AbstractRBM</code>, default is <code>BernoulliRBM</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.joindbms" href="#BoltzmannMachines.joindbms"><code>BoltzmannMachines.joindbms</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">joindbms(dbms)
joindbms(dbms, visibleindexes)</code></pre><p>Joins the DBMs given by the vector <code>dbms</code> by joining each layer of RBMs.</p><p>If the vector <code>visibleindexes</code> is specified, it is supposed to contain in the i&#39;th entry an indexing vector that determines the positions in the combined DBM for the visible nodes of the i&#39;th of the <code>dbms</code>. By default the indexes of the visible nodes are assumed to be consecutive.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.joinrbms-Union{Tuple{T}, Tuple{T,T}} where T&lt;:AbstractRBM" href="#BoltzmannMachines.joinrbms-Union{Tuple{T}, Tuple{T,T}} where T&lt;:AbstractRBM"><code>BoltzmannMachines.joinrbms</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">joinrbms(rbms)
joinrbms(rbms, visibleindexes)</code></pre><p>Joins the given vector of <code>rbms</code> of the same type to form one RBM of this type and returns the joined RBM.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.loglikelihood" href="#BoltzmannMachines.loglikelihood"><code>BoltzmannMachines.loglikelihood</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">loglikelihood(dbm, x; ...)</code></pre><p>Estimates the mean log-likelihood of the DBM on the data set <code>x</code> with Annealed Importance Sampling. This requires a separate run of AIS for each sample.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.loglikelihood" href="#BoltzmannMachines.loglikelihood"><code>BoltzmannMachines.loglikelihood</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">loglikelihood(rbm, x)
loglikelihood(rbm, x, logz)</code></pre><p>Computes the average log-likelihood of an RBM on a given dataset <code>x</code>. Uses <code>logz</code> as value for the log of the partition function or estimates the partition function with Annealed Importance Sampling.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.logpartitionfunction-Tuple{Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Float64}" href="#BoltzmannMachines.logpartitionfunction-Tuple{Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Float64}"><code>BoltzmannMachines.logpartitionfunction</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">logpartitionfunction(bm; ...)
logpartitionfunction(bm, logr)</code></pre><p>Calculates or estimates the log of the partition function of the Boltzmann Machine <code>bm</code>.</p><p><code>r</code> is an estimator of the ratio of the <code>bm</code>&#39;s partition function Z to the partition function Z<em>0 of the reference BM with zero weights but same biases as the given <code>bm</code>. In case of a GaussianBernoulliRBM, the reference model also has the same standard deviation parameter. The estimated partition function of the Boltzmann Machine is Z = r * Z</em>0 with <code>r</code> being the mean of the importance weights. Therefore, the log of the estimated partition function is log(Z) = log(r) + log(Z_0)</p><p>If the log of <code>r</code> is not given as argument <code>logr</code>, Annealed Importance Sampling (AIS) is performed to get a value for it. In this case, the optional arguments for AIS can be specified (see <code>aislogimpweights</code>), and the optional boolean argument <code>parallelized</code> can be used to turn on batch-parallelized computing of the importance weights.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.logpartitionfunctionzeroweights-Tuple{AbstractRBM}" href="#BoltzmannMachines.logpartitionfunctionzeroweights-Tuple{AbstractRBM}"><code>BoltzmannMachines.logpartitionfunctionzeroweights</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">logpartitionfunctionzeroweights(bm)</code></pre><p>Returns the value of the log of the partition function of the Boltzmann Machine that results when one sets the weights of <code>bm</code> to zero, and leaves the other parameters (biases) unchanged.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.logproblowerbound" href="#BoltzmannMachines.logproblowerbound"><code>BoltzmannMachines.logproblowerbound</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">logproblowerbound(dbm, x; ...)
logproblowerbound(dbm, x, logimpweights; ...)
logproblowerbound(dbm, x, logz; ...)</code></pre><p>Estimates the mean of the variational lower bound for the log probability of the DBM on a given dataset <code>x</code> like described in Equation 38 in [Salakhutdinov, 2015]. The logarithmized partition function can be specified directly as <code>logz</code> or by giving the <code>logimpweights</code> from estimating the partition function with the Annealed Importance Sampling algorithm (AIS). (See <code>aislogimpweights</code>.) If neither <code>logimpweights</code> or <code>logz</code> is given, the partition function will be estimated by AIS with default parameters.</p><p><strong>Optional keyword argument:</strong></p><ul><li>The approximate posterior distribution may be given as argument <code>mu</code> or is calculated by the mean-field method.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.meanfield" href="#BoltzmannMachines.meanfield"><code>BoltzmannMachines.meanfield</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">meanfield(dbm, x)
meanfield(dbm, x, eps)</code></pre><p>Computes the mean-field approximation for the data set <code>x</code> and returns a matrix of particles for the DBM. The number of particles is equal to the number of samples in <code>x</code>. <code>eps</code> is the convergence criterion for the fix-point iteration, default 0.001. It is assumed that all nodes in in-between-layers are Bernoulli distributed.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.monitorexactloglikelihood!-Tuple{Array{MonitoringItem,1},Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Int64,Dict{String,Array{Float64,2}}}" href="#BoltzmannMachines.monitorexactloglikelihood!-Tuple{Array{MonitoringItem,1},Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Int64,Dict{String,Array{Float64,2}}}"><code>BoltzmannMachines.monitorexactloglikelihood!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">monitorexactloglikelihood!(monitor, bm, epoch, datadict)</code></pre><p>Computes the mean exact log-likelihood in the Boltzmann Machine model <code>bm</code> for the data sets in the DataDict <code>datadict</code> and stores this information in the Monitor <code>monitor</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.monitorfreeenergy!-Tuple{Array{MonitoringItem,1},AbstractRBM,Int64,Dict{String,Array{Float64,2}}}" href="#BoltzmannMachines.monitorfreeenergy!-Tuple{Array{MonitoringItem,1},AbstractRBM,Int64,Dict{String,Array{Float64,2}}}"><code>BoltzmannMachines.monitorfreeenergy!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">monitorfreeenergy!(monitor, rbm, epoch, datadict)</code></pre><p>Computes the free energy for the <code>datadict</code>&#39;s data sets in the RBM model <code>rbm</code> and stores the information in the <code>monitor</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.monitorloglikelihood!-Tuple{Array{MonitoringItem,1},AbstractRBM,Int64,Dict{String,Array{Float64,2}}}" href="#BoltzmannMachines.monitorloglikelihood!-Tuple{Array{MonitoringItem,1},AbstractRBM,Int64,Dict{String,Array{Float64,2}}}"><code>BoltzmannMachines.monitorloglikelihood!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">monitorloglikelihood!(monitor, rbm, epoch, datadict)</code></pre><p>Estimates the log-likelihood of the <code>datadict</code>&#39;s data sets in the RBM model <code>rbm</code> with AIS and stores the values, together with information about the variance of the estimator, in the <code>monitor</code>.</p><p>If there is more than one worker available, the computation is parallelized by default. Parallelization can be turned on or off with the optional boolean argument <code>parallelized</code>.</p><p>For the other optional keyword arguments, see <code>aislogimportanceweights</code>.</p><p>See also: <code>loglikelihood</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.monitorlogproblowerbound!-Tuple{Array{MonitoringItem,1},Array{#s1708,1} where #s1708&lt;:AbstractRBM,Int64,Dict{String,Array{Float64,2}}}" href="#BoltzmannMachines.monitorlogproblowerbound!-Tuple{Array{MonitoringItem,1},Array{#s1708,1} where #s1708&lt;:AbstractRBM,Int64,Dict{String,Array{Float64,2}}}"><code>BoltzmannMachines.monitorlogproblowerbound!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">monitorlogproblowerbound!(monitor, dbm, epoch, datadict)</code></pre><p>Estimates the lower bound of the log probability of the <code>datadict</code>&#39;s data sets in the DBM <code>dbm</code> with AIS and stores the values, together with information about the variance of the estimator, in the <code>monitor</code>.</p><p>If there is more than one worker available, the computation is parallelized by default. Parallelization can be turned on or off with the optional boolean argument <code>parallelized</code>.</p><p>For the other optional keyword arguments, see <code>aislogimpweights</code>.</p><p>See also: <code>logproblowerbound</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.monitorreconstructionerror!-Tuple{Array{MonitoringItem,1},AbstractRBM,Int64,Dict{String,Array{Float64,2}}}" href="#BoltzmannMachines.monitorreconstructionerror!-Tuple{Array{MonitoringItem,1},AbstractRBM,Int64,Dict{String,Array{Float64,2}}}"><code>BoltzmannMachines.monitorreconstructionerror!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">monitorreconstructionerror!(monitor, rbm, epoch, datadict)</code></pre><p>Computes the reconstruction error for the data sets in the <code>datadict</code> and the <code>rbm</code> and stores the values in the <code>monitor</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.monitorweightsnorm!-Tuple{Array{MonitoringItem,1},AbstractRBM,Int64}" href="#BoltzmannMachines.monitorweightsnorm!-Tuple{Array{MonitoringItem,1},AbstractRBM,Int64}"><code>BoltzmannMachines.monitorweightsnorm!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">monitorweightsnorm!(monitor, rbm, epoch)</code></pre><p>Computes the L2-norm of the weights matrix and the bias vectors of the <code>rbm</code> and stores the values in the <code>monitor</code>. These values can give a hint how much the updates are changing the parameters during learning.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.propagateforward" href="#BoltzmannMachines.propagateforward"><code>BoltzmannMachines.propagateforward</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">propagateforward(rbm, datadict, factor)</code></pre><p>Returns a new <code>DataDict</code> containing the same labels as the given <code>datadict</code> but as mapped values it contains the hidden potential in the <code>rbm</code> of the original datasets. The factor is applied for calculating the hidden potential and is 1.0 by default.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.reconstructionerror" href="#BoltzmannMachines.reconstructionerror"><code>BoltzmannMachines.reconstructionerror</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">reconstructionerror(rbm, x)</code></pre><p>Computes the mean reconstruction error of the RBM on the dataset <code>x</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.samplehidden!-Union{Tuple{M}, Tuple{Any,AbstractRBM,M}, Tuple{Any,AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.samplehidden!-Union{Tuple{M}, Tuple{Any,AbstractRBM,M}, Tuple{Any,AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.samplehidden!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">samplehidden!(h, rbm, v)
samplehidden!(h, rbm, v, factor)</code></pre><p>Like <code>samplehidden</code>, but stores the returned result in <code>h</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.samplehidden-Union{Tuple{M}, Tuple{AbstractXBernoulliRBM,M}, Tuple{AbstractXBernoulliRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.samplehidden-Union{Tuple{M}, Tuple{AbstractXBernoulliRBM,M}, Tuple{AbstractXBernoulliRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.samplehidden</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">samplehidden(rbm, v)
samplehidden(rbm, v, factor)</code></pre><p>Returns activations of the hidden nodes in the AbstractRBM <code>rbm</code>, sampled from the state <code>v</code> of the visible nodes. <code>v</code> may be a vector or a matrix that contains the samples in its rows. For the <code>factor</code>, see <code>hiddenpotential(rbm, v, factor)</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.sampleparticles" href="#BoltzmannMachines.sampleparticles"><code>BoltzmannMachines.sampleparticles</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">sampleparticles(bm, nparticles, burnin)</code></pre><p>Samples in the Boltzmann Machine model <code>bm</code> by running <code>nparticles</code> parallel, randomly initialized Gibbs chains for <code>burnin</code> steps. Returns particles containing <code>nparticles</code> generated samples. See also: <code>Particles</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.samples-Tuple{AbstractRBM,Int64}" href="#BoltzmannMachines.samples-Tuple{AbstractRBM,Int64}"><code>BoltzmannMachines.samples</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">samples(bm, nsamples; ...)</code></pre><p>Generates <code>nsamples</code> samples from a Boltzmann machine model <code>bm</code> by running a Gibbs sampler.</p><p><strong>Optional keyword arguments:</strong></p><ul><li><code>burnin</code>: Number of Gibbs sampling steps, defaults to 50.</li><li><code>samplelast</code>: boolean to indicate whether to sample in last step (true, default) or whether to use the activation potential.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.samplevisible!-Union{Tuple{M}, Tuple{M,AbstractRBM,M}, Tuple{M,AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.samplevisible!-Union{Tuple{M}, Tuple{M,AbstractRBM,M}, Tuple{M,AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.samplevisible!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">samplevisible!(v, rbm, h)
samplevisible!(v, rbm, h, factor)</code></pre><p>Like <code>samplevisible</code>, but stores the returned result in <code>v</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.samplevisible-Union{Tuple{M}, Tuple{AbstractRBM,M}, Tuple{AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.samplevisible-Union{Tuple{M}, Tuple{AbstractRBM,M}, Tuple{AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.samplevisible</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">samplevisible(rbm, h)
samplevisible(rbm, h, factor)</code></pre><p>Returns activations of the visible nodes in the AbstractRBM <code>rbm</code>, sampled from the state <code>h</code> of the hidden nodes. <code>h</code> may be a vector or a matrix that contains the samples in its rows. For the <code>factor</code>, see <code>visiblepotential(rbm, h, factor)</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.splitdata-Tuple{Array{Float64,2},Float64}" href="#BoltzmannMachines.splitdata-Tuple{Array{Float64,2},Float64}"><code>BoltzmannMachines.splitdata</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">splitdata(x, ratio)</code></pre><p>Splits the data set <code>x</code> randomly in two data sets <code>x1</code> and <code>x2</code>, such that the ratio <code>n2</code>/<code>n1</code> of the numbers of lines/samples in <code>x1</code> and <code>x2</code> is approximately equal to the given <code>ratio</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.stackrbms-Tuple{Array{Float64,2}}" href="#BoltzmannMachines.stackrbms-Tuple{Array{Float64,2}}"><code>BoltzmannMachines.stackrbms</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">stackrbms(x; ...)</code></pre><p>Performs greedy layerwise training for Deep Belief Networks or greedy layerwise pretraining for Deep Boltzmann Machines and returns the trained model.</p><p><strong>Optional keyword arguments (ordered by importance):</strong></p><ul><li><code>predbm</code>: boolean indicating that the greedy layerwise training is  pre-training for a DBM.  If its value is false (default), a DBN is trained.</li><li><code>nhiddens</code>: vector containing the number of nodes of the i&#39;th hidden layer in  the i&#39;th entry</li><li><code>epochs</code>: number of training epochs</li><li><code>learningrate</code>: learningrate, default 0.005</li><li><code>batchsize</code>: size of minibatches, defaults to 1</li><li><code>trainlayers</code>: a vector of <code>TrainLayer</code> objects. With this argument it is possible  to specify the training parameters for each layer/RBM individually.  If the number of training epochs and the learning rate are not specified  explicitly for a layer, the values of <code>epochs</code> and <code>learningrate</code> are used.  For more information see help of <code>TrainLayer</code>.</li><li><code>monitoringdata</code>: a data dictionary (see type <code>DataDict</code>)  The data is propagated forward through the  network to monitor higher levels.  If a non-empty dictionary is given, the monitoring functions in the  <code>trainlayers</code>-arguments must accept a <code>DataDict</code> as third argument.</li><li><code>samplehidden</code>: boolean indicating that consequent layers are to be trained  with sampled values instead of the deterministic potential,  which is the default.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.traindbm!-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM,Array{Float64,2},Array{Array{Float64,2},1},AbstractOptimizer}" href="#BoltzmannMachines.traindbm!-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM,Array{Float64,2},Array{Array{Float64,2},1},AbstractOptimizer}"><code>BoltzmannMachines.traindbm!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">traindbm!(dbm, x, particles, learningrate)</code></pre><p>Trains the given <code>dbm</code> for one epoch.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.traindbm!-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM,Array{Float64,2}}" href="#BoltzmannMachines.traindbm!-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM,Array{Float64,2}}"><code>BoltzmannMachines.traindbm!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">traindbm!(dbm, x; ...)</code></pre><p>Trains the <code>dbm</code> (a <code>BasicDBM</code> or a more general <code>MultimodalDBM</code>) using the learning procedure for a general Boltzmann Machine with the training data set <code>x</code>. A learning step consists of mean-field inference (positive phase), stochastic approximation by Gibbs Sampling (negative phase) and the parameter updates.</p><p><strong>Optional keyword arguments (ordered by importance):</strong></p><ul><li><code>epoch</code>: number of training epochs</li><li><code>learningrate</code>/<code>learningrates</code>: a vector of learning rates for each epoch to  update the weights and biases. The learning rates should decrease with the  epochs, e. g. like <code>a / (b + epoch)</code>. If only one value is given as  <code>learningrate</code>, <code>a</code> and <code>b</code> are 11.0 and 10.0, respectively.</li><li><code>nparticles</code>: number of particles used for sampling, default 100</li><li><code>monitoring</code>: A function that is executed after each training epoch.  It has to accept the trained DBM and the current epoch as arguments.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.trainrbm!-Tuple{AbstractRBM,Array{Float64,2}}" href="#BoltzmannMachines.trainrbm!-Tuple{AbstractRBM,Array{Float64,2}}"><code>BoltzmannMachines.trainrbm!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">trainrbm!(rbm, x)</code></pre><p>Trains the given <code>rbm</code> for one epoch using the data set <code>x</code>. (See also function <code>fitrbm</code>.)</p><p><strong>Optional keyword arguments:</strong></p><ul><li><code>learningrate</code>, <code>cdsteps</code>, <code>sdlearningrate</code>, <code>upfactor</code>, <code>downfactor</code>,  <code>optimizer</code>:  See documentation of function <code>fitrbm</code>.</li><li><code>chainstate</code>: a matrix for holding the states of the RBM&#39;s hidden nodes. If  it is specified, PCD is used.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.updateparameters!-Union{Tuple{R}, Tuple{AbstractRBM,AbstractOptimizer{R}}} where R&lt;:AbstractRBM" href="#BoltzmannMachines.updateparameters!-Union{Tuple{R}, Tuple{AbstractRBM,AbstractOptimizer{R}}} where R&lt;:AbstractRBM"><code>BoltzmannMachines.updateparameters!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">updateparameters!(rbm, optimizer)</code></pre><p>Updates the RBM <code>rbm</code> by walking a step in the direction of the gradient that has been computed by calling <code>computegradient!</code> on <code>optimizer</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.visibleinput!-Union{Tuple{M}, Tuple{M,Union{BernoulliGaussianRBM, BernoulliRBM, Binomial2BernoulliRBM},M}} where M&lt;:AbstractArray{Float64,1}" href="#BoltzmannMachines.visibleinput!-Union{Tuple{M}, Tuple{M,Union{BernoulliGaussianRBM, BernoulliRBM, Binomial2BernoulliRBM},M}} where M&lt;:AbstractArray{Float64,1}"><code>BoltzmannMachines.visibleinput!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">visibleinput!(v, rbm, h)</code></pre><p>Like <code>visibleinput</code> but stores the returned result in <code>v</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.visibleinput-Union{Tuple{M}, Tuple{AbstractRBM,M}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.visibleinput-Union{Tuple{M}, Tuple{AbstractRBM,M}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.visibleinput</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">visibleinput(rbm, h)</code></pre><p>Returns activations of the visible nodes in the AbstractXBernoulliRBM <code>rbm</code>, sampled from the state <code>h</code> of the hidden nodes. <code>h</code> may be a vector or a matrix that contains the samples in its rows.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.visiblepotential!-Union{Tuple{M}, Tuple{M,Union{BernoulliGaussianRBM, BernoulliRBM},M}, Tuple{M,Union{BernoulliGaussianRBM, BernoulliRBM},M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.visiblepotential!-Union{Tuple{M}, Tuple{M,Union{BernoulliGaussianRBM, BernoulliRBM},M}, Tuple{M,Union{BernoulliGaussianRBM, BernoulliRBM},M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.visiblepotential!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">visiblepotential!(v, rbm, h)</code></pre><p>Like <code>visiblepotential</code> but stores the returned result in <code>v</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.visiblepotential-Union{Tuple{M}, Tuple{AbstractRBM,M}, Tuple{AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.visiblepotential-Union{Tuple{M}, Tuple{AbstractRBM,M}, Tuple{AbstractRBM,M,Float64}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.visiblepotential</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">visiblepotential(rbm, h)
visiblepotential(rbm, h, factor)</code></pre><p>Returns the potential for activations of the visible nodes in the AbstractRBM <code>rbm</code>, given the activations <code>h</code> of the hidden nodes. <code>h</code> may be a vector or a matrix that contains the samples in its rows. The potential is a deterministic value to which sampling can be applied to get the activations.</p><p>The total input can be scaled with the <code>factor</code>. This is needed when pretraining the <code>rbm</code> as part of a DBM.</p><p>In RBMs with Bernoulli distributed visible units, the potential of the visible nodes is the vector of probabilities for them to be turned on.</p><p>For a Binomial2BernoulliRBM, the visible units are sampled from a Binomial(2,p) distribution in the Gibbs steps. In this case, the potential is the vector of values for 2p. (The value is doubled to get a value in the same range as the sampled one.)</p><p>For GaussianBernoulliRBMs, the potential of the visible nodes is the vector of means of the Gaussian distributions for each node.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.AbstractXBernoulliRBM" href="#BoltzmannMachines.AbstractXBernoulliRBM"><code>BoltzmannMachines.AbstractXBernoulliRBM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Abstract super type for RBMs with binary and Bernoulli distributed hidden nodes.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.MultivariateBernoulliDistribution" href="#BoltzmannMachines.MultivariateBernoulliDistribution"><code>BoltzmannMachines.MultivariateBernoulliDistribution</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">MultivariateBernoulliDistribution(bm)</code></pre><p>Calculates and stores the probabilities for all possible combinations of a multivariate Bernoulli distribution defined by a Boltzmann machine model with Bernoulli distributed visible nodes. Can be used for sampling from this distribution, see <code>samples</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.NoRBM" href="#BoltzmannMachines.NoRBM"><code>BoltzmannMachines.NoRBM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Singleton-Placeholder for <code>AbstractRBM</code>s </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.PartitionedBernoulliDBM" href="#BoltzmannMachines.PartitionedBernoulliDBM"><code>BoltzmannMachines.PartitionedBernoulliDBM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A DBM with only Bernoulli distributed nodes which may contain partitioned layers.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.StackedOptimizer" href="#BoltzmannMachines.StackedOptimizer"><code>BoltzmannMachines.StackedOptimizer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">StackedOptimizer(optimizers)</code></pre><p>Can be used for optimizing a stack of RBMs / a DBM by using the given the vector of <code>optimizers</code> (one for each RBM). For more information about the concept of optimizers, see <code>AbstractOptimizer</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.aisupdatelogimpweights!-Tuple{Any,Array{Array{Float64,2},1},Array{Array{Float64,2},1},Float64,Float64,Array{#s1708,1} where #s1708&lt;:Union{BernoulliRBM, PartitionedRBM{BernoulliRBM}},Array{Array{Float64,1},1},Array{Array{Float64,2},1}}" href="#BoltzmannMachines.aisupdatelogimpweights!-Tuple{Any,Array{Array{Float64,2},1},Array{Array{Float64,2},1},Float64,Float64,Array{#s1708,1} where #s1708&lt;:Union{BernoulliRBM, PartitionedRBM{BernoulliRBM}},Array{Array{Float64,1},1},Array{Array{Float64,2},1}}"><code>BoltzmannMachines.aisupdatelogimpweights!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Updates the logarithmized importance weights <code>logimpweights</code> in AIS by adding the log ratio of unnormalized probabilities of the states of the odd layers in the PartitionedBernoulliDBM <code>dbm</code>. The activation states of the DBM&#39;s nodes are given by the <code>particles</code>. For performance reasons, the biases are specified separately.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.akaikeinformationcriterion-Tuple{Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Float64}" href="#BoltzmannMachines.akaikeinformationcriterion-Tuple{Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Float64}"><code>BoltzmannMachines.akaikeinformationcriterion</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">akaikeinformationcriterion(bm, loglikelihood)</code></pre><p>Calculates the Akaike information criterion for a Boltzmann Machine, given its <code>loglikelihood</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.batchparallelized-Tuple{Function,Int64,Function}" href="#BoltzmannMachines.batchparallelized-Tuple{Function,Int64,Function}"><code>BoltzmannMachines.batchparallelized</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">batchparallelized(f, n, op)</code></pre><p>Distributes the work for executing the function <code>f</code> <code>n</code> times on all the available workers and reduces the results with the operator <code>op</code>. <code>f</code> is a function that gets a number (of tasks) to execute the tasks.</p><p><strong>Example:</strong></p><pre><code class="language-none">batchparallelized(n -&gt; aislogimpweights(dbm; nparticles = n), 100, vcat)</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.bayesianinformationcriterion-Tuple{Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Int64,Float64}" href="#BoltzmannMachines.bayesianinformationcriterion-Tuple{Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Int64,Float64}"><code>BoltzmannMachines.bayesianinformationcriterion</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">bayesianinformationcriterion(bm, nvariables, loglikelihood)</code></pre><p>Calculates the Akaike information criterion for a Boltzmann machine, given its <code>loglikelihood</code> and the number of samples <code>nsamples</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.bernoulliloglikelihoodbaserate-Tuple{Array{Float64,2}}" href="#BoltzmannMachines.bernoulliloglikelihoodbaserate-Tuple{Array{Float64,2}}"><code>BoltzmannMachines.bernoulliloglikelihoodbaserate</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">bernoulliloglikelihoodbaserate(x)</code></pre><p>Calculates the log-likelihood for the data set <code>x</code> in the &quot;base-rate&quot; BM with all weights being zero and visible bias set to the empirical probability of the samples&#39; components in <code>x</code> being 1.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.bernoulliloglikelihoodbaserate-Tuple{Int64}" href="#BoltzmannMachines.bernoulliloglikelihoodbaserate-Tuple{Int64}"><code>BoltzmannMachines.bernoulliloglikelihoodbaserate</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">bernoulliloglikelihoodbaserate(nvariables)</code></pre><p>Calculates the log-likelihood for a random sample in the &quot;base-rate&quot; BM with all parameters being zero and thus all visible units being independent and Bernoulli distributed.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.combinedbiases-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM}" href="#BoltzmannMachines.combinedbiases-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM}"><code>BoltzmannMachines.combinedbiases</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">combinedbiases(dbm)</code></pre><p>Returns a vector containing in the i&#39;th element the bias vector for the i&#39;th layer of the <code>dbm</code>. For intermediate layers, visible and hidden biases are combined to a single bias vector.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.converttomostspecifictype-Tuple{Array{T,1} where T}" href="#BoltzmannMachines.converttomostspecifictype-Tuple{Array{T,1} where T}"><code>BoltzmannMachines.converttomostspecifictype</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Converts a vector to a vector of the most specific type that all elements share as common supertype.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.copyannealed!-Union{Tuple{BRBM}, Tuple{BRBM,BRBM,Float64}} where BRBM&lt;:Union{BernoulliRBM, Binomial2BernoulliRBM}" href="#BoltzmannMachines.copyannealed!-Union{Tuple{BRBM}, Tuple{BRBM,BRBM,Float64}} where BRBM&lt;:Union{BernoulliRBM, Binomial2BernoulliRBM}"><code>BoltzmannMachines.copyannealed!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">copyannealed!(annealedrbm, rbm, temperature)</code></pre><p>Copies all parameters that are to be annealed from the RBM <code>rbm</code> to the RBM <code>annealedrbm</code> and anneals them with the given <code>temperature</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.correlations-Tuple{Dict{String,Array{Float64,2}}}" href="#BoltzmannMachines.correlations-Tuple{Dict{String,Array{Float64,2}}}"><code>BoltzmannMachines.correlations</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">correlations(datadict)</code></pre><p>Creates and returns a dictionary with the same keys as the given <code>datadict</code>. The values of the returned dictionary are the correlations of the samples in the datasets given as values in the <code>datadict</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.crossvalidationargs-Tuple{Array{Float64,2},Vararg{Any,N} where N}" href="#BoltzmannMachines.crossvalidationargs-Tuple{Array{Float64,2},Vararg{Any,N} where N}"><code>BoltzmannMachines.crossvalidationargs</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">crossvalidationargs(x, pars...; )</code></pre><p>Returns a tuple of argument vectors containing the parameters for a function such as the <code>monitoredfit</code> argument in <code>crossvalidation</code>.</p><p>Usage example:     map(monitoredfit, crossvalidationargs(x)...)</p><p><strong>Optional named argument:</strong></p><ul><li><code>kfold</code>: see <code>crossvalidation</code>.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.curvebundles-Tuple{}" href="#BoltzmannMachines.curvebundles-Tuple{}"><code>BoltzmannMachines.curvebundles</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">curvebundles(...)</code></pre><p>Generates an example dataset that can be visualized as bundles of trend curves with added noise. Additional binary columns with labels may be added.</p><p><strong>Optional named arguments:</strong></p><ul><li><code>nbundles</code>: number of bundles</li><li><code>nperbundle</code>: number of sequences per bundle</li><li><code>nvariables</code>: number of variables in the sequences</li><li><code>noisesd</code>: standard deviation of the noise added on all sequences</li><li><code>addlabels</code>: add leading columns to the resulting dataset, specifying the  membership to a bundle</li><li><code>pbreak</code>: probability that an intermediate point in a sequence is a  breakpoint, defaults to 0.2.</li><li><code>breakval</code>: a function that expects no input and generates a single (random) value for a defining point of a piecewise linear sequence. Defaults to <code>rand</code>.</li></ul><p><strong>Example:</strong></p><p>To quickly grasp the idea, plot generated samples against the variable index:</p><pre><code class="language-none">x = BMs.curvebundles(nvariables = 10, nbundles = 3,
                   nperbundle = 4, noisesd = 0.03,
                   addlabels = true)
BoltzmannMachinesPlots.plotcurvebundles(x)</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.emptyfunc" href="#BoltzmannMachines.emptyfunc"><code>BoltzmannMachines.emptyfunc</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>A function with no arguments doing nothing. Usable as default argument for functions as arguments.W</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.energyzerohiddens-Tuple{BernoulliRBM,Array{Float64,1}}" href="#BoltzmannMachines.energyzerohiddens-Tuple{BernoulliRBM,Array{Float64,1}}"><code>BoltzmannMachines.energyzerohiddens</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">energyzerohiddens(rbm, v)</code></pre><p>Computes the energy for the visible activations <code>v</code> in the RBM <code>rbm</code>, if all hidden nodes have zero activation, i. e. yields the same as <code>energy´(rbm, v, zeros(rbm.hidbias))</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.freeenergydiffs-Tuple{AbstractRBM,AbstractRBM,Array{Float64,2}}" href="#BoltzmannMachines.freeenergydiffs-Tuple{AbstractRBM,AbstractRBM,Array{Float64,2}}"><code>BoltzmannMachines.freeenergydiffs</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">freeeenergydiffs(rbm1, rbm2, x)</code></pre><p>Computes the differences of the free energy for the samples in the dataset <code>x</code> regarding the RBM models <code>rbm1</code> and <code>rbm2</code>. Returns a vector of differences.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.gaussianloglikelihoodbaserate-Tuple{Array{Float64,2}}" href="#BoltzmannMachines.gaussianloglikelihoodbaserate-Tuple{Array{Float64,2}}"><code>BoltzmannMachines.gaussianloglikelihoodbaserate</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">gaussianloglikelihoodbaserate(x)</code></pre><p>Calculates the mean log-likelihood for the data set <code>x</code> with all variables and components of the variables being independent and Gaussian distributed. The standard deviation and the mean of the i&#39;th variable is the mean and standard deviation of values of the i&#39;th component of the sample vectors.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.initcombination-Tuple{Array{BernoulliRBM,1}}" href="#BoltzmannMachines.initcombination-Tuple{Array{BernoulliRBM,1}}"><code>BoltzmannMachines.initcombination</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns particle for DBM, initialized with zeros.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.initcombinationoddlayersonly-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM}" href="#BoltzmannMachines.initcombinationoddlayersonly-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractRBM}"><code>BoltzmannMachines.initcombinationoddlayersonly</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">initcombinationoddlayersonly(dbm)</code></pre><p>Creates and zero-initializes a particle for layers with odd indexes in the <code>dbm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.initgammaprocess-Tuple{Float64,Float64}" href="#BoltzmannMachines.initgammaprocess-Tuple{Float64,Float64}"><code>BoltzmannMachines.initgammaprocess</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Update beta with an autoregressive Gamma process. beta<em>0 ~ Gamma(nu,c/(1-phi)) = Gamma(1/var, var) h</em>t ~ Possion( phi/c * h<em>{t-1}) beta</em>t ~ Gamma(nu + z_t, c) Achieves a stationary distribution with mean 1 and variance var: Gamma(nu, var) = Gamma(1/var, var)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.initvisiblebias-Tuple{Array{Float64,2}}" href="#BoltzmannMachines.initvisiblebias-Tuple{Array{Float64,2}}"><code>BoltzmannMachines.initvisiblebias</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">initvisiblebias(x)</code></pre><p>Returns sensible initial values for the visible bias for training an RBM on the data set <code>x</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.joinvecs" href="#BoltzmannMachines.joinvecs"><code>BoltzmannMachines.joinvecs</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">joinvecs(vecs, indexes)</code></pre><p>Combines the Float-vectors in <code>vecs</code> into one vector. The <code>indexes</code><code>vector must contain in the i&#39;th entry the indexes that the elements of the i&#39;th vector in</code>vecs` are supposed to have in the resulting combined vector.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.joinweights-Union{Tuple{Array{T,1}}, Tuple{T}, Tuple{Array{T,1},Any}} where T&lt;:AbstractRBM" href="#BoltzmannMachines.joinweights-Union{Tuple{Array{T,1}}, Tuple{T}, Tuple{Array{T,1},Any}} where T&lt;:AbstractRBM"><code>BoltzmannMachines.joinweights</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">joinweights(rbms)
joinweights(rbms, visibleindexes)</code></pre><p>Combines the weight matrices of the RBMs in the vector <code>rbms</code> into one weight matrix and returns it.</p><p>If the vector <code>visibleindexes</code> is specified, it is supposed to contain in the i&#39;th entry an indexing vector that determines the positions in the combined weight matrix for the visible nodes of the i&#39;th of the <code>rbms</code>. By default the indexes of the visible nodes are assumed to be consecutive.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.log1pexp-Tuple{Float64}" href="#BoltzmannMachines.log1pexp-Tuple{Float64}"><code>BoltzmannMachines.log1pexp</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">log1pexp(x)</code></pre><p>Calculates log(1+exp(x)). For sufficiently large values of x, the approximation log(1+exp(x)) ≈ x is used. This is useful to prevent overflow.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.loglikelihooddiff-Union{Tuple{R}, Tuple{R,R,Array{Float64,2},Float64}} where R&lt;:AbstractRBM" href="#BoltzmannMachines.loglikelihooddiff-Union{Tuple{R}, Tuple{R,R,Array{Float64,2},Float64}} where R&lt;:AbstractRBM"><code>BoltzmannMachines.loglikelihooddiff</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">loglikelihooddiff(rbm1, rbm2, x)
loglikelihooddiff(rbm1, rbm2, x, logzdiff)
loglikelihooddiff(rbm1, rbm2, x, logimpweights)</code></pre><p>Computes difference of the loglikelihood functions of the two RBMs on the data matrix <code>x</code>, averaged over the samples. For this purpose, the partition function ratio Z2/Z1 is estimated by AIS unless the importance weights are specified the by parameter <code>logimpweights</code> or the difference in the log partition functions is given by <code>logzdiff</code>.</p><p>The first model is better than the second if the returned value is positive.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.logmeanexp-Tuple{Array{Float64,1}}" href="#BoltzmannMachines.logmeanexp-Tuple{Array{Float64,1}}"><code>BoltzmannMachines.logmeanexp</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Performs numerically stable computation of the mean on log-scale. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.logsumexp-Tuple{Array{Float64,1}}" href="#BoltzmannMachines.logsumexp-Tuple{Array{Float64,1}}"><code>BoltzmannMachines.logsumexp</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Performs numerically stable summation on log-scale. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.means-Tuple{Dict{String,Array{Float64,2}}}" href="#BoltzmannMachines.means-Tuple{Dict{String,Array{Float64,2}}}"><code>BoltzmannMachines.means</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">means(datadict)</code></pre><p>Creates and returns a dictionary with the same keys as the given <code>datadict</code>. The values of the returned dictionary are the samples&#39; means in the <code>datadict</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.monitorcordiff!-Tuple{Array{MonitoringItem,1},Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Int64,Dict{String,Array{Float64,2}}}" href="#BoltzmannMachines.monitorcordiff!-Tuple{Array{MonitoringItem,1},Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM},Int64,Dict{String,Array{Float64,2}}}"><code>BoltzmannMachines.monitorcordiff!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">monitorcordiff!(monitor, rbm, epoch, cordict)</code></pre><p>Generates samples and records the distance of their correlation matrix to the correlation matrices for (original) datasets contained in the <code>cordict</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.mostevenbatches" href="#BoltzmannMachines.mostevenbatches"><code>BoltzmannMachines.mostevenbatches</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">mostevenbatches(ntasks)
mostevenbatches(ntasks, nbatches)</code></pre><p>Splits a number of tasks <code>ntasks</code> into a number of batches <code>nbatches</code>. The number of batches is by default <code>min(nworkers(), ntasks)</code>. The returned result is a vector containing the numbers of tasks for each batch.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.mostspecifictype-Tuple{Array{T,1} where T}" href="#BoltzmannMachines.mostspecifictype-Tuple{Array{T,1} where T}"><code>BoltzmannMachines.mostspecifictype</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">mostspecifictype(v)</code></pre><p>Returns the most specific supertype for all elements in the vector <code>v</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.newparticleslike-Tuple{Array{Array{Float64,2},1}}" href="#BoltzmannMachines.newparticleslike-Tuple{Array{Array{Float64,2},1}}"><code>BoltzmannMachines.newparticleslike</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">newparticleslike(particles)</code></pre><p>Creates new and uninitialized particles of the same dimensions as the given <code>particles</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.next!-Tuple{Array{Array{Float64,1},1}}" href="#BoltzmannMachines.next!-Tuple{Array{Array{Float64,1},1}}"><code>BoltzmannMachines.next!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">next!(particle)</code></pre><p>Sets <code>particle</code> to the next combination of nodes&#39; activations. Returns false if the loop went through all combinations; true otherwise.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.next!-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractArray{Float64,1}" href="#BoltzmannMachines.next!-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractArray{Float64,1}"><code>BoltzmannMachines.next!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">next!(combination)</code></pre><p>Sets the vector <code>combination</code>, containing a sequence of the values 0.0 and 1.0, to the next combination of 0.0s and 1.0s. Returns false if the new combination consists only of zeros; true otherwise.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.nhiddennodes-Tuple{AbstractRBM}" href="#BoltzmannMachines.nhiddennodes-Tuple{AbstractRBM}"><code>BoltzmannMachines.nhiddennodes</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">nhiddennodes(rbm)</code></pre><p>Returns the number of visible nodes for an RBM.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.nmodelparameters-Tuple{Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM}}" href="#BoltzmannMachines.nmodelparameters-Tuple{Union{AbstractRBM, Array{#s1708,1} where #s1708&lt;:AbstractRBM}}"><code>BoltzmannMachines.nmodelparameters</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">nmodelparameters(bm)</code></pre><p>Returns the number of parameters in the Boltzmann Machine model <code>bm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.nomonitoring-Tuple{Any,Any}" href="#BoltzmannMachines.nomonitoring-Tuple{Any,Any}"><code>BoltzmannMachines.nomonitoring</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">nomonitoring</code></pre><p>Accepts a model and a number of epochs and returns nothing.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.nunits-Tuple{AbstractRBM}" href="#BoltzmannMachines.nunits-Tuple{AbstractRBM}"><code>BoltzmannMachines.nunits</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">nunits(bm)</code></pre><p>Returns an integer vector that contans in the i&#39;th entry the number of nodes in the i&#39;th layer of the <code>bm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.nvisiblenodes-Tuple{AbstractRBM}" href="#BoltzmannMachines.nvisiblenodes-Tuple{AbstractRBM}"><code>BoltzmannMachines.nvisiblenodes</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">nvisiblenodes(rbm)</code></pre><p>Returns the number of visible nodes for an RBM.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.piecewiselinearsequences-Tuple{Int64,Int64}" href="#BoltzmannMachines.piecewiselinearsequences-Tuple{Int64,Int64}"><code>BoltzmannMachines.piecewiselinearsequences</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">piecewiselinearsequences(nsequences, nvariables; ...)</code></pre><p>Generates a dataset consisting of samples with values that are piecewise linear functions of the variable index.</p><p>Optional named arguments: <code>pbreak</code>, <code>breakval</code>, see <code>piecewiselinearsequencebundles</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.randombatchmasks-Tuple{Int64,Int64}" href="#BoltzmannMachines.randombatchmasks-Tuple{Int64,Int64}"><code>BoltzmannMachines.randombatchmasks</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">randombatchmasks(nsamples, batchsize)</code></pre><p>Returns BitArray-Sets for the sample indices when training on a dataset with <code>nsamples</code> samples using minibatches of size <code>batchsize</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.ranges-Tuple{Array{Int64,1}}" href="#BoltzmannMachines.ranges-Tuple{Array{Int64,1}}"><code>BoltzmannMachines.ranges</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">ranges(numbers)</code></pre><p>Returns a vector of consecutive integer ranges, the first starting with 1. The i&#39;th such range spans over <code>numbers[i]</code> items.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.reversedrbm-Tuple{BernoulliGaussianRBM}" href="#BoltzmannMachines.reversedrbm-Tuple{BernoulliGaussianRBM}"><code>BoltzmannMachines.reversedrbm</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns the GBRBM with weights such that hidden and visible of the given <code>bgrbm</code> are switched and a visible standard deviation of 1.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.samplefrequencies-Union{Tuple{Array{T,2}}, Tuple{T}} where T" href="#BoltzmannMachines.samplefrequencies-Union{Tuple{Array{T,2}}, Tuple{T}} where T"><code>BoltzmannMachines.samplefrequencies</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">samplefrequencies(x)</code></pre><p>Returns a dictionary containing the rows of the data set <code>x</code> as keys and their relative frequencies as values.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.samplehiddenpotential!-Union{Tuple{M}, Tuple{M,AbstractXBernoulliRBM}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.samplehiddenpotential!-Union{Tuple{M}, Tuple{M,AbstractXBernoulliRBM}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.samplehiddenpotential!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">samplehiddenpotential!(h, rbm)</code></pre><p>Samples the activation of the hidden nodes from the potential <code>h</code> and stores the returned result in <code>h</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.samplevisiblepotential!-Union{Tuple{M}, Tuple{M,Union{BernoulliGaussianRBM, BernoulliRBM}}} where M&lt;:(AbstractArray{Float64,N} where N)" href="#BoltzmannMachines.samplevisiblepotential!-Union{Tuple{M}, Tuple{M,Union{BernoulliGaussianRBM, BernoulliRBM}}} where M&lt;:(AbstractArray{Float64,N} where N)"><code>BoltzmannMachines.samplevisiblepotential!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">samplehiddenpotential!(v, rbm)</code></pre><p>Samples the activation of the visible nodes from the potential <code>v</code> and stores the returned result in <code>v</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.stackrbms_preparetrainlayers-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractTrainLayer,Array{Float64,2},Int64,Float64,Array{Int64,1},Int64,AbstractOptimizer}" href="#BoltzmannMachines.stackrbms_preparetrainlayers-Tuple{Array{#s1708,1} where #s1708&lt;:AbstractTrainLayer,Array{Float64,2},Int64,Float64,Array{Int64,1},Int64,AbstractOptimizer}"><code>BoltzmannMachines.stackrbms_preparetrainlayers</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Prepares the layerwise training specifications for <code>stackrbms</code> </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.stackrbms_trainlayer-Tuple{Array{Float64,2},TrainLayer}" href="#BoltzmannMachines.stackrbms_trainlayer-Tuple{Array{Float64,2},TrainLayer}"><code>BoltzmannMachines.stackrbms_trainlayer</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Trains a layer without partitioning for <code>stackrbms</code>. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.stackrbms_trainlayer-Tuple{Array{Float64,2},TrainPartitionedLayer}" href="#BoltzmannMachines.stackrbms_trainlayer-Tuple{Array{Float64,2},TrainPartitionedLayer}"><code>BoltzmannMachines.stackrbms_trainlayer</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Trains a partitioned layer for <code>stackrbms</code>. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.unnormalizedlogprob-Tuple{Any,Array{Float64,2}}" href="#BoltzmannMachines.unnormalizedlogprob-Tuple{Any,Array{Float64,2}}"><code>BoltzmannMachines.unnormalizedlogprob</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">unnormalizedlogprob(mdbm, x; ...)</code></pre><p>Estimates the mean unnormalized log probability of the samples (rows in <code>x</code>) in the MultimodalDBM <code>mdbm</code> by running the Annealed Importance Sampling (AIS) in a smaller modified DBM for each sample.</p><p>The named optional arguments for AIS can be specified here. (See <code>aislogimpweights</code>)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.unnormalizedprobhidden-Tuple{BernoulliRBM,Array{Float64,1}}" href="#BoltzmannMachines.unnormalizedprobhidden-Tuple{BernoulliRBM,Array{Float64,1}}"><code>BoltzmannMachines.unnormalizedprobhidden</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">unnormalizedprobhidden(rbm, h)
unnormalizedprobhidden(gbrbm, h)</code></pre><p>Calculates the unnormalized probability of the <code>rbm</code>&#39;s hidden nodes&#39; activations given by <code>h</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.unnormalizedproboddlayers" href="#BoltzmannMachines.unnormalizedproboddlayers"><code>BoltzmannMachines.unnormalizedproboddlayers</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Computes the unnormalized probability of the nodes in layers with odd indexes, i. e. p*(v, h2, h4, ...).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.unnormalizedprobs-Tuple{Union{BernoulliGaussianRBM, BernoulliRBM},Array{Array{Float64,1},1}}" href="#BoltzmannMachines.unnormalizedprobs-Tuple{Union{BernoulliGaussianRBM, BernoulliRBM},Array{Array{Float64,1},1}}"><code>BoltzmannMachines.unnormalizedprobs</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">unnormalizedprobs(bm, samples)</code></pre><p>Calculates the unnormalized probabilities for all <code>samples</code> (vector of vectors), in the Boltzmann Machine <code>bm</code>.</p><p>The visible nodes of the <code>bm</code> must be Bernoulli distributed.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BoltzmannMachines.weightsinput!-Tuple{Array{Array{Float64,2},1},Array{Array{Float64,2},1},Array{#s1708,1} where #s1708&lt;:Union{BernoulliRBM, PartitionedRBM{BernoulliRBM}},Array{Array{Float64,2},1}}" href="#BoltzmannMachines.weightsinput!-Tuple{Array{Array{Float64,2},1},Array{Array{Float64,2},1},Array{#s1708,1} where #s1708&lt;:Union{BernoulliRBM, PartitionedRBM{BernoulliRBM}},Array{Array{Float64,2},1}}"><code>BoltzmannMachines.weightsinput!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">weightsinput!(input, input2, dbm, particles)</code></pre><p>Computes the input that results only from the weights (without biases) and the previous states in <code>particles</code> for all nodes in the DBM <code>dbm</code> and stores it in <code>input</code>. The state of the <code>particles</code> and the <code>dbm</code> is not altered. <code>input2</code> must have the same size as <code>input</code> and <code>particle</code>. For performance reasons, <code>input2</code> is used as preallocated space for storing intermediate results.</p></div></div></section><footer><hr/></footer></article></body></html>

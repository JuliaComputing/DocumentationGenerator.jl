<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings · Images.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Images.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Readme</a></li><li class="current"><a class="toctext" href>Docstrings</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Docstrings</a></li></ul></nav><hr/><div id="topbar"><span>Docstrings</span><a class="fa fa-bars" href="#"></a></div></header><p>Package doesn&#39;t contain Documenter docs.</p><p>Docs automatically generated by juliadocs.org</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.BlobLoG" href="#Images.BlobLoG"><code>Images.BlobLoG</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>BlobLoG stores information about the location of peaks as discovered by <code>blob_LoG</code>. It has fields:</p><ul><li>location: the location of a peak in the filtered image (a CartesianIndex)</li><li>σ: the value of σ which lead to the largest <code>-LoG</code>-filtered amplitude at this location</li><li>amplitude: the value of the <code>-LoG(σ)</code>-filtered image at the peak</li></ul><p>Note that the radius is equal to σ√2.</p><p>See also: <a href="#Images.blob_LoG-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,N},Union{Tuple, AbstractArray{T,1} where T}}, Tuple{AbstractArray{T,N},Union{Tuple, AbstractArray{T,1} where T},Tuple{Vararg{Bool,N} where N}}, Tuple{AbstractArray{T,N},Union{Tuple, AbstractArray{T,1} where T},Tuple{Vararg{Bool,N} where N},Any}} where N where T"><code>blob_LoG</code></a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.ColorizedArray-Union{Tuple{N}, Tuple{C}, Tuple{Any,IndirectArray{C,N,A,V} where V&lt;:AbstractArray{C,1} where A&lt;:(AbstractArray{#s834,N} where #s834&lt;:Integer)}} where N where C&lt;:Colorant" href="#Images.ColorizedArray-Union{Tuple{N}, Tuple{C}, Tuple{Any,IndirectArray{C,N,A,V} where V&lt;:AbstractArray{C,1} where A&lt;:(AbstractArray{#s834,N} where #s834&lt;:Integer)}} where N where C&lt;:Colorant"><code>Images.ColorizedArray</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">ColorizedArray(intensity, label::IndirectArray) -&gt; A</code></pre><p>Create an array, combining a <code>label</code> array (where each pixel is assigned one of a list of discrete colors) and an <code>intensity</code> array (where each pixel has a scalar value). <code>A</code> satisfies</p><pre><code class="language-none">A[i,j,...] = intensity[i,j,...] * label[i,j,...]</code></pre><p>The label array &quot;tinges&quot; the grayscale intensity with the color associated with that point&#39;s label.</p><p>This computation is performed lazily, as to be suitable even for large arrays.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.HomogeneousPoint" href="#Images.HomogeneousPoint"><code>Images.HomogeneousPoint</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>HomogeneousPoint(x::NTuple{N, T})</p><p>In projective geometry <a href="https://en.wikipedia.org/wiki/Homogeneous_coordinates">homogeneous coordinates</a> are the natural coordinates for describing points and lines.</p><p>For instance, the homogeneous coordinates for a planar point are a triplet of real numbers <span>$(u, v ,w)$</span>, with <span>$w \neq 0$</span>. This triple can be associated with a point <span>$P = (x,y)$</span> in Cartesian coordinates, where <span>$x = \frac{u}{w}$</span> and <span>$y = \frac{v}{w}$</span> <a href="http://www.geom.uiuc.edu/docs/reference/CRC-formulas/node6.html#SECTION01140000000000000000">(more details)</a>.</p><p>In particular, the <code>HomogeneousPoint((10.0,5.0,1.0))</code> is the standardised projective representation of the Cartesian point <code>(10.0,5.0)</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.Percentile" href="#Images.Percentile"><code>Images.Percentile</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Percentile(x)</code></pre><p>Indicate that <code>x</code> should be interpreted as a <a href="https://en.wikipedia.org/wiki/Percentile">percentile</a> rather than an absolute value. For example,</p><ul><li><code>canny(img, 1.4, (80, 20))</code> uses absolute thresholds on the edge magnitude image</li><li><code>canny(img, 1.4, (Percentile(80), Percentile(20)))</code> uses percentiles of the edge magnitude image as threshold</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ColorTypes.blue" href="#ColorTypes.blue"><code>ColorTypes.blue</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>b = blue(img)</code> extracts the blue channel from an RGB image <code>img</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ColorTypes.green" href="#ColorTypes.green"><code>ColorTypes.green</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>g = green(img)</code> extracts the green channel from an RGB image <code>img</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ColorTypes.red" href="#ColorTypes.red"><code>ColorTypes.red</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>r = red(img)</code> extracts the red channel from an RGB image <code>img</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.adjust_gamma-Union{Tuple{T}, Tuple{AbstractArray{Gray{T},N} where N,Number}} where T&lt;:Normed" href="#Images.adjust_gamma-Union{Tuple{T}, Tuple{AbstractArray{Gray{T},N} where N,Number}} where T&lt;:Normed"><code>Images.adjust_gamma</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">gamma_corrected_img = adjust_gamma(img, gamma)</code></pre><p>Returns a gamma corrected image.</p><p><strong>Details</strong></p><p>Gamma correction is a non-linear  transformation given by the relation</p><div>\[f(x) = x^\gamma \quad \text{for} \; x \in \mathbb{R}, \gamma &gt; 0.\]</div><p>It is called a <em>power law</em> transformation because one quantity varies as a power of another quantity.</p><p>Gamma correction has historically been used to preprocess an image to compensate for the fact that the intensity of light generated by a physical device is not usually a linear function of the applied signal but instead follows a power law [1]. For example, for many Cathode Ray Tubes (CRTs) the emitted light intensity on the display is approximately equal to the voltage raised to the power of γ, where γ ∈ [1.8, 2.8]. Hence preprocessing a raw image with an exponent of 1/γ  would have ensured a linear response to brightness.</p><p>Research in psychophysics has also established an <a href="https://en.wikipedia.org/wiki/Stevens%27s_power_law">empirical  power law </a>  between light intensity and perceptual brightness. Hence, gamma correction often serves as a useful image enhancement tool.</p><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The <code>adjust_gamma</code> function can handle a variety of input types. The returned image depends on the input type. If the input is an <code>Image</code> then the resulting image is of the same type and has the same properties.</p><p>For coloured images, the input is converted to YIQ type and the Y channel is gamma corrected. This is the combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choice for <code>gamma</code></strong></p><p>The <code>gamma</code> value must be a non-zero positive number.</p><p><strong>Example</strong></p><pre><code class="language-julia">using Images, ImageView

# Create an example image consisting of a linear ramp of intensities.
n = 32
intensities = 0.0:(1.0/n):1.0
img = repeat(intensities, inner=(20,20))&#39;

# Brighten the dark tones.
imgadj = adjust_gamma(img,1/2)

# Display the original and adjusted image.
imshow(img)
imshow(imgadj)</code></pre><p><strong>References</strong></p><ol><li>W. Burger and M. J. Burge. <em>Digital Image Processing</em>. Texts in Computer Science, 2016. <a href="https://doi.org/10.1007/978-1-4471-6684-9">doi:10.1007/978-1-4471-6684-9</a></li></ol><p>See also: <a href="@ref">histmatch</a>,<a href="@ref">clahe</a>, and <a href="@ref">imhist</a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.adjust_histogram" href="#Images.adjust_histogram"><code>Images.adjust_histogram</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">adjust_histogram(Matching(),img, targetimg, nbins)
adjust_histogram(Matching(),img, targetimg, edges)</code></pre><p>Returns a histogram matched image with a granularity of <code>nbins</code> number of bins. The first argument <code>img</code> is the image to be matched, and the second argument <code>targetimg</code> is the image having the desired histogram to be matched to.</p><p><strong>Details</strong></p><p>The purpose of histogram matching is to transform the intensities in a source image so that the intensities distribute according to the histogram of a specified target image. If one interprets histograms as piecewise-constant models of probability density functions (see <a href="#Images.build_histogram-Tuple{AbstractArray,Integer,Union{Real, Color{T,1} where T},Union{Real, Color{T,1} where T}}"><code>build_histogram</code></a>), then the histogram matching task can be modelled as the problem of transforming one probability distribution into another [1]. It turns out that the solution to this transformation problem involves the cumulative and inverse cumulative distribution functions of the source and target probability density functions.</p><p>In particular, let the random variables <span>$x \thicksim p_{x}$</span> and <span>$z \thicksim p_{z}$</span>  represent an intensity in the source and target image respectively, and let</p><div>\[ S(x) = \int_0^{x}p_{x}(w)\mathrm{d} w \quad \text{and} \quad
 T(z) = \int_0^{z}p_{z}(w)\mathrm{d} w\]</div><p>represent their concomitant cumulative disitribution functions. Then the sought-after mapping <span>$Q(\cdot)$</span> such that <span>$Q(x) \thicksim p_{z}$</span> is given by</p><div>\[Q(x) =  T^{-1}\left( S(x) \right),\]</div><p>where <span>$T^{-1}(y) = \operatorname{min} \{ x \in \mathbb{R} : y \leq T(x) \}$</span> is the inverse cumulative distribution function of <span>$T(x)$</span>.</p><p>The mapping suggests that one can conceptualise histogram matching as performing histogram equalisation on the source and target image and relating the two equalised histograms. Refer to <a href="#Images.adjust_histogram"><code>adjust_histogram</code></a> for more details on histogram equalisation.</p><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code> and <code>targetimg</code></strong></p><p>The <code>adjust_histogram(Matching(),...)</code> function can handle a variety of input types. The type of the returned image matches the input type.</p><p>For colored images, the inputs are converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a>  type and the distributions of the Y channels are matched. The modified Y channel is then combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram. If you do not specify the number of bins then a default value of 256 bins is utilised.</p><p><strong>Choices for <code>edges</code></strong></p><p>If you do not designate the number of bins, then you have the option to directly stipulate how the intervals will be divided by specifying a <a href="@ref"><code>range</code></a> type.</p><p><strong>Example</strong></p><pre><code class="language-julia">using Images, TestImages, ImageView

img_source = testimage(&quot;mandril_gray&quot;)
img_target = adjust_gamma(img_source,1/2)
img_transformed = adjust_histogram(Matching(),img_source, img_target)
#=
    A visual inspection confirms that img_transformed resembles img_target
    much more closely than img_source.
=#
imshow(img_source)
imshow(img_target)
imshow(img_transformed)</code></pre><p><strong>References</strong></p><ol><li>W. Burger and M. J. Burge. <em>Digital Image Processing</em>. Texts in Computer Science, 2016. <a href="https://doi.org/10.1007/978-1-4471-6684-9">doi:10.1007/978-1-4471-6684-9</a></li></ol><p>See also:</p><table><tr><th>Histogram Equalization</th><th>Histogram Matching</th><th>Histogram Construction</th></tr><tr><td><a href="#Images.adjust_histogram"><code>adjust_histogram</code></a></td><td><a href="#Images.adjust_histogram"><code>adjust_histogram!</code></a></td><td><a href="#Images.build_histogram-Tuple{AbstractArray,Integer,Union{Real, Color{T,1} where T},Union{Real, Color{T,1} where T}}"><code>build_histogram</code></a></td></tr><tr><td><a href="#Images.adjust_histogram!"><code>adjust_histogram!</code></a></td><td></td><td></td></tr></table></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.adjust_histogram" href="#Images.adjust_histogram"><code>Images.adjust_histogram</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">adjust_histogram(Equalization(),img, nbins)
adjust_histogram(Equalization(),img, nbins, minval, maxval)</code></pre><p>Returns a histogram equalised image with a granularity of <code>nbins</code> number of bins.</p><p><strong>Details</strong></p><p>Histogram equalisation was initially conceived to  improve the contrast in a single-channel grayscale image. The method transforms the distribution of the intensities in an image so that they are as uniform as possible [1]. The natural justification for uniformity is that the image has better contrast  if the intensity levels of an image span a wide range on the intensity scale. As it turns out, the necessary transformation is a mapping based on the cumulative histogram.</p><p>One can consider an <span>$L$</span>-bit single-channel <span>$I \times J$</span> image with gray values in the set <span>$\{0,1,\ldots,L-1 \}$</span>, as a collection of independent and identically distributed random variables. Specifically, let the sample space <span>$\Omega$</span> be the set of all <span>$IJ$</span>-tuples <span>$\omega =(\omega_{11},\omega_{12},\ldots,\omega_{1J},\omega_{21},\omega_{22},\ldots,\omega_{2J},\omega_{I1},\omega_{I2},\ldots,\omega_{IJ})$</span>, where each <span>$\omega_{ij} \in \{0,1,\ldots, L-1 \}$</span>. Furthermore, impose a probability measure on <span>$\Omega$</span> such that the functions <span>$\Omega \ni \omega \to \omega_{ij} \in \{0,1,\ldots,L-1\}$</span> are independent and identically distributed.</p><p>One can then regard an image as a matrix of random variables <span>$\mathbf{G} = [G_{i,j}(\omega)]$</span>, where each function <span>$G_{i,j}: \Omega \to \mathbb{R}$</span> is defined by</p><div>\[G_{i,j}(\omega) = \frac{\omega_{ij}}{L-1},\]</div><p>and each <span>$G_{i,j}$</span> is distributed according to some unknown density <span>$f_{G}$</span>. While <span>$f_{G}$</span> is unknown, one can approximate it with a normalised histogram of gray levels,</p><div>\[\hat{f}_{G}(v)= \frac{n_v}{IJ},\]</div><p>where</p><div>\[n_v = \left | \left\{(i,j)\, |\,  G_{i,j}(\omega)  = v \right \} \right |\]</div><p>represents the number of times a gray level with intensity <span>$v$</span> occurs in <span>$\mathbf{G}$</span>. To transforming the distribution of the intensities so that they are as uniform as possible one needs to find a mapping <span>$T(\cdot)$</span> such that <span>$T(G_{i,j}) \thicksim U$</span>. The required mapping turns out to be the cumulative distribution function (CDF) of the empirical density <span>$\hat{f}_{G}$</span>,</p><div>\[ T(G_{i,j}) = \int_0^{G_{i,j}}\hat{f}_{G}(w)\mathrm{d} w.\]</div><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The <code>adjust_histogram(Equalization(),...)</code> function can handle a variety of input types.  The type of the returned image matches the input type.</p><p>For coloured images, the input is converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a> type and the Y channel is equalised. This is the combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram.</p><p><strong>Choices for <code>minval</code> and <code>maxval</code></strong></p><p>If minval and maxval are specified then intensities are equalized to the range [minval, maxval]. The default values are 0 and 1.</p><p><strong>Example</strong></p><pre><code class="language-julia">
using TestImages, FileIO, ImageView

img =  testimage(&quot;mandril_gray&quot;);
imgeq = adjust_histogram(Equalization(),img,256,0,1);

imshow(img)
imshow(imgeq)</code></pre><p><strong>References</strong></p><ol><li>R. C. Gonzalez and R. E. Woods. <em>Digital Image Processing (3rd Edition)</em>.  Upper Saddle River, NJ, USA: Prentice-Hall,  2006.</li></ol><p>See also:</p><table><tr><th>Histogram Equalization</th><th>Histogram Matching</th><th>Histogram Construction</th></tr><tr><td><a href="#Images.adjust_histogram!"><code>adjust_histogram!</code></a></td><td><a href="#Images.adjust_histogram"><code>adjust_histogram</code></a></td><td><a href="#Images.build_histogram-Tuple{AbstractArray,Integer,Union{Real, Color{T,1} where T},Union{Real, Color{T,1} where T}}"><code>build_histogram</code></a></td></tr><tr><td></td><td><a href="#Images.adjust_histogram!"><code>adjust_histogram!</code></a></td><td></td></tr></table></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.adjust_histogram!" href="#Images.adjust_histogram!"><code>Images.adjust_histogram!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">adjust_histogram!(Matching(),img, targetimg, nbins)
adjust_histogram!(Matching(),img, targetimg, edges)</code></pre><p>Same as  <a href="#Images.adjust_histogram"><code>adjust_histogram</code></a>  except that it modifies the image that was passed as an argument.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.adjust_histogram!" href="#Images.adjust_histogram!"><code>Images.adjust_histogram!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">adjust_histogram!(Equalization(),img, nbins)
adjust_histogram!(Equalization(),img, nbins, minval, maxval)</code></pre><p>Same as <a href="#Images.adjust_histogram"><code>adjust_histogram</code></a> except that it modifies the image that was passed as an argument.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.bilinear_interpolation-Union{Tuple{T}, Tuple{AbstractArray{T,2},Number,Number}} where T" href="#Images.bilinear_interpolation-Union{Tuple{T}, Tuple{AbstractArray{T,2},Number,Number}} where T"><code>Images.bilinear_interpolation</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">P = bilinear_interpolation(img, r, c)</code></pre><p>Bilinear Interpolation is used to interpolate functions of two variables on a rectilinear 2D grid.</p><p>The interpolation is done in one direction first and then the values obtained are used to do the interpolation in the second direction.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.blob_LoG-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,N},Union{Tuple, AbstractArray{T,1} where T}}, Tuple{AbstractArray{T,N},Union{Tuple, AbstractArray{T,1} where T},Tuple{Vararg{Bool,N} where N}}, Tuple{AbstractArray{T,N},Union{Tuple, AbstractArray{T,1} where T},Tuple{Vararg{Bool,N} where N},Any}} where N where T" href="#Images.blob_LoG-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,N},Union{Tuple, AbstractArray{T,1} where T}}, Tuple{AbstractArray{T,N},Union{Tuple, AbstractArray{T,1} where T},Tuple{Vararg{Bool,N} where N}}, Tuple{AbstractArray{T,N},Union{Tuple, AbstractArray{T,1} where T},Tuple{Vararg{Bool,N} where N},Any}} where N where T"><code>Images.blob_LoG</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">blob_LoG(img, σscales, [edges], [σshape]) -&gt; Vector{BlobLoG}</code></pre><p>Find &quot;blobs&quot; in an N-D image using the negative Lapacian of Gaussians with the specifed vector or tuple of σ values. The algorithm searches for places where the filtered image (for a particular σ) is at a peak compared to all spatially- and σ-adjacent voxels, where σ is <code>σscales[i] * σshape</code> for some i. By default, <code>σshape</code> is an ntuple of 1s.</p><p>The optional <code>edges</code> argument controls whether peaks on the edges are included. <code>edges</code> can be <code>true</code> or <code>false</code>, or a N+1-tuple in which the first entry controls whether edge-σ values are eligible to serve as peaks, and the remaining N entries control each of the N dimensions of <code>img</code>.</p><p><strong>Citation:</strong></p><p>Lindeberg T (1998), &quot;Feature Detection with Automatic Scale Selection&quot;, International Journal of Computer Vision, 30(2), 79–116.</p><p>See also: <a href="#Images.BlobLoG"><code>BlobLoG</code></a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.boxdiff-Union{Tuple{T}, Tuple{AbstractArray{T,2},UnitRange,UnitRange}} where T" href="#Images.boxdiff-Union{Tuple{T}, Tuple{AbstractArray{T,2},UnitRange,UnitRange}} where T"><code>Images.boxdiff</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">sum = boxdiff(integral_image, ytop:ybot, xtop:xbot)
sum = boxdiff(integral_image, CartesianIndex(tl_y, tl_x), CartesianIndex(br_y, br_x))
sum = boxdiff(integral_image, tl_y, tl_x, br_y, br_x)</code></pre><p>An integral image is a data structure which helps in efficient calculation of sum of pixels in a rectangular subset of an image. It stores at each pixel the sum of all pixels above it and to its left. The sum of a window in an image can be directly calculated using four array references of the integral image, irrespective of the size of the window, given the <code>yrange</code> and <code>xrange</code> of the window. Given an integral image -</p><pre><code class="language-none">    A - - - - - - B -
    - * * * * * * * -
    - * * * * * * * -
    - * * * * * * * -
    - * * * * * * * -
    - * * * * * * * -
    C * * * * * * D -
    - - - - - - - - -</code></pre><p>The sum of pixels in the area denoted by * is given by S = D + A - B - C.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.build_histogram-Tuple{AbstractArray,Integer,Union{Real, Color{T,1} where T},Union{Real, Color{T,1} where T}}" href="#Images.build_histogram-Tuple{AbstractArray,Integer,Union{Real, Color{T,1} where T},Union{Real, Color{T,1} where T}}"><code>Images.build_histogram</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">edges, count = build_histogram(img, nbins)
edges, count = build_histogram(img, nbins, minval, maxval)
edges, count = build_histogram(img, edges)</code></pre><p>Generates a histogram for the image over <code>nbins</code> spread between <code>[minval, maxval]</code>. Color images are automatically converted to grayscale.</p><p><strong>Output</strong></p><p>Returns <code>edges</code> which is a <a href="@ref"><code>range</code></a> type that specifies how the  interval <code>[minval, maxval]</code> is divided into bins, and an array <code>count</code> which records the concomitant bin frequencies. In particular, <code>count</code> has the following properties:</p><ul><li><code>count[0]</code> is the number satisfying <code>x &lt; edges[1]</code></li><li><code>count[i]</code> is the number of values <code>x</code> that satisfy <code>edges[i] &lt;= x &lt; edges[i+1]</code></li><li><code>count[end]</code> is the number satisfying <code>x &gt;= edges[end]</code>.</li><li><code>length(count) == length(edges)+1</code>.</li></ul><p><strong>Details</strong></p><p>One can consider a histogram as a piecewise-constant model of a probability density function <span>$f$</span> [1]. Suppose that <span>$f$</span> has support on some interval <span>$I = [a,b]$</span>.  Let <span>$m$</span> be an integer and <span>$a = a_1 &lt; a_2 &lt; \ldots &lt; a_m &lt; a_{m+1} = b$</span> a sequence of real numbers. Construct a sequence of intervals</p><div>\[I_1 = [a_1,a_2], I_2 = (a_2, a_3], \ldots, I_{m} = (a_m,a_{m+1}]\]</div><p>which partition <span>$I$</span> into subsets <span>$I_j$</span> <span>$(j = 1, \ldots, m)$</span> on which <span>$f$</span> is constant. These subsets satisfy <span>$I_i \cap I_j = \emptyset, \forall i \neq j$</span>, and are commonly referred to as <em>bins</em>. Together they encompass the entire range of data values such that <span>$\sum_j |I_j | = | I |$</span>. Each bin has width <span>$w_j = |I_j| = a_{j+1} - a_j$</span> and height <span>$h_j$</span> which is the constant probability density over the region of the bin. Integrating the constant probability density over the width of the bin <span>$w_j$</span> yields a probability mass of <span>$\pi_j = h_j w_j$</span> for the bin.</p><p>For a sample <span>$x_1, x_2, \ldots, x_N$</span>, let</p><div>\[n_j = \sum_{n = 1}^{N}\mathbf{1}_{(I_j)}(x_n),
\quad \text{where} \quad
\mathbf{1}_{(I_j)}(x) =
\begin{cases}
 1 &amp; \text{if} x \in I_j,\\
 0 &amp; \text{otherwise},
\end{cases},\]</div><p>represents the number of samples falling into the interval <span>$I_j$</span>. An estimate for the probability mass of the <span>$j$</span>th bin is given by the relative frequency <span>$\hat{\pi} = \frac{n_j}{N}$</span>, and the histogram estimator of the probability density function is defined as</p><div>\[\begin{aligned}
\hat{f}_n(x)  &amp; = \sum_{j = 1}^{m}\frac{n_j}{Nw_j} \mathbf{1}_{(I_j)}(x) \\
&amp; = \sum_{j = 1}^{m}\frac{\hat{\pi}_j}{w_j} \mathbf{1}_{(I_j)}(x) \\
&amp; = \sum_{j = 1}^{m}\hat{h}_j \mathbf{1}_{(I_j)}(x).
\end{aligned}\]</div><p>The function <span>$\hat{f}_n(x)$</span> is a genuine density estimator because <span>$\hat{f}_n(x)  \ge 0$</span> and</p><div>\[\begin{aligned}
\int_{-\infty}^{\infty}\hat{f}_n(x) \operatorname{d}x &amp; = \sum_{j=1}^{m} \frac{n_j}{Nw_j} w_j \\
&amp; = 1.
\end{aligned}\]</div><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the number of discrete bins for the histogram. When specifying the number of bins consider the maximum number of greylevels that your image type supports. For example, with an image of type <code>N0f8</code> there is a maximum of 256 possible graylevels. Hence, if you request more than 256 bins for that type of image you should expect to obtain zero counts for numerous bins.</p><p><strong>Choices for <code>minval</code></strong></p><p>You have the option to specify the lower bound of the interval over which the histogram will be computed.  If <code>minval</code> is not specified then the minimum value present in the image is taken as the lower bound.</p><p><strong>Choices for <code>maxval</code></strong></p><p>You have the option to specify the upper bound of the interval over which the histogram will be computed.  If <code>maxval</code> is not specified then the maximum value present in the image is taken as the upper bound.</p><p><strong>Choices for <code>edges</code></strong></p><p>If you do not designate the number of bins, nor the lower or upper bound of the interval, then you have the option to directly stipulate how the intervals will be divided by specifying a <a href="@ref"><code>range</code></a> type.</p><p><strong>Example</strong></p><p>Compute the histogram of a grayscale image.</p><pre><code class="language-julia">
using TestImages, FileIO, ImageView

img =  testimage(&quot;mandril_gray&quot;);
edges, counts  = build_histogram(img,256,0,1)</code></pre><p>Given a color image, compute the histogram of the red channel.</p><pre><code class="language-julia">img = testimage(&quot;mandrill&quot;)
r = red.(img)
edges, counts  = build_histogram(r,256,0,1)</code></pre><p><strong>References</strong></p><p>[1] E. Herrholz, &quot;Parsimonious Histograms,&quot; Ph.D. dissertation, Inst. of Math. and Comp. Sci., University of Greifswald, Greifswald, Germany, 2011.</p><p>See also:</p><table><tr><th>Histogram Equalization</th><th>Histogram Matching</th></tr><tr><td><a href="#Images.adjust_histogram"><code>adjust_histogram</code></a></td><td><a href="#Images.adjust_histogram"><code>adjust_histogram</code></a></td></tr><tr><td><a href="#Images.adjust_histogram!"><code>adjust_histogram!</code></a></td><td><a href="#Images.adjust_histogram!"><code>adjust_histogram!</code></a></td></tr></table></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.canny-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,2},Tuple{N,N}}, Tuple{AbstractArray{T,2},Tuple{N,N},Number}} where N&lt;:Union{Number, Color{T,1} where T} where T&lt;:Union{Number, Color{T,1} where T}" href="#Images.canny-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,2},Tuple{N,N}}, Tuple{AbstractArray{T,2},Tuple{N,N},Number}} where N&lt;:Union{Number, Color{T,1} where T} where T&lt;:Union{Number, Color{T,1} where T}"><code>Images.canny</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">canny_edges = canny(img, (upper, lower), sigma=1.4)</code></pre><p>Performs Canny Edge Detection on the input image.</p><p>Parameters :</p><p>(upper, lower) :  Bounds for hysteresis thresholding   sigma :           Specifies the standard deviation of the gaussian filter</p><p><strong>Example</strong></p><pre><code class="language-julia">imgedg = canny(img, (Percentile(80), Percentile(20)))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.clahe-Union{Tuple{AbstractArray{C,2}}, Tuple{C}, Tuple{AbstractArray{C,2},Integer}} where C" href="#Images.clahe-Union{Tuple{AbstractArray{C,2}}, Tuple{C}, Tuple{AbstractArray{C,2},Integer}} where C"><code>Images.clahe</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">hist_equalised_img = clahe(img, nbins, xblocks = 8, yblocks = 8, clip = 3)
</code></pre><p>Performs Contrast Limited Adaptive Histogram Equalisation (CLAHE) on the input image. It differs from ordinary histogram equalization in the respect that the adaptive method computes several histograms, each corresponding to a distinct section of the image, and uses them to redistribute the lightness values of the image. It is therefore suitable for improving the local contrast and enhancing the definitions of edges in each region of an image.</p><p><strong>Details</strong></p><p>Histogram equalisation was initially conceived to  improve the contrast in a single-channel grayscale image. The method transforms the distribution of the intensities in an image so that they are as uniform as possible [1]. The natural justification for uniformity is that the image has better contrast  if the intensity levels of an image span a wide range on the intensity scale. As it turns out, the necessary transformation is a mapping based on the cumulative histogram–-see <a href="@ref">histeq</a> for more details.</p><p>A natural extension of histogram equalisation is to apply the contrast enhancement locally rather than globally [2]. Conceptually, one can imagine that the process involves partitioning the image into a grid of rectangular regions and applying histogram equalisation based on the local CDF of each contextual region. However, to smooth the transition of the pixels from one contextual region to another,  the mapping of a pixel is not done soley based on the local CDF of its contextual region. Rather, the mapping of a pixel is a bilinear blend based on the CDF of its contextual region, and the CDFs of the immediate neighbouring regions.</p><p>In adaptive histogram equalisation the image <span>$\mathbf{G}$</span> is partitioned into <span>$P \times Q$</span> equisized submatrices,</p><div>\[\mathbf{G} =  \begin{bmatrix}
\mathbf{G}_{11} &amp; \mathbf{G}_{12} &amp; \ldots &amp; \mathbf{G}_{1C} \\
\mathbf{G}_{21} &amp; \mathbf{G}_{22} &amp; \ldots &amp; \mathbf{G}_{2C} \\
\vdots &amp; \vdots &amp; \ldots &amp; \vdots \\
\mathbf{G}_{R1} &amp; \mathbf{G}_{R2} &amp; \ldots &amp; \mathbf{G}_{RC} \\
\end{bmatrix}.\]</div><p>For each submatrix <span>$\mathbf{G}_{rc}$</span>, one computes a concomitant CDF, which we shall denote by <span>$T_{rc}(G_{i,j})$</span>. In order to determine which CDFs will be used in the bilinear interpolation step, it is useful to  introduce the function</p><div>\[\Phi(\mathbf{G}_{rc}) = \left(  \phi_{rc},  \phi&#39;_{rc}\right) \triangleq \left(\frac{rP}{2}, \frac{cQ}{2} \right)\]</div><p>and to form the sequences  <span>$\left(\phi_{11}, \phi_{21}, \ldots, \phi_{R1} \right)$</span> and <span>$\left(\phi&#39;_{11}, \phi&#39;_{12}, \ldots, \phi&#39;_{1C} \right)$</span>. For a given pixel <span>$G_{i,j}(\omega)$</span>, values of <span>$r$</span> and <span>$c$</span> are implicitly defined by the solution to the inequalities</p><div>\[\phi_{r1} \le i \le \phi_{(r+1)1}  \quad \text{and}  \quad  \phi&#39;_{1c} \le j \le \phi&#39;_{1(c+1)}.\]</div><p>With <span>$r$</span> and <span>$c$</span> appropriately defined, the requisite CDFs are given by</p><div>\[\begin{aligned}
T_1(v)  &amp; \triangleq  T_{rc}(G_{i,j}) \\
T_2(v)  &amp; \triangleq  T_{(r+1)c}(G_{i,j}) \\
T_3(v)  &amp; \triangleq  T_{(r+1)(c+1)}(G_{i,j}) \\
T_4(v)  &amp; \triangleq  T_{r(c+1)}(G_{i,j}).
\end{aligned}\]</div><p>Finally, with</p><div>\[\begin{aligned}
t  &amp; \triangleq  \frac{i - \phi_{r1}}{\phi_{(r+1)1} - \phi_{r1} } \\
u  &amp; \triangleq  \frac{j - \phi&#39;_{1c}}{\phi&#39;_{1(c+1)} - \phi&#39;_{1c} },
\end{aligned}\]</div><p>the bilinear interpolated transformation that maps an intensity <span>$v$</span> at location <span>$(i,j)$</span> in the image to an intensity <span>$v&#39;$</span> is given by [3]</p><div>\[v&#39; \triangleq \bar{T}(v)  = (1-t) (1-u)T_1(G_{i,j}) + t(1-u)T_2(G_{i,j}) + tuT_3(G_{i,j}) +(1-t)uT_4(G_{i,j}).\]</div><p>An unfortunate side-effect of contrast enhancement is that it has a tendency to amplify the level of noise in an image, especially when the magnitude of the contrast enhancement is very high. The magnitude of contrast enhancement is associated with the gradient of <span>$T(\cdot)$</span>, because the  gradient determines the extent to which consecutive input intensities are stretched across the grey-level spectrum. One can diminish the level of noise amplification by limiting the magnitude of the contrast enhancement, that is, by limiting the magnitude of the gradient.</p><p>Since the derivative of <span>$T(\cdot)$</span> is the empirical density <span>$\hat{f}_{G}$</span>, the slope of the mapping function at any input intensity is proportional to the height of the histogram  <span>$\hat{f}_{G}$</span> at that intensity.  Therefore, limiting the slope of the local mapping function is equivalent to clipping the height of the histogram. A detailed description of the  implementation  details of the clipping process can be found in [2].</p><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The <code>clahe</code> function can handle a variety of input types. The returned image depends on the input type. If the input is an <code>Image</code> then the resulting image is of the same type and has the same properties.</p><p>For coloured images, the input is converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a> type and the Y channel is equalised. This is the combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram of each local region.</p><p><strong>Choices for <code>xblocks</code> and <code>yblocks</code></strong></p><p>The <code>xblocks</code> and <code>yblocks</code> specify the number of blocks to divide the input image into in each direction. By default both values are set to eight.</p><p><strong>Choices for <code>clip</code></strong></p><p>The <code>clip</code> parameter specifies the value at which the histogram is clipped.  The default value is three. The excess in the histogram bins with value exceeding <code>clip</code> is redistributed among the other bins.</p><p><strong>Example</strong></p><pre><code class="language-julia">
using Images, TestImages, ImageView

img =  testimage(&quot;mandril_gray&quot;)
imgeq = clahe(img,256, xblocks = 50, yblocks = 50)

imshow(img)
imshow(imgeq)</code></pre><p><strong>References</strong></p><ol><li>R. C. Gonzalez and R. E. Woods. <em>Digital Image Processing (3rd Edition)</em>.  Upper Saddle River, NJ, USA: Prentice-Hall,  2006.</li><li>S. M. Pizer, E. P. Amburn, J. D. Austin, R. Cromartie, A. Geselowitz, T. Greer, B. ter Haar Romeny, J. B. Zimmerman and K. Zuiderveld “Adaptive histogram equalization and its variations,” <em>Computer Vision, Graphics, and Image Processing</em>, vol. 38, no. 1, p. 99, Apr. 1987. <a href="https://doi.org/10.1016/s0734-189x(87)80156-1">10.1016/S0734-189X(87)80186-X</a></li><li>W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery.  <em>Numerical Recipes: The Art of Scientific Computing (3rd Edition)</em>. New York, NY, USA: Cambridge University Press, 2007.</li></ol><p>See also: <a href="@ref">histmatch</a>,<a href="@ref">histeq</a>, <a href="@ref">imhist</a> and  <a href="@ref">adjust_gamma</a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.clearborder" href="#Images.clearborder"><code>Images.clearborder</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">cleared_img = clearborder(img)
cleared_img = clearborder(img, width)
cleared_img = clearborder(img, width, background)</code></pre><p>Returns a copy of the original image after clearing objects connected to the border of the image.</p><p>Parameters:</p><ul><li>img          = Binary/Grayscale input image</li><li>width        = Width of the border examined (Default value is 1)</li><li>background   = Value to be given to pixels/elements that are cleared (Default value is 0)</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.cliphist-Union{Tuple{T}, Tuple{AbstractArray{T,1},Number}} where T" href="#Images.cliphist-Union{Tuple{T}, Tuple{AbstractArray{T,1},Number}} where T"><code>Images.cliphist</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">clipped_hist = cliphist(hist, clip)</code></pre><p>Clips the histogram above a certain value <code>clip</code>. The excess left in the bins exceeding <code>clip</code> is redistributed among the remaining bins.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.complement-Tuple{Union{Number, Colorant}}" href="#Images.complement-Tuple{Union{Number, Colorant}}"><code>Images.complement</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">y = complement(x)</code></pre><p>Take the complement <code>1-x</code> of <code>x</code>.  If <code>x</code> is a color with an alpha channel, the alpha channel is left untouched. Don&#39;t forget to add a dot when <code>x</code> is an array: <code>complement.(x)</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.component_boxes-Tuple{AbstractArray{Int64,N} where N}" href="#Images.component_boxes-Tuple{AbstractArray{Int64,N} where N}"><code>Images.component_boxes</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>component_boxes(labeled_array)</code> -&gt; an array of bounding boxes for each label, including the background label 0</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.component_centroids-Union{Tuple{AbstractArray{Int64,N}}, Tuple{N}} where N" href="#Images.component_centroids-Union{Tuple{AbstractArray{Int64,N}}, Tuple{N}} where N"><code>Images.component_centroids</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>component_centroids(labeled_array)</code> -&gt; an array of centroids for each label, including the background label 0</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.component_indices-Tuple{AbstractArray{Int64,N} where N}" href="#Images.component_indices-Tuple{AbstractArray{Int64,N} where N}"><code>Images.component_indices</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>component_indices(labeled_array)</code> -&gt; an array of pixels for each label, including the background label 0</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.component_lengths-Tuple{AbstractArray{Int64,N} where N}" href="#Images.component_lengths-Tuple{AbstractArray{Int64,N} where N}"><code>Images.component_lengths</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>component_lengths(labeled_array)</code> -&gt; an array of areas (2D), volumes (3D), etc. for each label, including the background label 0</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.component_subscripts-Tuple{AbstractArray{Int64,N} where N}" href="#Images.component_subscripts-Tuple{AbstractArray{Int64,N} where N}"><code>Images.component_subscripts</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>component_subscripts(labeled_array)</code> -&gt; an array of pixels for each label, including the background label 0</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.convexhull-Union{Tuple{AbstractArray{T,2}}, Tuple{T}} where T&lt;:Union{Gray{Bool}, Bool}" href="#Images.convexhull-Union{Tuple{AbstractArray{T,2}}, Tuple{T}} where T&lt;:Union{Gray{Bool}, Bool}"><code>Images.convexhull</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">chull = convexhull(img)</code></pre><p>Computes the convex hull of a binary image and returns the vertices of convex hull as a CartesianIndex array.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.corner2subpixel-Tuple{AbstractArray{T,2} where T,AbstractArray{Bool,2}}" href="#Images.corner2subpixel-Tuple{AbstractArray{T,2} where T,AbstractArray{Bool,2}}"><code>Images.corner2subpixel</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">corners = corner2subpixel(responses::AbstractMatrix,corner_indicator::AbstractMatrix{Bool})
        -&gt; Vector{HomogeneousPoint{Float64,3}}</code></pre><p>Refines integer corner coordinates to sub-pixel precision.</p><p>The function takes as input a matrix representing corner responses and a boolean indicator matrix denoting the integer coordinates of a corner in the image. The output is a vector of type <a href="#Images.HomogeneousPoint"><code>HomogeneousPoint</code></a> storing the sub-pixel coordinates of the corners.</p><p>The algorithm computes a correction factor which is added to the original integer coordinates. In particular, a univariate quadratic polynomial is fit separately to the <span>$x$</span>-coordinates and <span>$y$</span>-coordinates of a corner and its immediate east/west, and north/south neighbours. The fit is achieved using a local coordinate system for each corner, where the origin of the coordinate system is a given corner, and its immediate neighbours are assigned coordinates of  minus one and plus one.</p><p>The corner and its two neighbours form a system of three equations. For example, let  <span>$x_1 = -1$</span>,  <span>$x_2 = 0$</span> and  <span>$x_3 = 1$</span> denote the local <span>$x$</span> coordinates of the west, center and east pixels and let the vector <span>$\mathbf{b} = [r_1, r_2, r_3]$</span> denote the corresponding corner response values. With</p><div>\[    \mathbf{A} =
        \begin{bmatrix}
            x_1^2 &amp; x_1  &amp; 1  \\
            x_2^2 &amp; x_2  &amp; 1 \\
            x_3^2 &amp; x_3  &amp; 1 \\
        \end{bmatrix},\]</div><p>the coefficients of the quadratic polynomial can be found by solving the system of equations <span>$\mathbf{b} = \mathbf{A}\mathbf{x}$</span>. The result is given by <span>$x = \mathbf{A}^{-1}\mathbf{b}$</span>.</p><p>The vertex of the quadratic polynomial yields a sub-pixel estimate of the true corner position. For example, for a univariate quadratic polynomial <span>$px^2 + qx + r$</span>, the <span>$x$</span>-coordinate of the vertex is <span>$\frac{-q}{2p}$</span>. Hence, the refined sub-pixel coordinate is equal to:  <span>$c +  \frac{-q}{2p}$</span>, where <span>$c$</span> is the integer coordinate.</p><div class="admonition note"><div class="admonition-title">Note</div><div class="admonition-text"><p>Corners on the boundary of the image are not refined to sub-pixel precision.</p></div></div></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.entropy-Tuple{AbstractArray}" href="#Images.entropy-Tuple{AbstractArray}"><code>Images.entropy</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">entropy(logᵦ, img)
entropy(img; [kind=:shannon])</code></pre><p>Compute the entropy of a grayscale image defined as <code>-sum(p.*logᵦ(p))</code>. The base β of the logarithm (a.k.a. entropy unit) is one of the following:</p><ul><li><code>:shannon</code> (log base 2, default), or use logᵦ = log2</li><li><code>:nat</code> (log base e), or use logᵦ = log</li><li><code>:hartley</code> (log base 10), or use logᵦ = log10</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.fastcorners-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}, Tuple{AbstractArray{T,N} where N,Int64}, Tuple{AbstractArray{T,N} where N,Int64,Float64}} where T" href="#Images.fastcorners-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}, Tuple{AbstractArray{T,N} where N,Int64}, Tuple{AbstractArray{T,N} where N,Int64,Float64}} where T"><code>Images.fastcorners</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">fastcorners(img, n, threshold) -&gt; corners</code></pre><p>Performs FAST Corner Detection. <code>n</code> is the number of contiguous pixels which need to be greater (lesser) than intensity + threshold (intensity - threshold) for a pixel to be marked as a corner. The default value for n is 12.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.findlocalmaxima" href="#Images.findlocalmaxima"><code>Images.findlocalmaxima</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>findlocalmaxima(img, [region, edges]) -&gt; Vector{CartesianIndex}</code></p><p>Returns the coordinates of elements whose value is larger than all of their immediate neighbors.  <code>region</code> is a list of dimensions to consider.  <code>edges</code> is a boolean specifying whether to include the first and last elements of each dimension, or a tuple-of-Bool specifying edge behavior for each dimension separately.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.findlocalminima" href="#Images.findlocalminima"><code>Images.findlocalminima</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Like <code>findlocalmaxima</code>, but returns the coordinates of the smallest elements.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.gaussian_pyramid-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,N},Int64,Real,Real}} where N where T" href="#Images.gaussian_pyramid-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,N},Int64,Real,Real}} where N where T"><code>Images.gaussian_pyramid</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">pyramid = gaussian_pyramid(img, n_scales, downsample, sigma)</code></pre><p>Returns a  gaussian pyramid of scales <code>n_scales</code>, each downsampled by a factor <code>downsample</code> &gt; 1 and <code>sigma</code> for the gaussian kernel.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.harris-Tuple{AbstractArray}" href="#Images.harris-Tuple{AbstractArray}"><code>Images.harris</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">harris_response = harris(img; [k], [border], [weights])</code></pre><p>Performs Harris corner detection. The covariances can be taken using either a mean weighted filter or a gamma kernel.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.histeq-Tuple{AbstractArray,Integer,Union{Real, Color{T,1} where T},Union{Real, Color{T,1} where T}}" href="#Images.histeq-Tuple{AbstractArray,Integer,Union{Real, Color{T,1} where T},Union{Real, Color{T,1} where T}}"><code>Images.histeq</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">hist_equalised_img = histeq(img, nbins)
hist_equalised_img = histeq(img, nbins, minval, maxval)</code></pre><p>Returns a histogram equalised image with a granularity of approximately <code>nbins</code> number of bins.</p><p><strong>Details</strong></p><p>Histogram equalisation was initially conceived to  improve the contrast in a single-channel grayscale image. The method transforms the distribution of the intensities in an image so that they are as uniform as possible [1]. The natural justification for uniformity is that the image has better contrast  if the intensity levels of an image span a wide range on the intensity scale. As it turns out, the necessary transformation is a mapping based on the cumulative histogram.</p><p>One can consider an <span>$L$</span>-bit single-channel <span>$I \times J$</span> image with gray values in the set <span>$\{0,1,\ldots,L-1 \}$</span>, as a collection of independent and identically distributed random variables. Specifically, let the sample space <span>$\Omega$</span> be the set of all <span>$IJ$</span>-tuples <span>$\omega =(\omega_{11},\omega_{12},\ldots,\omega_{1J},\omega_{21},\omega_{22},\ldots,\omega_{2J},\omega_{I1},\omega_{I2},\ldots,\omega_{IJ})$</span>, where each <span>$\omega_{ij} \in \{0,1,\ldots, L-1 \}$</span>. Furthermore, impose a probability measure on <span>$\Omega$</span> such that the functions <span>$\Omega \ni \omega \to \omega_{ij} \in \{0,1,\ldots,L-1\}$</span> are independent and identically distributed.</p><p>One can then regard an image as a matrix of random variables <span>$\mathbf{G} = [G_{i,j}(\omega)]$</span>, where each function <span>$G_{i,j}: \Omega \to \mathbb{R}$</span> is defined by</p><div>\[G_{i,j}(\omega) = \frac{\omega_{ij}}{L-1},\]</div><p>and each <span>$G_{i,j}$</span> is distributed according to some unknown density <span>$f_{G}$</span>. While <span>$f_{G}$</span> is unknown, one can approximate it with a normalised histogram of gray levels,</p><div>\[\hat{f}_{G}(v)= \frac{n_v}{IJ},\]</div><p>where</p><div>\[n_v = \left | \left\{(i,j)\, |\,  G_{i,j}(\omega)  = v \right \} \right |\]</div><p>represents the number of times a gray level with intensity <span>$v$</span> occurs in <span>$\mathbf{G}$</span>. To transforming the distribution of the intensities so that they are as uniform as possible one needs to find a mapping <span>$T(\cdot)$</span> such that <span>$T(G_{i,j}) \thicksim U$</span>. The required mapping turns out to be the cumulative distribution function (CDF) of the empirical density <span>$\hat{f}_{G}$</span>,</p><div>\[ T(G_{i,j}) = \int_0^{G_{i,j}}\hat{f}_{G}(w)\mathrm{d} w.\]</div><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The <code>histeq</code> function can handle a variety of input types. The returned image depends on the input type. If the input is an <code>Image</code> then the resulting image is of the same type and has the same properties.</p><p>For coloured images, the input is converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a> type and the Y channel is equalised. This is the combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram.</p><p><strong>Choices for <code>minval</code> and <code>maxval</code></strong></p><p>If minval and maxval are specified then intensities are equalized to the range (minval, maxval). The default values are 0 and 1.</p><p><strong>Example</strong></p><pre><code class="language-julia">
using TestImages, FileIO, ImageView

img =  testimage(&quot;mandril_gray&quot;);
imgeq = histeq(img,256);

imshow(img)
imshow(imgeq)</code></pre><p><strong>References</strong></p><ol><li>R. C. Gonzalez and R. E. Woods. <em>Digital Image Processing (3rd Edition)</em>.  Upper Saddle River, NJ, USA: Prentice-Hall,  2006.</li></ol><p>See also: <a href="@ref">histmatch</a>,<a href="@ref">clahe</a>, <a href="@ref">imhist</a> and  <a href="@ref">adjust_gamma</a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.histmatch" href="#Images.histmatch"><code>Images.histmatch</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">hist_matched_img = histmatch(img, oimg, nbins)</code></pre><p>Returns a histogram matched image with a granularity of <code>nbins</code> number of bins. The first argument <code>img</code> is the image to be matched, and the second argument <code>oimg</code> is the image having the desired histogram to be matched to.</p><p><strong>Details</strong></p><p>The purpose of histogram matching is to transform the intensities in a source image so that the intensities distribute according to the histogram of a specified target image. If one interprets histograms as piecewise-constant models of probability density functions (see <a href="@ref">imhist</a>), then the histogram matching task can be modelled as the problem of transforming one probability distribution into another [1].  It turns out that the solution to this transformation problem involves the cumulative and inverse cumulative distribution functions of the source and target probability density functions.</p><p>In particular, let the random variables <span>$x \thicksim p_{x}$</span> and <span>$z \thicksim p_{z}$</span>  represent an intensity in the source and target image respectively, and let</p><div>\[ S(x) = \int_0^{x}p_{x}(w)\mathrm{d} w \quad \text{and} \quad
 T(z) = \int_0^{z}p_{z}(w)\mathrm{d} w\]</div><p>represent their concomitant cumulative disitribution functions. Then the sought-after mapping <span>$Q(\cdot)$</span> such that <span>$Q(x) \thicksim p_{z}$</span> is given by</p><div>\[Q(x) =  T^{-1}\left( S(x) \right),\]</div><p>where <span>$T^{-1}(y) = \operatorname{min} \{ x \in \mathbb{R} : y \leq T(x) \}$</span> is the inverse cumulative distribution function of <span>$T(x)$</span>.</p><p>The mapping suggests that one can conceptualise histogram matching as performing histogram equalisation on the source and target image and relating the two equalised histograms. Refer to <a href="@ref">histeq</a> for more details on histogram equalisation.</p><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code> and <code>oimg</code></strong></p><p>The <code>histmatch</code> function can handle a variety of input types. The returned image depends on the input type. If the input is an <code>Image</code> then the resulting image is of the same type and has the same properties.</p><p>For coloured images, the input is converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a>  type and the Y channel is gamma corrected. This is then combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram.</p><p><strong>Example</strong></p><pre><code class="language-julia">using Images, TestImages, ImageView

img_source = testimage(&quot;mandril_gray&quot;)
img_target = adjust_gamma(img_source,1/2)
img_transformed = histmatch(img_source, img_target)
#=
    A visual inspection confirms that img_transformed resembles img_target
    much more closely than img_source.
=#
imshow(img_source)
imshow(img_target)
imshow(img_transformed)</code></pre><p><strong>References</strong></p><ol><li>W. Burger and M. J. Burge. <em>Digital Image Processing</em>. Texts in Computer Science, 2016. <a href="https://doi.org/10.1007/978-1-4471-6684-9">doi:10.1007/978-1-4471-6684-9</a></li></ol><p>See also: <a href="@ref">histeq</a>,<a href="@ref">clahe</a>, and <a href="@ref">imhist</a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.imROF-Union{Tuple{T}, Tuple{AbstractArray{T,2},Number,Integer}} where T&lt;:Union{Number, Color{T,1} where T}" href="#Images.imROF-Union{Tuple{T}, Tuple{AbstractArray{T,2},Number,Integer}} where T&lt;:Union{Number, Color{T,1} where T}"><code>Images.imROF</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">imgr = imROF(img, λ, iterations)</code></pre><p>Perform Rudin-Osher-Fatemi (ROF) filtering, more commonly known as Total Variation (TV) denoising or TV regularization. <code>λ</code> is the regularization coefficient for the derivative, and <code>iterations</code> is the number of relaxation iterations taken. 2d only.</p><p>See https://en.wikipedia.org/wiki/Total<em>variation</em>denoising and Chambolle, A. (2004). &quot;An algorithm for total variation minimization and applications&quot;.     Journal of Mathematical Imaging and Vision. 20: 89–97</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.imadjustintensity-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,Tuple{Any,Any}}} where T" href="#Images.imadjustintensity-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,Tuple{Any,Any}}} where T"><code>Images.imadjustintensity</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>imadjustintensity(img [, (minval,maxval)]) -&gt; Image</code></p><p>Map intensities over the interval <code>(minval,maxval)</code> to the interval    <code>[0,1]</code>. This is equivalent to <code>map(ScaleMinMax(eltype(img), minval,    maxval), img)</code>.  (minval,maxval) defaults to <code>extrema(img)</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.imcorner-Tuple{AbstractArray}" href="#Images.imcorner-Tuple{AbstractArray}"><code>Images.imcorner</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">corners = imcorner(img; [method])
corners = imcorner(img, threshold, percentile; [method])</code></pre><p>Performs corner detection using one of the following methods -</p><pre><code class="language-none">1. harris
2. shi_tomasi
3. kitchen_rosenfeld</code></pre><p>The parameters of the individual methods are described in their documentation. The maxima values of the resultant responses are taken as corners. If a threshold is specified, the values of the responses are thresholded to give the corner pixels. The threshold is assumed to be a percentile value unless <code>percentile</code> is set to false.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.imcorner_subpixel-Tuple{AbstractArray}" href="#Images.imcorner_subpixel-Tuple{AbstractArray}"><code>Images.imcorner_subpixel</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">corners = imcorner_subpixel(img; [method])
         -&gt; Vector{HomogeneousPoint{Float64,3}}
corners = imcorner_subpixel(img, threshold, percentile; [method])
         -&gt; Vector{HomogeneousPoint{Float64,3}}</code></pre><p>Same as <a href="#Images.imcorner-Tuple{AbstractArray}"><code>imcorner</code></a>, but estimates corners to sub-pixel precision.</p><p>Sub-pixel precision is achieved by interpolating the corner response values using the 4-connected neighbourhood of a maximum response value. See <a href="#Images.corner2subpixel-Tuple{AbstractArray{T,2} where T,AbstractArray{Bool,2}}"><code>corner2subpixel</code></a> for more details of the interpolation scheme.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.imedge" href="#Images.imedge"><code>Images.imedge</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">grad_y, grad_x, mag, orient = imedge(img, kernelfun=KernelFactors.ando3, border=&quot;replicate&quot;)</code></pre><p>Edge-detection filtering. <code>kernelfun</code> is a valid kernel function for <a href="@ref"><code>imgradients</code></a>, defaulting to <a href="@ref"><code>KernelFactors.ando3</code></a>. <code>border</code> is any of the boundary conditions specified in <code>padarray</code>.</p><p>Returns a tuple <code>(grad_y, grad_x, mag, orient)</code>, which are the horizontal gradient, vertical gradient, and the magnitude and orientation of the strongest edge, respectively.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.imhist-Tuple{AbstractArray,Integer,Union{Real, Color{T,1} where T},Union{Real, Color{T,1} where T}}" href="#Images.imhist-Tuple{AbstractArray,Integer,Union{Real, Color{T,1} where T},Union{Real, Color{T,1} where T}}"><code>Images.imhist</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">edges, count = imhist(img, nbins)
edges, count = imhist(img, nbins, minval, maxval)
edges, count = imhist(img, edges)</code></pre><p>Generates a histogram for the image over nbins spread between <code>(minval, maxval]</code>. Color images are automatically converted to grayscale.</p><p><strong>Output</strong></p><p>Returns <code>edges</code> which is a <a href="@ref"><code>range</code></a> type that specifies how the  interval <code>(minval, maxval]</code> is divided into bins, and an array <code>count</code> which records the concomitant bin frequencies. In particular, <code>count</code> has the following properties:</p><ul><li><code>count[i+1]</code> is the number of values <code>x</code> that satisfy <code>edges[i] &lt;= x &lt; edges[i+1]</code>.</li><li><code>count[1]</code> is the number satisfying <code>x &lt; edges[1]</code>, and</li><li><code>count[end]</code> is the number satisfying <code>x &gt;= edges[end]</code>.</li><li><code>length(count) == length(edges)+1</code>.</li></ul><p><strong>Details</strong></p><p>One can consider a histogram as a piecewise-constant model of a probability density function <span>$f$</span> [1]. Suppose that <span>$f$</span> has support on some interval <span>$I = [a,b]$</span>.  Let <span>$m$</span> be an integer and <span>$a = a_1 &lt; a_2 &lt; \ldots &lt; a_m &lt; a_{m+1} = b$</span> a sequence of real numbers. Construct a sequence of intervals</p><div>\[I_1 = [a_1,a_2], I_2 = (a_2, a_3], \ldots, I_{m} = (a_m,a_{m+1}]\]</div><p>which partition <span>$I$</span> into subsets <span>$I_j$</span> <span>$(j = 1, \ldots, m)$</span> on which <span>$f$</span> is constant. These subsets satisfy <span>$I_i \cap I_j = \emptyset, \forall i \neq j$</span>, and are commonly referred to as <em>bins</em>. Together they encompass the entire range of data values such that <span>$\sum_j |I_j | = | I |$</span>. Each bin has width <span>$w_j = |I_j| = a_{j+1} - a_j$</span> and height <span>$h_j$</span> which is the constant probability density over the region of the bin. Integrating the constant probability density over the width of the bin <span>$w_j$</span> yields a probability mass of <span>$\pi_j = h_j w_j$</span> for the bin.</p><p>For a sample <span>$x_1, x_2, \ldots, x_N$</span>, let</p><div>\[n_j = \sum_{n = 1}^{N}\mathbf{1}_{(I_j)}(x_n),
\quad \text{where} \quad
\mathbf{1}_{(I_j)}(x) =
\begin{cases}
 1 &amp; \text{if} x \in I_j,\\
 0 &amp; \text{otherwise},
\end{cases},\]</div><p>represents the number of samples falling into the interval <span>$I_j$</span>. An estimate for the probability mass of the <span>$j$</span>th bin is given by the relative frequency <span>$\hat{\pi} = \frac{n_j}{N}$</span>, and the histogram estimator of the probability density function is defined as</p><div>\[\begin{aligned}
\hat{f}_n(x)  &amp; = \sum_{j = 1}^{m}\frac{n_j}{Nw_j} \mathbf{1}_{(I_j)}(x) \\
&amp; = \sum_{j = 1}^{m}\frac{\hat{\pi}_j}{w_j} \mathbf{1}_{(I_j)}(x) \\
&amp; = \sum_{j = 1}^{m}\hat{h}_j \mathbf{1}_{(I_j)}(x).
\end{aligned}\]</div><p>The function <span>$\hat{f}_n(x)$</span> is a genuine density estimator because <span>$\hat{f}_n(x)  \ge 0$</span> and</p><div>\[\begin{aligned}
\int_{-\infty}^{\infty}\hat{f}_n(x) \operatorname{d}x &amp; = \sum_{j=1}^{m} \frac{n_j}{Nw_j} w_j \\
&amp; = 1.
\end{aligned}\]</div><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the number of discrete bins for the histogram.</p><p><strong>Choices for <code>minval</code></strong></p><p>You have the option to specify the lower bound of the interval over which the histogram will be computed.  If <code>minval</code> is not specified then the minimum value present in the image is taken as the lower bound.</p><p><strong>Choices for <code>maxval</code></strong></p><p>You have the option to specify the upper bound of the interval over which the histogram will be computed.  If <code>maxval</code> is not specified then the maximum value present in the image is taken as the upper bound.</p><p><strong>Choices for <code>edges</code></strong></p><p>If you do not designate the number of bins, nor the lower or upper bound of the interval, then you have the option to directly stipulate how the intervals will be divided by specifying a <a href="@ref"><code>range</code></a> type.</p><p><strong>Example</strong></p><p>Compute the histogram of a grayscale image.</p><pre><code class="language-julia">
using TestImages, FileIO, ImageView

img =  testimage(&quot;mandril_gray&quot;);
edges, counts  = imhist(img,256);</code></pre><p>Given a color image, compute the hisogram of the red channel.</p><pre><code class="language-julia">img = testimage(&quot;mandrill&quot;)
r = red(img)
edges, counts  = imhist(r,256);</code></pre><p><strong>References</strong></p><p>[1] E. Herrholz, &quot;Parsimonious Histograms,&quot; Ph.D. dissertation, Inst. of Math. and Comp. Sci., University of Greifswald, Greifswald, Germany, 2011.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.imstretch-Tuple{AbstractArray,Number,Number}" href="#Images.imstretch-Tuple{AbstractArray,Number,Number}"><code>Images.imstretch</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>imgs = imstretch(img, m, slope)</code> enhances or reduces (for slope &gt; 1 or &lt; 1, respectively) the contrast near saturation (0 and 1). This is essentially a symmetric gamma-correction. For a pixel of brightness <code>p</code>, the new intensity is <code>1/(1+(m/(p+eps))^slope)</code>.</p><p>This assumes the input <code>img</code> has intensities between 0 and 1.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.integral_image-Tuple{AbstractArray}" href="#Images.integral_image-Tuple{AbstractArray}"><code>Images.integral_image</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">integral_img = integral_image(img)</code></pre><p>Returns the integral image of an image. The integral image is calculated by assigning to each pixel the sum of all pixels above it and to its left, i.e. the rectangle from (1, 1) to the pixel. An integral image is a data structure which helps in efficient calculation of sum of pixels in a rectangular subset of an image. See <code>boxdiff</code> for more information.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.kitchen_rosenfeld-Tuple{AbstractArray}" href="#Images.kitchen_rosenfeld-Tuple{AbstractArray}"><code>Images.kitchen_rosenfeld</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">kitchen_rosenfeld_response = kitchen_rosenfeld(img; [border])</code></pre><p>Performs Kitchen Rosenfeld corner detection. The covariances can be taken using either a mean weighted filter or a gamma kernel.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.label_components" href="#Images.label_components"><code>Images.label_components</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">label = label_components(tf, [connectivity])
label = label_components(tf, [region])</code></pre><p>Find the connected components in a binary array <code>tf</code>. There are two forms that <code>connectivity</code> can take:</p><ul><li>It can be a boolean array of the same dimensionality as <code>tf</code>, of size 1 or 3</li></ul><p>along each dimension. Each entry in the array determines whether a given neighbor is used for connectivity analyses. For example, <code>connectivity = trues(3,3)</code> would use 8-connectivity and test all pixels that touch the current one, even the corners.</p><ul><li>You can provide a list indicating which dimensions are used to</li></ul><p>determine connectivity. For example, <code>region = [1,3]</code> would not test neighbors along dimension 2 for connectivity. This corresponds to just the nearest neighbors, i.e., 4-connectivity in 2d and 6-connectivity in 3d.</p><p>The default is <code>region = 1:ndims(A)</code>.</p><p>The output <code>label</code> is an integer array, where 0 is used for background pixels, and each connected region gets a different integer index.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.magnitude-Tuple{AbstractArray,AbstractArray}" href="#Images.magnitude-Tuple{AbstractArray,AbstractArray}"><code>Images.magnitude</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">m = magnitude(grad_x, grad_y)</code></pre><p>Calculates the magnitude of the gradient images given by <code>grad_x</code> and <code>grad_y</code>. Equivalent to <code>sqrt(grad_x.^2 + grad_y.^2)</code>.</p><p>Returns a magnitude image the same size as <code>grad_x</code> and <code>grad_y</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.magnitude_phase-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}} where T" href="#Images.magnitude_phase-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}} where T"><code>Images.magnitude_phase</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">magnitude_phase(grad_x, grad_y) -&gt; m, p</code></pre><p>Convenience function for calculating the magnitude and phase of the gradient images given in <code>grad_x</code> and <code>grad_y</code>.  Returns a tuple containing the magnitude and phase images.  See <code>magnitude</code> and <code>phase</code> for details.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.maxabsfinite-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}} where T" href="#Images.maxabsfinite-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}} where T"><code>Images.maxabsfinite</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>m = maxabsfinite(A)</code> calculates the maximum absolute value in <code>A</code>, ignoring any values that are not finite (Inf or NaN).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.maxfinite-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}} where T" href="#Images.maxfinite-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}} where T"><code>Images.maxfinite</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>m = maxfinite(A)</code> calculates the maximum value in <code>A</code>, ignoring any values that are not finite (Inf or NaN).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.meanfinite-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,Any}} where T&lt;:Real" href="#Images.meanfinite-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,Any}} where T&lt;:Real"><code>Images.meanfinite</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>M = meanfinite(img, region)</code> calculates the mean value along the dimensions listed in <code>region</code>, ignoring any non-finite values.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.minfinite-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}} where T" href="#Images.minfinite-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}} where T"><code>Images.minfinite</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>m = minfinite(A)</code> calculates the minimum value in <code>A</code>, ignoring any values that are not finite (Inf or NaN).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.ncc-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}} where T" href="#Images.ncc-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}} where T"><code>Images.ncc</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>C = ncc(A, B)</code> computes the normalized cross-correlation of <code>A</code> and <code>B</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.orientation-Union{Tuple{T}, Tuple{T,T}, Tuple{T,T,Any}} where T&lt;:Number" href="#Images.orientation-Union{Tuple{T}, Tuple{T,T}, Tuple{T,T,Any}} where T&lt;:Number"><code>Images.orientation</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">orientation(grad_x, grad_y) -&gt; orient</code></pre><p>Calculate the orientation angle of the strongest edge from gradient images given by <code>grad_x</code> and <code>grad_y</code>.  Equivalent to <code>atan(grad_x, grad_y)</code>.  When both <code>grad_x</code> and <code>grad_y</code> are effectively zero, the corresponding angle is set to zero.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.otsu_threshold-Union{Tuple{AbstractArray{T,N}}, Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,N},Int64}} where N where T&lt;:Union{Real, Gray}" href="#Images.otsu_threshold-Union{Tuple{AbstractArray{T,N}}, Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,N},Int64}} where N where T&lt;:Union{Real, Gray}"><code>Images.otsu_threshold</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">thres = otsu_threshold(img)
thres = otsu_threshold(img, bins)</code></pre><p>Computes threshold for grayscale image using Otsu&#39;s method.</p><p>Parameters:</p><ul><li>img         = Grayscale input image</li><li>bins        = Number of bins used to compute the histogram. Needed for floating-point images.</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.phase-Union{Tuple{T}, Tuple{T,T}, Tuple{T,T,Any}} where T&lt;:Number" href="#Images.phase-Union{Tuple{T}, Tuple{T,T}, Tuple{T,T,Any}} where T&lt;:Number"><code>Images.phase</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">phase(grad_x, grad_y) -&gt; p</code></pre><p>Calculate the rotation angle of the gradient given by <code>grad_x</code> and <code>grad_y</code>. Equivalent to <code>atan(-grad_y, grad_x)</code>, except that when both <code>grad_x</code> and <code>grad_y</code> are effectively zero, the corresponding angle is set to zero.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.sad-Tuple{AbstractArray,AbstractArray}" href="#Images.sad-Tuple{AbstractArray,AbstractArray}"><code>Images.sad</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>s = sad(A, B)</code> computes the sum-of-absolute differences over arrays/images A and B</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.sadn-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}} where T" href="#Images.sadn-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}} where T"><code>Images.sadn</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>s = sadn(A, B)</code> computes the sum-of-absolute differences over arrays/images A and B, normalized by array size</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.shepp_logan-Tuple{Any,Any}" href="#Images.shepp_logan-Tuple{Any,Any}"><code>Images.shepp_logan</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">phantom = shepp_logan(N,[M]; highContrast=true)</code></pre><p>output the NxM Shepp-Logan phantom, which is a standard test image usually used for comparing image reconstruction algorithms in the field of computed tomography (CT) and magnetic resonance imaging (MRI). If the argument M is omitted, the phantom is of size NxN. When setting the keyword argument <code>highConstrast</code> to false, the CT version of the phantom is created. Otherwise, the high contrast MRI version is calculated.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.shi_tomasi-Tuple{AbstractArray}" href="#Images.shi_tomasi-Tuple{AbstractArray}"><code>Images.shi_tomasi</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">shi_tomasi_response = shi_tomasi(img; [border], [weights])</code></pre><p>Performs Shi Tomasi corner detection. The covariances can be taken using either a mean weighted filter or a gamma kernel.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.ssd-Tuple{AbstractArray,AbstractArray}" href="#Images.ssd-Tuple{AbstractArray,AbstractArray}"><code>Images.ssd</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>s = ssd(A, B)</code> computes the sum-of-squared differences over arrays/images A and B</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.ssdn-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}} where T" href="#Images.ssdn-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}} where T"><code>Images.ssdn</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><code>s = ssdn(A, B)</code> computes the sum-of-squared differences over arrays/images A and B, normalized by array size</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.thin_edges-Union{Tuple{T}, Tuple{AbstractArray{T,2},AbstractArray}, Tuple{AbstractArray{T,2},AbstractArray,AbstractString}} where T" href="#Images.thin_edges-Union{Tuple{T}, Tuple{AbstractArray{T,2},AbstractArray}, Tuple{AbstractArray{T,2},AbstractArray,AbstractString}} where T"><code>Images.thin_edges</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">thinned = thin_edges(img, gradientangle, [border])
thinned, subpix = thin_edges_subpix(img, gradientangle, [border])
thinned, subpix = thin_edges_nonmaxsup(img, gradientangle, [border]; [radius::Float64=1.35], [theta=pi/180])
thinned, subpix = thin_edges_nonmaxsup_subpix(img, gradientangle, [border]; [radius::Float64=1.35], [theta=pi/180])</code></pre><p>Edge thinning for 2D edge images.  Currently the only algorithm available is non-maximal suppression, which takes an edge image and its gradient angle, and checks each edge point for local maximality in the direction of the gradient. The returned image is non-zero only at maximal edge locations.</p><p><code>border</code> is any of the boundary conditions specified in <code>padarray</code>.</p><p>In addition to the maximal edge image, the <code>_subpix</code> versions of these functions also return an estimate of the subpixel location of each local maxima, as a 2D array or image of <code>Graphics.Point</code> objects.  Additionally, each local maxima is adjusted to the estimated value at the subpixel location.</p><p>Currently, the <code>_nonmaxsup</code> functions are identical to the first two function calls, except that they also accept additional keyword arguments.  <code>radius</code> indicates the step size to use when searching in the direction of the gradient; values between 1.2 and 1.5 are suggested (default 1.35).  <code>theta</code> indicates the step size to use when discretizing angles in the <code>gradientangle</code> image, in radians (default: 1 degree in radians = pi/180).</p><p>Example:</p><pre><code class="language-none">g = rgb2gray(rgb_image)
gx, gy = imgradients(g)
mag, grad_angle = magnitude_phase(gx,gy)
mag[mag .&lt; 0.5] = 0.0  # Threshold magnitude image
thinned, subpix =  thin_edges_subpix(mag, grad_angle)</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.yen_threshold-Union{Tuple{AbstractArray{T,N}}, Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,N},Int64}} where N where T&lt;:Union{Real, Gray}" href="#Images.yen_threshold-Union{Tuple{AbstractArray{T,N}}, Tuple{N}, Tuple{T}, Tuple{AbstractArray{T,N},Int64}} where N where T&lt;:Union{Real, Gray}"><code>Images.yen_threshold</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">thres = yen_threshold(img)
thres = yen_threshold(img, bins)</code></pre><p>Computes threshold for grayscale image using Yen&#39;s maximum correlation criterion for bilevel thresholding</p><p>Parameters:</p><ul><li>img         = Grayscale input image</li><li>bins        = Number of bins used to compute the histogram. Needed for floating-point images.</li></ul><p>#Citation Yen J.C., Chang F.J., and Chang S. (1995) “A New Criterion for Automatic Multilevel Thresholding” IEEE Trans. on Image Processing, 4(3): 370-378. DOI:10.1109/83.366472</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.imaverage" href="#Images.imaverage"><code>Images.imaverage</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>kern = imaverage(filtersize)</code> constructs a boxcar-filter of the specified size.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.sumfinite!-Union{Tuple{N}, Tuple{T}, Tuple{Any,Any,AbstractArray{T,N}}} where N where T" href="#Images.sumfinite!-Union{Tuple{N}, Tuple{T}, Tuple{Any,Any,AbstractArray{T,N}}} where N where T"><code>Images.sumfinite!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">sumfinite!(S, K, A)</code></pre><p>Compute the sum <code>S</code> and number of contributing pixels <code>K</code> for reductions of the array <code>A</code> over dimensions. <code>S</code> and <code>K</code> must have identical indices, and either match <code>A</code> or have singleton-dimensions for the dimensions that are being summed over. Only pixels with finite value are included in the tallies of <code>S</code> and <code>K</code>.</p><p>Note that the pixel mean is just S./K.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Images.unsafe_neighbourhood_4-Tuple{AbstractArray{T,2} where T,Int64,Int64}" href="#Images.unsafe_neighbourhood_4-Tuple{AbstractArray{T,2} where T,Int64,Int64}"><code>Images.unsafe_neighbourhood_4</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">unsafe_neighbourhood_4(matrix::AbstractMatrix,r::Int,c::Int)</code></pre><p>Returns the value of a matrix at given coordinates together with the values of the north, south, east and west neighbours.</p><p>This function does not perform bounds checking. It is up to the user to ensure that the function is not called with indices that are on the boundary of the matrix.</p></div></div></section><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Readme</span></a></footer></article></body></html>

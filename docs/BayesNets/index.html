<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · BayesNets.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>BayesNets.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Home</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Home</a></li></ul></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><p>Package doesn&#39;t contain Documenter docs.</p><p>Docs automatically generated by juliadocs.org</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.BDeuPrior" href="#BayesNets.BDeuPrior"><code>BayesNets.BDeuPrior</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Assigns equal scores to Markov equivalent structures</p><pre><code class="language-none">α_ijk = x/{q_i * r_i} for each j, k and some given x</code></pre><p>see DMU section 2.4.3</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.BayesNetSampler" href="#BayesNets.BayesNetSampler"><code>BayesNets.BayesNetSampler</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Abstract type for sampling with:</p><ul><li><code>Random.rand(BayesNet, BayesNetSampler)</code></li><li><code>Random.rand(BayesNet, BayesNetSampler, nsamples)</code></li><li><code>Random.rand!(Assignment, BayesNet, BayesNetSampler)</code></li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.DirectSampler" href="#BayesNets.DirectSampler"><code>BayesNets.DirectSampler</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Straightforward sampling from a BayesNet. The default sampler.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.DirichletPrior" href="#BayesNets.DirichletPrior"><code>BayesNets.DirichletPrior</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Baysian Structure learning seeks to maximize P(G|D) In the Bayesian fashion, we can provide a prior over the parameters in our learning network. This is described using a Dirichlet Prior.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.DiscreteBayesNet" href="#BayesNets.DiscreteBayesNet"><code>BayesNets.DiscreteBayesNet</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p><code>DiscreteBayesNet</code>s are Bayesian Networks where every variable is an integer within 1:Nᵢ and every distribution is Categorical.</p><p>This representation is very common, and allows for the use of factors, for example in <em>Probabilistic Graphical Models</em> by Koller and Friedman</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.ExactInference" href="#BayesNets.ExactInference"><code>BayesNets.ExactInference</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Exact inference using factors and variable eliminations</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.Factor" href="#BayesNets.Factor"><code>BayesNets.Factor</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Factor(bn, name, evidence=Assignment())</code></pre><p>Create a factor for a node, given some evidence.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.Factor" href="#BayesNets.Factor"><code>BayesNets.Factor</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Factor(dims, potential)</code></pre><p>Create a Factor corresponding to the potential.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.Factor-Tuple{AbstractArray{Symbol,1},Array{Int64,1},Nothing}" href="#BayesNets.Factor-Tuple{AbstractArray{Symbol,1},Array{Int64,1},Nothing}"><code>BayesNets.Factor</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">Factor(dims, lengths, fill_value=0)</code></pre><p>Create a factor with dimensions <code>dims</code>, each with lengths corresponding to <code>lengths</code>. <code>fill_value</code> will fill the potential array with that value. To keep uninitialized, use <code>fill_value=nothing</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.GibbsSampler" href="#BayesNets.GibbsSampler"><code>BayesNets.GibbsSampler</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>The GibbsSampler type houses the parameters of the Gibbs sampling algorithm.  The parameters are defined below:</p><p>burn<em>in:  The first burn</em>in samples will be discarded.  They will not be returned. The thinning parameter does not affect the burn in period. This is used to ensure that the Gibbs sampler converges to the target stationary distribution before actual samples are drawn.</p><p>thinning: For every thinning + 1 number of samples drawn, only the last is kept. Thinning is used to reduce autocorrelation between samples. Thinning is not used during the burn in period. e.g. If thinning is 1, samples will be drawn in groups of two and only the second sample will be in the output.</p><p>time<em>limit: The number of milliseconds to run the algorithm. The algorithm will return the samples it has collected when either nsamples samples have been collected or time</em>limit milliseconds have passed.  If time_limit is null then the algorithm will run until nsamples have been collected. This means it is possible that zero samples are returned.</p><p>error<em>if</em>time<em>out: If error</em>if<em>time</em>out is true and the time<em>limit expires, an error will be raised. If error</em>if<em>time</em>out is false and the time limit expires, the samples that have been collected so far will be returned.         This means it is possible that zero samples are returned.  Burn in samples will not be returned. If time_limit is null, this parameter does nothing.</p><p>consistent_with: the assignment that all samples must be consistent with (ie, Assignment(:A=&gt;1) means all samples must have :A=1). Use to sample conditional distributions.</p><p>max<em>cache</em>size:  If null, cache as much as possible, otherwise cache at most &quot;max<em>cache</em>size&quot;  distributions</p><p>variable<em>order: variable</em>order determines the order of variables changed when generating a new sample. If null use a random order for every sample (this is different from updating the variables at random). Otherwise should be a list containing all the variables in the order they should be updated.</p><p>initial_sample:  The inital assignment to variables to use.  If null, the initial sample is chosen by briefly using a LikelihoodWeightedSampler.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.GibbsSamplingFull" href="#BayesNets.GibbsSamplingFull"><code>BayesNets.GibbsSamplingFull</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">infer(im, inf)</code></pre><p>Run Gibbs sampling for <code>N</code> iterations. Each iteration changes all nodes. Discareds first <code>burn_in</code> samples and keeps only the <code>thin</code>-th sample. Ex, if <code>thin=3</code>, will discard the first two samples and keep the third.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaLang/julia/blob/099e826241fca365a120df9bac9a9fede6e7bae4/base/#L0-L7">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.GibbsSamplingNodewise" href="#BayesNets.GibbsSamplingNodewise"><code>BayesNets.GibbsSamplingNodewise</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">infer(GibbsSampling, state::Assignment, InferenceState)</code></pre><p>Run Gibbs sampling for <code>N</code> iterations. Each iteration changes one node.</p><p>Discareds first <code>burn_in</code> samples and keeps only the <code>thin</code>-th sample. Ex, if <code>thin=3</code>, will discard the first two samples and keep the third.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaLang/julia/blob/099e826241fca365a120df9bac9a9fede6e7bae4/base/#L0-L7">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.K2GraphSearch" href="#BayesNets.K2GraphSearch"><code>BayesNets.K2GraphSearch</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">K2GraphSearch</code></pre><p>A GraphSearchStrategy following the K2 algorithm. Takes polynomial time to find the optimal structure assuming a topological variable ordering.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.LikelihoodWeightedSampler" href="#BayesNets.LikelihoodWeightedSampler"><code>BayesNets.LikelihoodWeightedSampler</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Likelihood Weighted Sampling</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.LikelihoodWeightingInference" href="#BayesNets.LikelihoodWeightingInference"><code>BayesNets.LikelihoodWeightingInference</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Approximates p(query|evidence) with N weighted samples using likelihood weighted sampling</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaLang/julia/blob/099e826241fca365a120df9bac9a9fede6e7bae4/base/#L0-L3">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.LoopyBelief" href="#BayesNets.LoopyBelief"><code>BayesNets.LoopyBelief</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Loopy belief propogation for a network.</p><p>Early stopping if change is messages &lt; <code>tol</code> for `iters<em>for</em>convergence&#39; iterations. For no stopping, use tol &lt; 0.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaLang/julia/blob/099e826241fca365a120df9bac9a9fede6e7bae4/base/#L0-L5">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.NegativeBayesianInformationCriterion" href="#BayesNets.NegativeBayesianInformationCriterion"><code>BayesNets.NegativeBayesianInformationCriterion</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">NegativeBayesianInformationCriterion</code></pre><p>A ScoringFunction for the negative Bayesian information criterion.</p><pre><code class="language-none">BIC = -2⋅L + k⋅ln(n)

   L - the log likelihood of the data under the cpd
   k - the number of free parameters to be estimated
   n - the sample size</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.RejectionSampler" href="#BayesNets.RejectionSampler"><code>BayesNets.RejectionSampler</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Rejection Sampling in which the assignments are forced to be consistent with the provided values. Each sampler is attempted at most <code>max_nsamples</code> times before returning an empty assignment.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.ScoreComponentCache" href="#BayesNets.ScoreComponentCache"><code>BayesNets.ScoreComponentCache</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">ScoreComponentCache</code></pre><p>Used to store scores in a priority queue such that graph search algorithms know when a particular construction has already been made.     cache<a href="parentsⱼ, score">ⱼ</a> for the ith variable with parents parents</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.ScoreComponentCache-Tuple{DataFrame}" href="#BayesNets.ScoreComponentCache-Tuple{DataFrame}"><code>BayesNets.ScoreComponentCache</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">ScoreComponentCache(data::DataFrame)</code></pre><p>Construct an empty ScoreComponentCache the size of ncol(data)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.ScoringFunction" href="#BayesNets.ScoringFunction"><code>BayesNets.ScoringFunction</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">ScoringFunction</code></pre><p>An abstract type for which subtypes allow extracting CPD score components, which are to be maximized: score_component(::ScoringFunction, cpd::CPD, data::DataFrame)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.UniformPrior" href="#BayesNets.UniformPrior"><code>BayesNets.UniformPrior</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A uniform Dirichlet prior such that all α are the same</p><p>Defaults to the popular K2 prior, α = 1, which is similar to Laplace Smoothing</p><pre><code class="language-none">https://en.wikipedia.org/wiki/Additive_smoothing</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.convert-Tuple{Type{DataFrame},Factor}" href="#Base.convert-Tuple{Type{DataFrame},Factor}"><code>Base.convert</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Convert a Factor to a DataFrame</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.convert-Tuple{Type{Factor},CategoricalCPD{Categorical{Float64}}}" href="#Base.convert-Tuple{Type{Factor},CategoricalCPD{Categorical{Float64}}}"><code>Base.convert</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">convert(DiscreteCPD, cpd)</code></pre><p>Construct a Factor from a DiscreteCPD.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.delete!-Tuple{BayesNet,Symbol}" href="#Base.delete!-Tuple{BayesNet,Symbol}"><code>Base.delete!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">delete!(bn::BayesNets, target::NodeName)</code></pre><p>Removing cpds will alter the vertex indeces. In particular, removing the ith cpd will swap i and n and then remove n.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.length-Tuple{Factor}" href="#Base.length-Tuple{Factor}"><code>Base.length</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Total number of elements in Factor (potential)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.CPDs.ProbabilisticGraphicalModels.infer-Union{Tuple{BN}, Tuple{LikelihoodWeightingInference,InferenceState{BN}}} where BN&lt;:BayesNet{CategoricalCPD{Categorical{Float64}}}" href="#BayesNets.CPDs.ProbabilisticGraphicalModels.infer-Union{Tuple{BN}, Tuple{LikelihoodWeightingInference,InferenceState{BN}}} where BN&lt;:BayesNet{CategoricalCPD{Categorical{Float64}}}"><code>BayesNets.CPDs.ProbabilisticGraphicalModels.infer</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Approximates p(query|evidence) with <code>nsamples</code> likelihood weighted samples.</p><p>Since this uses a Factor, it is only efficient if the number of samples is (signifcantly) greater than the number of possible instantiations for the query variables</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.CPDs.ProbabilisticGraphicalModels.is_independent-Tuple{BayesNet,AbstractArray{Symbol,1},AbstractArray{Symbol,1},AbstractArray{Symbol,1}}" href="#BayesNets.CPDs.ProbabilisticGraphicalModels.is_independent-Tuple{BayesNet,AbstractArray{Symbol,1},AbstractArray{Symbol,1},AbstractArray{Symbol,1}}"><code>BayesNets.CPDs.ProbabilisticGraphicalModels.is_independent</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns whether the set of node names <code>x</code> is d-separated from the set <code>y</code> given the set <code>given</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.CPDs.ProbabilisticGraphicalModels.markov_blanket-Tuple{BayesNet,Symbol}" href="#BayesNets.CPDs.ProbabilisticGraphicalModels.markov_blanket-Tuple{BayesNet,Symbol}"><code>BayesNets.CPDs.ProbabilisticGraphicalModels.markov_blanket</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Return the children, parents, and parents of children (excluding target) as a Set of NodeNames</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.CPDs.parents-Tuple{BayesNet,Symbol}" href="#BayesNets.CPDs.parents-Tuple{BayesNet,Symbol}"><code>BayesNets.CPDs.parents</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns the parents as a list of NodeNames</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.bayesian_score" href="#BayesNets.bayesian_score"><code>BayesNets.bayesian_score</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">bayesian_score(G::DAG, names::Vector{Symbol}, data::DataFrame[, ncategories::Vector{Int}[, prior::DirichletPrior]])</code></pre><p>Compute the bayesian score for graph structure <code>g</code>, with the data in <code>data</code>. <code>names</code> containes a symbol corresponding to each vertex in <code>g</code> that is the name of a column in <code>data</code>. <code>ncategories</code> is a vector of the number of values that each variable in the Bayesian network can take.</p><p>Note that every entry in data must be an integer greater than 0</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.bayesian_score_component-Union{Tuple{I}, Tuple{Int64,AbstractArray{I,1},AbstractArray{Int64,1},AbstractArray{Int64,2},AbstractArray{Float64,2}}} where I&lt;:Integer" href="#BayesNets.bayesian_score_component-Union{Tuple{I}, Tuple{Int64,AbstractArray{I,1},AbstractArray{Int64,1},AbstractArray{Int64,2},AbstractArray{Float64,2}}} where I&lt;:Integer"><code>BayesNets.bayesian_score_component</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Computes the Bayesian score component for the given target variable index and     Dirichlet prior counts given in alpha</p><p>INPUT:     i       - index of the target variable     parents - list of indeces of parent variables (should not contain self)     r       - list of instantiation counts accessed by variable index               r[1] gives number of discrete states variable 1 can take on     data - matrix of sufficient statistics / counts               d[j,k] gives the number of times the target variable took on its kth instantiation               given the jth parental instantiation</p><p>OUTPUT:     the Bayesian score, Float64</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.children-Tuple{BayesNet,Symbol}" href="#BayesNets.children-Tuple{BayesNet,Symbol}"><code>BayesNets.children</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns the children as a list of NodeNames</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.get_asia_bn-Tuple{}" href="#BayesNets.get_asia_bn-Tuple{}"><code>BayesNets.get_asia_bn</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>An ergodic version of the asia network, with the E variable removed</p><p>Orignal network: Lauritzen, Steffen L. and David J. Spiegelhalter, 1988</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.get_sat_fail_bn-Tuple{}" href="#BayesNets.get_sat_fail_bn-Tuple{}"><code>BayesNets.get_sat_fail_bn</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Satellite failure network from DMU, pg 17</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.get_sprinkler_bn-Tuple{}" href="#BayesNets.get_sprinkler_bn-Tuple{}"><code>BayesNets.get_sprinkler_bn</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>The usual sprinkler problem</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.get_weighted_sample!-Tuple{Dict{Symbol,Any},BayesNet,Dict{Symbol,Any}}" href="#BayesNets.get_weighted_sample!-Tuple{Dict{Symbol,Any},BayesNet,Dict{Symbol,Any}}"><code>BayesNets.get_weighted_sample!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Draw an assignment from the Bayesian network but set any variables in the evidence accordingly. Returns the assignment and the probability weighting associated with the evidence.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.gibbs_sample-Tuple{BayesNet,Integer,Integer}" href="#BayesNets.gibbs_sample-Tuple{BayesNet,Integer,Integer}"><code>BayesNets.gibbs_sample</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Implements Gibbs sampling. (https://en.wikipedia.org/wiki/Gibbs_sampling) For finite variables, the posterior distribution is sampled by building the exact distribution. For continuous variables, the posterior distribution is sampled using Metropolis Hastings MCMC. Discrete variables with infinite support are currently not supported. The Gibbs Sampler only supports CPDs that return Univariate Distributions. (CPD{D&lt;:UnivariateDistribution})</p><p>bn:: A Bayesian Network to sample from.  bn should only contain CPDs that return UnivariateDistributions.</p><p>nsamples: The number of samples to return.</p><p>burn<em>in:  The first burn</em>in samples will be discarded.  They will not be returned. The thinning parameter does not affect the burn in period. This is used to ensure that the Gibbs sampler converges to the target stationary distribution before actual samples are drawn.</p><p>thinning: For every thinning + 1 number of samples drawn, only the last is kept. Thinning is used to reduce autocorrelation between samples. Thinning is not used during the burn in period. e.g. If thinning is 1, samples will be drawn in groups of two and only the second sample will be in the output.</p><p>time<em>limit: The number of milliseconds to run the algorithm. The algorithm will return the samples it has collected when either nsamples samples have been collected or time</em>limit milliseconds have passed.  If time_limit is null then the algorithm will run until nsamples have been collected. This means it is possible that zero samples are returned.</p><p>error<em>if</em>time<em>out: If error</em>if<em>time</em>out is true and the time<em>limit expires, an error will be raised. If error</em>if<em>time</em>out is false and the time limit expires, the samples that have been collected so far will be returned. 	This means it is possible that zero samples are returned.  Burn in samples will not be returned. If time_limit is null, this parameter does nothing.</p><p>consistent_with: the assignment that all samples must be consistent with (ie, Assignment(:A=&gt;1) means all samples must have :A=1). Use to sample conditional distributions.</p><p>max<em>cache</em>size:  If null, cache as much as possible, otherwise cache at most &quot;max<em>cache</em>size&quot;  distributions</p><p>variable<em>order: variable</em>order determines the order of variables changed when generating a new sample. If null use a random order for every sample (this is different from updating the variables at random). Otherwise should be a list containing all the variables in the order they should be updated.</p><p>initial<em>sample:  The inital assignment to variables to use.  If null, the initial sample is chosen by briefly running rand(bn, get</em>weighted_dataframe).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.pattern-Tuple{Factor,Any}" href="#BayesNets.pattern-Tuple{Factor,Any}"><code>BayesNets.pattern</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">pattern(ϕ, [dims])</code></pre><p>Return an array with the pattern of each dimension&#39;s state for all possible instances</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.rand_bn_inference" href="#BayesNets.rand_bn_inference"><code>BayesNets.rand_bn_inference</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">rand_bn_inference(bn, num_query=2, num_evidence=3)</code></pre><p>Generate a random inference state for a Bayesian Network with an evidence assignment sample uniformly over the chosen nodes&#39; domain.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.rand_cpd" href="#BayesNets.rand_cpd"><code>BayesNets.rand_cpd</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">rand_cpd(bn::DiscreteBayesNet, ncategories::Int, target::NodeName, parents::NodeNames=NodeName[])</code></pre><p>Return a CategoricalCPD with the given number of categories with random categorical distributions</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.rand_discrete_bn" href="#BayesNets.rand_discrete_bn"><code>BayesNets.rand_discrete_bn</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">rand_discrete_bn(num_nodes16, max_num_parents=3,
        max_num_states=5, connected=true)</code></pre><p>Generate a random DiscreteBayesNet.</p><p>Creates DiscreteBayesNet with <code>num_nodes</code> nodes, with each node having a random number of states and parents, up to <code>max_num_parents</code> and <code>max_num_parents</code>, respectively. If <code>connected</code>, each node (except the first) will be guaranteed at least one parent, making the graph connected.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.readxdsl-Tuple{AbstractString}" href="#BayesNets.readxdsl-Tuple{AbstractString}"><code>BayesNets.readxdsl</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">readxdsl( filename::AbstractString )</code></pre><p>Return a DiscreteBayesNet read from the xdsl file</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.score_component-Tuple{ScoringFunction,CPD,DataFrame}" href="#BayesNets.score_component-Tuple{ScoringFunction,CPD,DataFrame}"><code>BayesNets.score_component</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">score_component(a::ScoringFunction, cpd::CPD, data::DataFrame)</code></pre><p>Extract a Float64 score for a cpd given the data. One seeks to maximize the score.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.score_components-Union{Tuple{C}, Tuple{ScoringFunction,Array{C,1},DataFrame}} where C&lt;:CPD" href="#BayesNets.score_components-Union{Tuple{C}, Tuple{ScoringFunction,Array{C,1},DataFrame}} where C&lt;:CPD"><code>BayesNets.score_components</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">score_components(a::ScoringFunction, cpd::CPD, data::DataFrame)
score_components(a::ScoringFunction, cpds::Vector{CPD}, data::DataFrame, cache::ScoreComponentCache)</code></pre><p>Get a list of score components for all cpds</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.statistics-Tuple{Array{Array{Int64,1},1},AbstractArray{Int64,1},AbstractArray{Int64,2}}" href="#BayesNets.statistics-Tuple{Array{Array{Int64,1},1},AbstractArray{Int64,1},AbstractArray{Int64,2}}"><code>BayesNets.statistics</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">statistics(
    parent_list::Vector{Vector{Int}},
    ncategories::AbstractVector{Int},
    data::AbstractMatrix{Int},
    )</code></pre><p>Computes sufficient statistics from a discrete dataset for a Discrete Bayesian Net structure</p><p>INPUT:     parents:         list of lists of parent indices         A variable with index i has ncategories[i]         and row in data[i,:]         No acyclicity checking is done     ncategories:         list of variable bin counts, or number of         discrete values the variable can take on, v ∈ {1 : ncategories[i]}     data:         table of discrete values [n×m]         where n is the number of nodes         and m is the number of samples</p><p>OUTPUT:     N :: Vector{Matrix{Int}}         a sufficient statistics table for each variable         Variable with index i has statistics table N[i],         which is r × q where         r = ncategories[i] is the number of variable instantiations and         q is the number of parental instantiations of variable i</p><pre><code class="language-none">    The r-values are ordered from 1 → ncategories[i]
    The q-values are ordered in the same ordering as ind2sub() in Julia Base
        Thus the instantiation of the first parent (by order given in parents[i])
        is varied the fastest.

    ex:
        Variable 1 has parents 2 and 3, with r₁ = 2, r₂ = 2, r₃ = 3
        q for variable 1 is q = r₂×r₃ = 6
        N[1] will be a 6×2 matrix where:
            N[1][1,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 1
            N[1][2,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 1
            N[1][3,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 2
            N[1][4,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 2
            N[1][5,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 3
            N[1][6,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 3
            N[1][6,2] is the number of time v₁ = 2, v₂ = 1, v₃ = 1
            ...</code></pre><p>This function uses sparse matrix black magic and was mercilessly stolen from Ed Schmerling.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.statistics-Tuple{Int64,AbstractArray{Int64,1},AbstractArray{Int64,1},AbstractArray{Int64,2}}" href="#BayesNets.statistics-Tuple{Int64,AbstractArray{Int64,1},AbstractArray{Int64,1},AbstractArray{Int64,2}}"><code>BayesNets.statistics</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">statistics(
    targetind::Int,
    parents::AbstractVector{Int},
    ncategories::AbstractVector{Int},
    data::AbstractMatrix{Int}
    )</code></pre><p>outputs a sufficient statistics table for the target variable that is r × q where r = ncategories[i] is the number of variable instantiations and q is the number of parental instantiations of variable i</p><p>The r-values are ordered from 1 → ncategories[i] The q-values are ordered in the same ordering as ind2sub() in Julia Base     Thus the instantiation of the first parent (by order given in parents[i])     is varied the fastest.</p><p>ex:     Variable 1 has parents 2 and 3, with r₁ = 2, r₂ = 2, r₃ = 3     q for variable 1 is q = r₂×r₃ = 6     N will be a 6×2 matrix where:         N[1,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 1         N[2,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 1         N[3,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 2         N[4,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 2         N[5,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 3         N[6,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 3         N[6,2] is the number of time v₁ = 2, v₂ = 1, v₃ = 1         ...</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.sumout-Tuple{BayesNets.Table,Union{AbstractArray{Symbol,1}, Symbol}}" href="#BayesNets.sumout-Tuple{BayesNets.Table,Union{AbstractArray{Symbol,1}, Symbol}}"><code>BayesNets.sumout</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">sumout(t, v)</code></pre><p>Table marginalization</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.table-Tuple{BayesNet{CategoricalCPD{Categorical{Float64}}},Symbol}" href="#BayesNets.table-Tuple{BayesNet{CategoricalCPD{Categorical{Float64}}},Symbol}"><code>BayesNets.table</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">table(bn::DiscreteBayesNet, name::NodeName)</code></pre><p>Constructs the CPD factor associated with the given node in the BayesNet</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Distributions.logpdf-Tuple{BayesNet,Dict{Symbol,Any}}" href="#Distributions.logpdf-Tuple{BayesNet,Dict{Symbol,Any}}"><code>Distributions.logpdf</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>The logpdf of a given assignment after conditioning on the values</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Distributions.ncategories-Tuple{BayesNet{CategoricalCPD{Categorical{Float64}}},Symbol}" href="#Distributions.ncategories-Tuple{BayesNet{CategoricalCPD{Categorical{Float64}}},Symbol}"><code>Distributions.ncategories</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">Distributions.ncategories(bn::DiscreteBayesNet, node::Symbol)</code></pre><p>Return the number of categories for a node in the network.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Distributions.pdf-Tuple{BayesNet,Dict{Symbol,Any}}" href="#Distributions.pdf-Tuple{BayesNet,Dict{Symbol,Any}}"><code>Distributions.pdf</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>The pdf of a given assignment after conditioning on the values</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LightGraphs.has_edge-Tuple{BayesNet,Symbol,Symbol}" href="#LightGraphs.has_edge-Tuple{BayesNet,Symbol,Symbol}"><code>LightGraphs.has_edge</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Whether the BayesNet contains the given edge</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LightGraphs.neighbors-Tuple{BayesNet,Symbol}" href="#LightGraphs.neighbors-Tuple{BayesNet,Symbol}"><code>LightGraphs.neighbors</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns all neighbors as a list of NodeNames.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LinearAlgebra.normalize-Tuple{Factor,Vararg{Any,N} where N}" href="#LinearAlgebra.normalize-Tuple{Factor,Vararg{Any,N} where N}"><code>LinearAlgebra.normalize</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">normalize!(ϕ, dims; p=1)
normalize!(ϕ; p=1)</code></pre><p>Return a normalized copy of the factor so all instances of dims have (or the entire factors has) p-norm of 1</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.fit-Tuple{Type{BayesNets.Table},DataFrame}" href="#StatsBase.fit-Tuple{Type{BayesNets.Table},DataFrame}"><code>StatsBase.fit</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>takes a list of observations of assignments represented as a DataFrame or a set of data samples (without :p), takes the unique assignments, and estimates the associated probability of each assignment based on its frequency of occurrence.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.fit-Union{Tuple{C}, Tuple{Type{BayesNet{C}},DataFrame,GraphSearchStrategy}} where C&lt;:CPD" href="#StatsBase.fit-Union{Tuple{C}, Tuple{Type{BayesNet{C}},DataFrame,GraphSearchStrategy}} where C&lt;:CPD"><code>StatsBase.fit</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">fit{C&lt;:CPD}(::Type{BayesNet{C}}, ::DataFrame, ::GraphSearchStrategy)</code></pre><p>Run the graph search algorithm defined by GraphSearchStrategy</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.fit-Union{Tuple{T}, Tuple{Type{BayesNet{T}},DataFrame,Tuple{Vararg{Pair{Symbol,Symbol},N} where N}}} where T&lt;:CPD" href="#StatsBase.fit-Union{Tuple{T}, Tuple{Type{BayesNet{T}},DataFrame,Tuple{Vararg{Pair{Symbol,Symbol},N} where N}}} where T&lt;:CPD"><code>StatsBase.fit</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">fit(::Type{BayesNet}, data, edges)</code></pre><p>Fit a Bayesian Net whose variables are the columns in data and whose edges are given in edges</p><pre><code class="language-none">ex: fit(DiscreteBayesNet, data, (:A=&gt;:B, :C=&gt;B))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.GibbsSamplerState" href="#BayesNets.GibbsSamplerState"><code>BayesNets.GibbsSamplerState</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Used to cache various things the Gibbs sampler needs</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.:*-Tuple{BayesNets.Table,BayesNets.Table}" href="#Base.:*-Tuple{BayesNets.Table,BayesNets.Table}"><code>Base.:*</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Table multiplication</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.Broadcast.broadcast!-Tuple{Any,Factor,Union{AbstractArray{Symbol,1}, Symbol},Any}" href="#Base.Broadcast.broadcast!-Tuple{Any,Factor,Union{AbstractArray{Symbol,1}, Symbol},Any}"><code>Base.Broadcast.broadcast!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">broadcast!(f, ϕ, dims, values)</code></pre><p>Broadcast a vector (or array of vectors) across the dimension(s) <code>dims</code> Each vector in <code>values</code> will be broadcast acroos its respective dimension in <code>dims</code></p><p>See Base.broadcast for more info.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.Broadcast.broadcast-Tuple{Any,Factor,Union{AbstractArray{Symbol,1}, Symbol},Any}" href="#Base.Broadcast.broadcast-Tuple{Any,Factor,Union{AbstractArray{Symbol,1}, Symbol},Any}"><code>Base.Broadcast.broadcast</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">broadcast(f, ϕ, dims, values)</code></pre><p>Broadcast a vector (or array of vectors) across the dimension(s) <code>dims</code> Each vector in <code>values</code> will be broadcast acroos its respective dimension in <code>dims</code></p><p>See Base.broadcast for more info.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.Sort.partialsort-Tuple{BayesNets.Table,Dict{Symbol,Any}}" href="#Base.Sort.partialsort-Tuple{BayesNets.Table,Dict{Symbol,Any}}"><code>Base.Sort.partialsort</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Given a Table, extract the rows which match the given assignment</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.count-Tuple{BayesNet{CategoricalCPD{Categorical{Float64}}},Symbol,DataFrame}" href="#Base.count-Tuple{BayesNet{CategoricalCPD{Categorical{Float64}}},Symbol,DataFrame}"><code>Base.count</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">Base.count(bn::BayesNet, name::NodeName, data::DataFrame)</code></pre><p>returns a table containing all observed assignments and their corresponding counts</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.eltype-Tuple{Factor}" href="#Base.eltype-Tuple{Factor}"><code>Base.eltype</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns Float64</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.getindex-Tuple{Factor,Dict{Symbol,Any}}" href="#Base.getindex-Tuple{Factor,Dict{Symbol,Any}}"><code>Base.getindex</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">getindex(ϕ, a)</code></pre><p>Get values with dimensions consistent with an assignment. Colons select entire dimension.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.in-Tuple{Symbol,Factor}" href="#Base.in-Tuple{Symbol,Factor}"><code>Base.in</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">in(dim, ϕ) -&gt; Bool</code></pre><p>Return true if <code>dim</code> is in the Factor <code>ϕ</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.indexin-Tuple{Symbol,Factor}" href="#Base.indexin-Tuple{Symbol,Factor}"><code>Base.indexin</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">indexin(dims, ϕ)</code></pre><p>Return the index of dimension <code>dim</code> in <code>ϕ</code>, or 0 if not in <code>ϕ</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.join" href="#Base.join"><code>Base.join</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">join(op, ϕ1, ϕ2, :outer, [v0])
join(op, ϕ1, ϕ2, :inner, [reducehow], [v0])</code></pre><p>Performs either an inner or outer join,</p><p>An outer join returns a Factor with the union of the two dimensions The two factors are combined with Base.broadcast(op, ...)</p><p>An inner join keeps the dimensions in common between the two Factors. The extra dimensions are reduced with     reducedim(reducehow, ...) and then the two factors are combined with:     op(ϕ1[common<em>dims].potential, ϕ2[common</em>dims].potential)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.names-Tuple{BayesNet}" href="#Base.names-Tuple{BayesNet}"><code>Base.names</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns the ordered list of NodeNames</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.names-Tuple{Factor}" href="#Base.names-Tuple{Factor}"><code>Base.names</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Names of each dimension</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.push!-Tuple{Factor,Symbol,Int64}" href="#Base.push!-Tuple{Factor,Symbol,Int64}"><code>Base.push!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Appends a new dimension to a Factor</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.rand-Tuple{BayesNet,BayesNetSampler,Integer}" href="#Base.rand-Tuple{BayesNet,BayesNetSampler,Integer}"><code>Base.rand</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Generates a DataFrame containing a dataset of variable assignments. Always return a DataFrame with <code>nsamples</code> rows.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.rand-Tuple{BayesNet,BayesNetSampler}" href="#Base.rand-Tuple{BayesNet,BayesNetSampler}"><code>Base.rand</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns an assignment sampled from the bn using the provided sampler</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.rand-Tuple{BayesNet,GibbsSampler,Integer}" href="#Base.rand-Tuple{BayesNet,GibbsSampler,Integer}"><code>Base.rand</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Implements Gibbs sampling. (https://en.wikipedia.org/wiki/Gibbs_sampling) For finite variables, the posterior distribution is sampled by building the exact distribution. For continuous variables, the posterior distribution is sampled using Metropolis Hastings MCMC. Discrete variables with infinite support are currently not supported. The Gibbs Sampler only supports CPDs that return Univariate Distributions. (CPD{D&lt;:UnivariateDistribution})</p><p>Sampling requires a GibbsSampler object which contains the parameters for Gibbs sampling. See the GibbsSampler documentation for parameter details.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.similar-Tuple{Factor}" href="#Base.similar-Tuple{Factor}"><code>Base.similar</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">similar(ϕ)</code></pre><p>Return a factor similar to <code>ϕ</code> with unitialized values</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.size-Tuple{Factor}" href="#Base.size-Tuple{Factor}"><code>Base.size</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">size(ϕ, [dims...])</code></pre><p>Returns a tuple of the dimensions of <code>ϕ</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.write-Tuple{IO,MIME{Symbol(&quot;text/plain&quot;)},BayesNet{CategoricalCPD{Categorical{Float64}}}}" href="#Base.write-Tuple{IO,MIME{Symbol(&quot;text/plain&quot;)},BayesNet{CategoricalCPD{Categorical{Float64}}}}"><code>Base.write</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">write(io, text/plain, bn)</code></pre><p>Writes a text file containing the sufficient statistics for a discrete Bayesian network. This was inspired by the format listed in Appendix A of &quot;Correlated Encounter Model for Cooperative Aircraft in the National Airspace System Version 1.0&quot; by Mykel Kochenderfer.</p><p>The text file contains the following parameters:</p><ul><li>variable labels: A space-delimited list specifies the variable labels, which are symbols.                  The ordering of the variables in this list determines the ordering of the variables                  in the other tables. Note that the ordering of the variable labels is not                  necessarily topological.</li><li>graphical structure: A binary matrix is used to represent the graphical structure of the Bayesian                  network. A 1 in the ith row and jth column means that there is a directed edge                  from the ith varible to the jth variable in the Bayesian network. The ordering                  of the variables are as defined in the variable labels section of the file.                  The entries are 0 or 1 and are not delimited.</li><li>variable instantiations: A list of integers specifying the number of instantiations for each variable.                  The list is space-delimited.</li><li>sufficient statistics: A list of space-delimited integers Pₐⱼₖ  which specifies the sufficient statistics.                  The array is ordered first by increasing k, then increasing j, then increasing i.                  The variable ordering is defined in the variable labels section of the file.                  The list is a flattened matrices, where each matrix is rₐ × qₐ where rₐ is the number of                  instantiations of variable a and qₐ is the number of instantiations of the parents of                  variable a. The ordering is the same as the ordering of the distributions vector in                  the CategoricalCPD type.                  The entires in Pₐⱼₖ are floating point probability values.</li></ul><p>For example, the network Success -&gt; Forecast with Success ∈ [1, 2] and P(1) = 0.2, P(2) = 0.8 and Forecast ∈ [1, 2, 3] with     P(1 | 1) = 0.4, P(2 | 1) = 0.4, P(3 | 1) = 0.2     P(1 | 2) = 0.1, P(2 | 2) = 0.3, P(3 | 2) = 0.6</p><p>Is output as:</p><p>Success Forecast 01 00 2 3 2 4 4 1 3</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets._evidence_lambda-Tuple{Symbol,Dict{Symbol,Any},Int64}" href="#BayesNets._evidence_lambda-Tuple{Symbol,Dict{Symbol,Any},Int64}"><code>BayesNets._evidence_lambda</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Get the lambda-message to itself for an evidence node. If it isn&#39;t an evidence node, this will break</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets._get_parent_indeces-Tuple{AbstractArray{Symbol,1},DataFrame}" href="#BayesNets._get_parent_indeces-Tuple{AbstractArray{Symbol,1},DataFrame}"><code>BayesNets._get_parent_indeces</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">score_component(a::ScoringFunction, cpd::CPD, data::DataFrame, cache::ScoreComponentCache)</code></pre><p>As score_component(ScoringFunction, cpd, data), but returns pre-computed values from the cache if they exist, and populates the cache if they don&#39;t</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets._init_gibbs_sample" href="#BayesNets._init_gibbs_sample"><code>BayesNets._init_gibbs_sample</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">_init_gibbs_sample(bn, evidence)</code></pre><p>A random sample of non-evidence nodes uniformly over their domain</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.duplicate-Tuple{Array,Tuple{Vararg{Int64,N}} where N}" href="#BayesNets.duplicate-Tuple{Array,Tuple{Vararg{Int64,N}} where N}"><code>BayesNets.duplicate</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">duplicate(A, dims)</code></pre><p>Repeates an array only through higer dimensions <code>dims</code>.</p><p>Custom version of repeate, but only outer repetition, and only duplicates the array for the number of times specified in <code>dims</code> for dimensions greater than <code>ndims(A)</code>. If <code>dims</code> is empty, returns a copy of <code>A</code>.</p><pre><code class="language-julia-repl">julia&gt; duplicate(collect(1:3), 2)
3×2 Array{Int64,2}:
 1  1
 2  2
 3  3

julia&gt; duplicate([1 3; 2 4], 3)
2×2×3 Array{Int64,3}:
[:, :, 1] =
 1  3
 2  4

[:, :, 2] =
 1  3
 2  4

[:, :, 3] =
 1  3
 2  4</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.eval_mb_cpd-Tuple{Symbol,Int64,Dict{Symbol,Any},Array{T,1} where T}" href="#BayesNets.eval_mb_cpd-Tuple{Symbol,Int64,Dict{Symbol,Any},Array{T,1} where T}"><code>BayesNets.eval_mb_cpd</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">eval_mb_cpd(node, ncategories, assignment, mb_cpds)</code></pre><p>Return the potential of all instances of a node given its markove blanket as a WeightVec:     P(node | pa<em>node) * Prod (c in children) P(c | pa</em>c)</p><p>Trys out all possible values of node (assumes categorical) Assignment should have values for all in the Markov blanket, including the variable itself.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.get_finite_distribution!-Tuple{BayesNets.GibbsSamplerState,Symbol,Dict{Symbol,Any},AbstractArray}" href="#BayesNets.get_finite_distribution!-Tuple{BayesNets.GibbsSamplerState,Symbol,Dict{Symbol,Any},AbstractArray}"><code>BayesNets.get_finite_distribution!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Helper to sample<em>posterior</em>finite</p><p>Modifies a and gss</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.get_mb_cpds-Tuple{BayesNet,Symbol}" href="#BayesNets.get_mb_cpds-Tuple{BayesNet,Symbol}"><code>BayesNets.get_mb_cpds</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Get the cpd&#39;s of a node and its children</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.get_weighted_dataframe-Tuple{BayesNet,Integer,Dict{Symbol,Any}}" href="#BayesNets.get_weighted_dataframe-Tuple{BayesNet,Integer,Dict{Symbol,Any}}"><code>BayesNets.get_weighted_dataframe</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>A dataset of variable assignments is obtained with an additional column of weights in accordance with the likelihood of each assignment.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.gibbs_sample_main_loop-Tuple{BayesNets.GibbsSamplerState,Integer,Integer,Dict{Symbol,Any},Dict{Symbol,Any},Union{Nothing, Array{Symbol,1}},Union{Nothing, Int64}}" href="#BayesNets.gibbs_sample_main_loop-Tuple{BayesNets.GibbsSamplerState,Integer,Integer,Dict{Symbol,Any},Dict{Symbol,Any},Union{Nothing, Array{Symbol,1}},Union{Nothing, Int64}}"><code>BayesNets.gibbs_sample_main_loop</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>The main loop associated with Gibbs sampling Returns a data frame with nsamples samples</p><p>Supports the various parameters supported by gibbs<em>sample Refer to gibbs</em>sample for parameter meanings</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.ndgrid_fill!-NTuple{4,Any}" href="#BayesNets.ndgrid_fill!-NTuple{4,Any}"><code>BayesNets.ndgrid_fill!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>???</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.reducedim" href="#BayesNets.reducedim"><code>BayesNets.reducedim</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">reducedim(op, ϕ, dims, [v0])</code></pre><p>Reduce dimensions <code>dims</code> in <code>ϕ</code> using function <code>op</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.sample_posterior!-Tuple{BayesNets.GibbsSamplerState,Symbol,Dict{Symbol,Any}}" href="#BayesNets.sample_posterior!-Tuple{BayesNets.GibbsSamplerState,Symbol,Dict{Symbol,Any}}"><code>BayesNets.sample_posterior!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>set a[varname] ~ P(varname | not varname)</p><p>Modifies a and caches in gss</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.sample_posterior_continuous!-Tuple{BayesNets.GibbsSamplerState,Symbol,Dict{Symbol,Any},Distribution{Univariate,Continuous}}" href="#BayesNets.sample_posterior_continuous!-Tuple{BayesNets.GibbsSamplerState,Symbol,Dict{Symbol,Any},Distribution{Univariate,Continuous}}"><code>BayesNets.sample_posterior_continuous!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Implements Metropolis-Hastings with a normal distribution proposal with mean equal to the previous value of the variable &quot;varname&quot; and stddev equal to 10 times the standard deviation of the distribution of the target variable given its parents ( var_distribution should be get(bn, varname)(a) )</p><p>MH will go through nsamples iterations.  If no proposal is accepted, the original value will remain</p><p>This function expects that a[varname] is within the support of the distribution, it will not check to make sure this is true</p><p>Helper to sample_posterior Should only be used to sampling continuous distributions</p><p>set a[varname] ~ P(varname | not varname)</p><p>Modifies a and caches in gss</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.sample_posterior_finite!-Tuple{BayesNets.GibbsSamplerState,Symbol,Dict{Symbol,Any},AbstractArray}" href="#BayesNets.sample_posterior_finite!-Tuple{BayesNets.GibbsSamplerState,Symbol,Dict{Symbol,Any},AbstractArray}"><code>BayesNets.sample_posterior_finite!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Helper to sample_posterior Should only be called if the variable associated with varname is discrete</p><p>set a[varname] ~ P(varname | not varname)</p><p>Modifies both a and gss</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BayesNets.sample_weighted_dataframe!-Tuple{Dict{Symbol,Any},DataFrame}" href="#BayesNets.sample_weighted_dataframe!-Tuple{Dict{Symbol,Any},DataFrame}"><code>BayesNets.sample_weighted_dataframe!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Chooses a sample at random from a weighted dataframe</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LightGraphs.dst-Tuple{Pair{Int64,Int64}}" href="#LightGraphs.dst-Tuple{Pair{Int64,Int64}}"><code>LightGraphs.dst</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns all descendants as a list of NodeNames.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LinearAlgebra.normalize!-Tuple{BayesNets.Table}" href="#LinearAlgebra.normalize!-Tuple{BayesNets.Table}"><code>LinearAlgebra.normalize!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Table normalization Ensures that the <code>:p</code> column sums to one</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LinearAlgebra.normalize!-Tuple{Factor,Union{AbstractArray{Symbol,1}, Symbol}}" href="#LinearAlgebra.normalize!-Tuple{Factor,Union{AbstractArray{Symbol,1}, Symbol}}"><code>LinearAlgebra.normalize!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">normalize!(ϕ, dims; p=1)
normalize!(ϕ; p=1)</code></pre><p>Normalize the factor so all instances of dims have (or the entire factors has) p-norm of 1</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Random.rand!-Tuple{Dict{Symbol,Any},BayesNet,BayesNetSampler}" href="#Random.rand!-Tuple{Dict{Symbol,Any},BayesNet,BayesNetSampler}"><code>Random.rand!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Overwrites assignment with a sample from bn using the sampler</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Random.rand!-Tuple{Dict{Symbol,Any},BayesNet,GibbsSampler}" href="#Random.rand!-Tuple{Dict{Symbol,Any},BayesNet,GibbsSampler}"><code>Random.rand!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">NOTE: this is inefficient. Use rand(bn, GibbsSampler, nsamples) whenever you can</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Random.rand!-Tuple{Factor}" href="#Random.rand!-Tuple{Factor}"><code>Random.rand!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">rand!(ϕ)</code></pre><p>Fill with random values</p></div></div></section><footer><hr/></footer></article></body></html>
